{"meta":{"title":"我的博客 - blog","subtitle":"驿站小憩","description":"脑容量不够，笔记来凑","author":"unistd68","url":"https://lives.xtcgch.ink"},"pages":[{"title":"","date":"2020-08-10T10:46:28.867Z","updated":"2018-11-25T02:34:13.891Z","comments":true,"path":"404.html","permalink":"https://lives.xtcgch.ink/404.html","excerpt":"","text":""},{"title":"tags","date":"2018-11-22T09:35:24.000Z","updated":"2021-09-13T05:14:50.756Z","comments":true,"path":"tags/index.html","permalink":"https://lives.xtcgch.ink/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-11-22T09:35:00.000Z","updated":"2021-09-13T04:58:02.649Z","comments":true,"path":"categories/index.html","permalink":"https://lives.xtcgch.ink/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"ideas之stupid篇","slug":"ideas之stupid篇-20211128","date":"2021-11-23T02:55:00.000Z","updated":"2021-11-28T10:22:19.100Z","comments":true,"path":"2021/11/23/ideas之stupid篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/11/23/ideas之stupid篇/","excerpt":"摘要： 记录奇奇怪怪的想法！","text":"摘要： 记录奇奇怪怪的想法！ 标题一 标题二 标题二 ★ 橙色字体 ★ 浅红字体","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://lives.xtcgch.ink/tags/IDEA/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"求职之架构篇","slug":"求职之架构篇-20211122","date":"2021-11-22T00:46:58.000Z","updated":"2021-11-22T01:07:43.028Z","comments":true,"path":"2021/11/22/求职之架构篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/11/22/求职之架构篇/","excerpt":"摘要： 本文主要记录架构方面的知识！","text":"摘要： 本文主要记录架构方面的知识！ 脑图 标题一 标题二橙色字体 浅红字体","categories":[{"name":"原理/专项/实战/开源/求职/算法/综合/其他","slug":"原理-专项-实战-开源-求职-算法-综合-其他","permalink":"https://lives.xtcgch.ink/categories/原理-专项-实战-开源-求职-算法-综合-其他/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"},{"name":"架构","slug":"架构","permalink":"https://lives.xtcgch.ink/tags/架构/"}],"keywords":[{"name":"原理/专项/实战/开源/求职/算法/综合/其他","slug":"原理-专项-实战-开源-求职-算法-综合-其他","permalink":"https://lives.xtcgch.ink/categories/原理-专项-实战-开源-求职-算法-综合-其他/"}]},{"title":"数据结构之算法篇","slug":"数据结构之算法-20211103","date":"2021-11-03T01:08:49.000Z","updated":"2021-11-08T00:59:34.284Z","comments":true,"path":"2021/11/03/数据结构之算法篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/11/03/数据结构之算法篇/","excerpt":"摘要： 本文记录下常用几种算法的思路。","text":"摘要： 本文记录下常用几种算法的思路。 脑图 动态规划 特点 快速处理复杂的计算，去除重复的计算 以空间换时间 重叠子问题 最优子结构 适用场景 能穷举结果的 边界确定的 使用步骤 状态定义： 构建问题最优解模型，包括问题最优解的定义、有哪些计算解的自变量 初始状态： 确定基础子问题的解（即已知解），原问题和子问题的解都是以基础子问题的解为起始点，在迭代计算中得到的 定义好一张二维表(可能也只是一维数组) 填表 找出状态转移公式 求出最优解 返回值： 确定应返回的问题的解是什么，即动态规划在何处停止迭代 确定状态 实战 扩展题目 :joy: :smile: :heart: - 0 1 2 3 4 5 6 7 0 true true true true true true true true 1 - true true true true true true true 2 - - true true true true true true 3 - - - true true true true true 4 - - - - true true true true 5 - - - - - true true true 6 - - - - - - true true 7 - - - - - - - true - 1 2 3 4 5 6 7 8 9 10 1 1 5 8 9 10 17 17 20 24 30 2 - 2 6 10 13 true true 3 - - 3 7 true true true 4 - - - 4 true true true 5 - - - - 5 true true 6 - - - - - 6 true 7 - - - - - - 7 8 - - - - - - true 8 9 - - - - - - true 9 10 - - - - - - true 10 -&gt;p[10]={}; - 0 1 2 3 4 5 6 0 0 0 0 0 0 0 0 1 - 2 3 6 7 11 15 2 - - 4 6 8 9 13 3 - - - 6 7 10 12 4 - - - - 8 9 12 5 - - - - - 10 12 6 - - - - - - 12 -&gt;p[7] = {0,2,4,6,8,11,15};","categories":[{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/tags/算法/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/categories/算法/"}]},{"title":"求职之linux内核","slug":"求职之linux内核-20211028","date":"2021-10-28T14:26:35.000Z","updated":"2021-11-23T14:58:46.062Z","comments":true,"path":"2021/10/28/求职之linux内核/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/28/求职之linux内核/","excerpt":"摘要： 记录一些跟linux内核有关的面试题。","text":"摘要： 记录一些跟linux内核有关的面试题。 脑图 一、基础篇 1 主要有哪几种内核锁？Linux 内核的同步机制是什么？自旋锁：spin_lock 忙等，中断中使用 信号量：semxxx down/up write/read mutex：初始化为1的信号量 读写锁，RCU(read-copy update) 2 Linux 中的用户模式和内核模式是什么含义？cpu mode，用户模式只能通过系统调用操作硬件资源，内核模式可以直接操作硬件资源 3 怎么申请大块内存？vmalloc 和 kmalloc 有什么区别？vmalloc 用于申请大块内存，虚拟地址连续，物理地址不一定连续，不能直接用于DMA，在进程地址空间有专门的一块。 kmalloc 用于申请小内存，由 slab 管理实现，一般至少小于4KB（page）。不能申请大于128K的数据。物理地址和虚拟地址都连续，可用于DMA操作。 4 进程间通信主要有哪几种方式？1）管道 Pipe）：管道可用于具有亲缘关系进程间的通信，允许一个进程和另一个 与它有共同祖先的进程之间进行通信 2）命名管道 named pipe）：命名管道克服了管道没有名字的限制，因此，除具有 管道所具有的功能外，它还允许无亲缘关系进程间的通信。命名管道在文件系统 中有对应的文件名。命名管道通过命令 mkfifo 或系统调用 mkfifo 来创建。 3）信号 Signal）：信号是比较复杂的通信方式，用于通知接受进程有某种事件发 生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux 除了支持 Unix 早期信号语义函数 sigal 外，还支持语义符合 Posix.1 标准的信号函数 sigaction 实际上，该函数是基于 BSD 的，BSD 为了实现可靠信号机制，又能够 统一对外接口，用 sigaction 函数重新实现了 signal 函数）。 4）消息 Message）队列：消息队列是消息的链接表，包括 Posix 消息队列 system V 消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则 可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格 式字节流以及缓冲区大小受限等缺 5）信号量 semaphore）：主要作为进程间以及同一进程不同线程之间的同步手段。 6）套接字 Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间 通信。起初是由 Unix 系统的 BSD 分支开发出来的，但现在一般可以移植到其它 类 Unix 系统上：Linux 和 System V 的变种都支持套接字。 5 伙伴系统申请内存的函数有哪些alloc_page(gfp_mask, order) __get_free_pages(gfp_mask, order) 6 通过 slab 分配器申请内存的函数有哪些自己构造对象：kmem_cache_create/kmem_cache_alloc 普通匿名内存申请：kmalloc 7 Linux 的内核空间和用户空间如何划分的？进程地址空间布局图？32位可配置3G/1G, 2G/2G，一般是两级页表 64位可配置几级页表，一般可选3级/4级页表，256G/256G，或512T/512T 8 vmalloc() 申请内存有什么特点？申请大块内存，虚拟地址连续，物理地址不一定连续，不能直接用于DMA。对于释放函数 vfree() 9 用户程序使用 malloc() 申请的内存空间在什么范围？stack 和 heap 中间。小于128M的通过brk申请，大于的通过 mmap 申请 10 在支持并使能 MMU 的系统中，Linux 内核和用于程序分别运行在物理地址模式还是虚拟地址模式？都运行在虚拟地址模式，页表转换对应由硬件单元MMU完成。 11 ARM 处理器是通过几级页表进行存储空间映射的？两级页表，PGD和PTE 12 Linux 是通过什么组件来实现支持多种文件系统的？VFS(virtual file system) 13 Linux虚拟文件系统的关键数据结构有哪些？super_block超级块 inode索引节点 dentry目录项 file文件 14 对文件系统的操作函数保存在哪个数据结构中？struct file_operations 15 Linux 中的文件包括哪些？可执行文件，普通文件，目录文件，链接文件，设备文件，管道文件 16 创建进程的系统调用有哪些？clone, fork, vfork 17 调用 schedule() 进行进程切换的方式有几种？1.系统调用 do_fork(); 2.定时中断 do_timer(); 3.唤醒进程 wake_up_process 4.改变进程的调度策略 setscheduler(); 5.系统调用礼让 sys_sched_yield(); 18 Linux 调度程序是根据进程的动态优先级还是静态优先级来调度进程的？Liunx 调度程序是根据根据进程的动态优先级来调度进程的，但是动态优先级又 是根据静态优先级根据算法计算出来的，两者是两个相关联的值。因为高优先级 的进程总是比低优先级的进程先被调度，为防止多个高优先级的进程占用 CPU 资 源，导致其他进程不能占有 CPU，所以引用动态优先级概念 19 进程调度的核心数据结构是哪个？struct runqueue 20 如何加载、卸载一个模块？ismod, rmmod 21 模块和应用程序分别运行在什么空间？模块运行在内核空间，应用程序运行在用户空间 22 Linux 中的浮点运算由应用程序实现还是内核实现？应用程序实现，Linux 中的浮点运算是利用数学库函数实现的，库函数能够被应 用程序链接后调用，不能被内核链接调用。这些运算是在应用程序中运行的，然 后再把结果反馈给系统。Linux 内核如果一定要进行浮点运算，需要在建立内核 时选上 math-emu,使用软件模拟计算浮点运算，据说这样做的代价有两个：用户 在安装驱动时需要重建内核，可能会影响到其他的应用程序，使得这些应用程序 在做浮点运算的时候也使用 math-emu，大大的降低了效率。 23 模块程序能否使用可链接的库函数？module 运行在内核空间，不能链接库函数 24 TLB 中缓存的是什么内容translation lookaside buffer, 也叫快表，用作页表缓冲。记录虚拟地址和物理地址的对应关系，用于加快地址转换 25 Linux 中有哪几种设备字符设备和块设备 26 字符设备驱动程序的关键数据结构是哪个struct cdev: kobject cdev_alloc() cdev_add() 27 设备驱动程序包括哪些功能函数open/read/write/ioctl/release/llseek 28 如何唯一标识一个设备？主设备号和次设备号。dev_t，12位表示主设备号，20位表示次设备号。 MKDEV(int major, int minor)用于生产一个 dev_t 类型的对象 29 Linux 通过什么方式实现系统调用？软件中断。系统调用编号，异常处理程序 30 Linux 软中断和工作队列的作用是什么？软中断：不可睡眠阻塞，处于中断上下文，不能进程切换，不能被自己打断。 工作队列：处理进程上下文中，可以睡眠阻塞。","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"},{"name":"LINUX内核","slug":"LINUX内核","permalink":"https://lives.xtcgch.ink/tags/LINUX内核/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"TODO","slug":"TODO","date":"2021-10-19T15:24:58.000Z","updated":"2021-11-22T14:22:46.833Z","comments":true,"path":"2021/10/19/TODO/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/19/TODO/","excerpt":"摘要： 暂做为TODO List 使用！","text":"摘要： 暂做为TODO List 使用！ 脑图 重要且紧急 rabbitmq 重要不紧急 布隆过滤器 bitmap 查看进程IO情况 iotop pidstat iostat dmesg mpstat 不重要但紧急 单调栈 不重要不紧急 apifox.cn mysql页大小","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"TODO","slug":"TODO","permalink":"https://lives.xtcgch.ink/tags/TODO/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"算法之sm4","slug":"算法之sm4-20211015","date":"2021-10-14T14:33:04.000Z","updated":"2021-11-22T14:22:56.843Z","comments":true,"path":"2021/10/14/算法之sm4/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/14/算法之sm4/","excerpt":"摘要：记录下sm4算法知识。","text":"摘要：记录下sm4算法知识。 脑图 实战 sm4.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261#include &quot;sm4.h&quot;/* * 32-bit integer manipulation macros (big endian) */#ifndef GET_ULONG_BE#define GET_ULONG_BE(n,b,i) \\&#123; \\ (n) = ( (unsigned long) (b)[(i) ] &lt;&lt; 24 ) \\ | ( (unsigned long) (b)[(i) + 1] &lt;&lt; 16 ) \\ | ( (unsigned long) (b)[(i) + 2] &lt;&lt; 8 ) \\ | ( (unsigned long) (b)[(i) + 3] ); \\&#125;#endif#ifndef PUT_ULONG_BE#define PUT_ULONG_BE(n,b,i) \\&#123; \\ (b)[(i) ] = (unsigned char) ( (n) &gt;&gt; 24 ); \\ (b)[(i) + 1] = (unsigned char) ( (n) &gt;&gt; 16 ); \\ (b)[(i) + 2] = (unsigned char) ( (n) &gt;&gt; 8 ); \\ (b)[(i) + 3] = (unsigned char) ( (n) ); \\&#125;#endif/* *rotate shift left marco definition * */#define SHL(x,n) (((x) &amp; 0xFFFFFFFF) &lt;&lt; n)#define ROTL(x,n) (SHL((x),n) | ((x) &gt;&gt; (32 - n)))#define SWAP(a,b) &#123; unsigned long t = a; a = b; b = t; t = 0; &#125;/* * Expanded SM4 S-boxes /* Sbox table: 8bits input convert to 8 bits output*/ static const unsigned char SboxTable[16][16] = &#123;&#123;0xd6,0x90,0xe9,0xfe,0xcc,0xe1,0x3d,0xb7,0x16,0xb6,0x14,0xc2,0x28,0xfb,0x2c,0x05&#125;,&#123;0x2b,0x67,0x9a,0x76,0x2a,0xbe,0x04,0xc3,0xaa,0x44,0x13,0x26,0x49,0x86,0x06,0x99&#125;,&#123;0x9c,0x42,0x50,0xf4,0x91,0xef,0x98,0x7a,0x33,0x54,0x0b,0x43,0xed,0xcf,0xac,0x62&#125;,&#123;0xe4,0xb3,0x1c,0xa9,0xc9,0x08,0xe8,0x95,0x80,0xdf,0x94,0xfa,0x75,0x8f,0x3f,0xa6&#125;,&#123;0x47,0x07,0xa7,0xfc,0xf3,0x73,0x17,0xba,0x83,0x59,0x3c,0x19,0xe6,0x85,0x4f,0xa8&#125;,&#123;0x68,0x6b,0x81,0xb2,0x71,0x64,0xda,0x8b,0xf8,0xeb,0x0f,0x4b,0x70,0x56,0x9d,0x35&#125;,&#123;0x1e,0x24,0x0e,0x5e,0x63,0x58,0xd1,0xa2,0x25,0x22,0x7c,0x3b,0x01,0x21,0x78,0x87&#125;,&#123;0xd4,0x00,0x46,0x57,0x9f,0xd3,0x27,0x52,0x4c,0x36,0x02,0xe7,0xa0,0xc4,0xc8,0x9e&#125;,&#123;0xea,0xbf,0x8a,0xd2,0x40,0xc7,0x38,0xb5,0xa3,0xf7,0xf2,0xce,0xf9,0x61,0x15,0xa1&#125;,&#123;0xe0,0xae,0x5d,0xa4,0x9b,0x34,0x1a,0x55,0xad,0x93,0x32,0x30,0xf5,0x8c,0xb1,0xe3&#125;,&#123;0x1d,0xf6,0xe2,0x2e,0x82,0x66,0xca,0x60,0xc0,0x29,0x23,0xab,0x0d,0x53,0x4e,0x6f&#125;,&#123;0xd5,0xdb,0x37,0x45,0xde,0xfd,0x8e,0x2f,0x03,0xff,0x6a,0x72,0x6d,0x6c,0x5b,0x51&#125;,&#123;0x8d,0x1b,0xaf,0x92,0xbb,0xdd,0xbc,0x7f,0x11,0xd9,0x5c,0x41,0x1f,0x10,0x5a,0xd8&#125;,&#123;0x0a,0xc1,0x31,0x88,0xa5,0xcd,0x7b,0xbd,0x2d,0x74,0xd0,0x12,0xb8,0xe5,0xb4,0xb0&#125;,&#123;0x89,0x69,0x97,0x4a,0x0c,0x96,0x77,0x7e,0x65,0xb9,0xf1,0x09,0xc5,0x6e,0xc6,0x84&#125;,&#123;0x18,0xf0,0x7d,0xec,0x3a,0xdc,0x4d,0x20,0x79,0xee,0x5f,0x3e,0xd7,0xcb,0x39,0x48&#125;&#125;;/* System parameter */static const unsigned long FK[4] = &#123;0xa3b1bac6,0x56aa3350,0x677d9197,0xb27022dc&#125;;/* fixed parameter */static const unsigned long CK[32] =&#123;0x00070e15,0x1c232a31,0x383f464d,0x545b6269,0x70777e85,0x8c939aa1,0xa8afb6bd,0xc4cbd2d9,0xe0e7eef5,0xfc030a11,0x181f262d,0x343b4249,0x50575e65,0x6c737a81,0x888f969d,0xa4abb2b9,0xc0c7ced5,0xdce3eaf1,0xf8ff060d,0x141b2229,0x30373e45,0x4c535a61,0x686f767d,0x848b9299,0xa0a7aeb5,0xbcc3cad1,0xd8dfe6ed,0xf4fb0209,0x10171e25,0x2c333a41,0x484f565d,0x646b7279&#125;;/* * private function: * look up in SboxTable and get the related value. * args: [in] inch: 0x00~0xFF (8 bits unsigned value). */static unsigned char sm4Sbox(unsigned char inch)&#123; unsigned char *pTable = (unsigned char *)SboxTable; unsigned char retVal = (unsigned char)(pTable[inch]); return retVal;&#125;/* * private F(Lt) function: * &quot;T algorithm&quot; == &quot;L algorithm&quot; + &quot;t algorithm&quot;. * args: [in] a: a is a 32 bits unsigned value; * return: c: c is calculated with line algorithm &quot;L&quot; and nonline algorithm &quot;t&quot; */static unsigned long sm4Lt(unsigned long ka)&#123; unsigned long bb = 0; unsigned long c = 0; unsigned char a[4]; unsigned char b[4]; PUT_ULONG_BE(ka,a,0) b[0] = sm4Sbox(a[0]); b[1] = sm4Sbox(a[1]); b[2] = sm4Sbox(a[2]); b[3] = sm4Sbox(a[3]); GET_ULONG_BE(bb,b,0) c =bb^(ROTL(bb, 2))^(ROTL(bb, 10))^(ROTL(bb, 18))^(ROTL(bb, 24)); return c;&#125;/* * private F function: * Calculating and getting encryption/decryption contents. * args: [in] x0: original contents; * args: [in] x1: original contents; * args: [in] x2: original contents; * args: [in] x3: original contents; * args: [in] rk: encryption/decryption key; * return the contents of encryption/decryption contents. */static unsigned long sm4F(unsigned long x0, unsigned long x1, unsigned long x2, unsigned long x3, unsigned long rk)&#123; return (x0^sm4Lt(x1^x2^x3^rk));&#125;/* private function: * Calculating round encryption key. * args: [in] a: a is a 32 bits unsigned value; * return: sk[i]: i&#123;0,1,2,3,...31&#125;. */static unsigned long sm4CalciRK(unsigned long ka)&#123; unsigned long bb = 0; unsigned long rk = 0; unsigned char a[4]; unsigned char b[4]; PUT_ULONG_BE(ka,a,0) b[0] = sm4Sbox(a[0]); b[1] = sm4Sbox(a[1]); b[2] = sm4Sbox(a[2]); b[3] = sm4Sbox(a[3]); GET_ULONG_BE(bb,b,0) rk = bb^(ROTL(bb, 13))^(ROTL(bb, 23)); return rk;&#125;static void sm4_setkey( unsigned long SK[32], unsigned char key[16] )&#123; unsigned long MK[4]; unsigned long k[36]; unsigned long i = 0; GET_ULONG_BE( MK[0], key, 0 ); GET_ULONG_BE( MK[1], key, 4 ); GET_ULONG_BE( MK[2], key, 8 ); GET_ULONG_BE( MK[3], key, 12 ); k[0] = MK[0]^FK[0]; k[1] = MK[1]^FK[1]; k[2] = MK[2]^FK[2]; k[3] = MK[3]^FK[3]; for(; i&lt;32; i++) &#123; k[i+4] = k[i] ^ (sm4CalciRK(k[i+1]^k[i+2]^k[i+3]^CK[i])); SK[i] = k[i+4]; &#125;&#125;/* * SM4 standard one round processing * */static void sm4_one_round( unsigned long sk[32], unsigned char input[16], unsigned char output[16] )&#123; unsigned long i = 0; unsigned long ulbuf[36]; memset(ulbuf, 0, sizeof(ulbuf)); GET_ULONG_BE( ulbuf[0], input, 0 ) GET_ULONG_BE( ulbuf[1], input, 4 ) GET_ULONG_BE( ulbuf[2], input, 8 ) GET_ULONG_BE( ulbuf[3], input, 12 ) while(i&lt;32) &#123; ulbuf[i+4] = sm4F(ulbuf[i], ulbuf[i+1], ulbuf[i+2], ulbuf[i+3], sk[i]);// #ifdef _DEBUG// printf(&quot;rk(%02d) = 0x%08x, X(%02d) = 0x%08x \\n&quot;,i,sk[i], i, ulbuf[i+4] );// #endif i++; &#125; PUT_ULONG_BE(ulbuf[35],output,0); PUT_ULONG_BE(ulbuf[34],output,4); PUT_ULONG_BE(ulbuf[33],output,8); PUT_ULONG_BE(ulbuf[32],output,12);&#125;/* * SM4 key schedule (128-bit, encryption) */void sm4_setkey_enc( sm4_context *ctx, unsigned char key[16] )&#123; ctx-&gt;mode = SM4_ENCRYPT; sm4_setkey( ctx-&gt;sk, key );&#125;/* * SM4 key schedule (128-bit, decryption) */void sm4_setkey_dec( sm4_context *ctx, unsigned char key[16] )&#123; int i; ctx-&gt;mode = SM4_ENCRYPT; sm4_setkey( ctx-&gt;sk, key ); for( i = 0; i &lt; 16; i ++ ) &#123; SWAP( ctx-&gt;sk[ i ], ctx-&gt;sk[ 31-i] ); &#125;&#125;/* * SM4-ECB block encryption/decryption */void sm4_crypt_ecb( sm4_context *ctx, int mode, int length, unsigned char *input, unsigned char *output)&#123; while( length &gt; 0 ) &#123; sm4_one_round( ctx-&gt;sk, input, output ); input += 16; output += 16; length -= 16; &#125;&#125;/* * SM4-CBC buffer encryption/decryption */void sm4_crypt_cbc( sm4_context *ctx, int mode, int length, unsigned char iv[16], unsigned char *input, unsigned char *output )&#123; int i; unsigned char temp[16]; if( mode == SM4_ENCRYPT ) &#123; while( length &gt; 0 ) &#123; for( i = 0; i &lt; 16; i++ ) output[i] = (unsigned char)( input[i] ^ iv[i] ); sm4_one_round( ctx-&gt;sk, output, output ); memcpy( iv, output, 16 ); input += 16; output += 16; length -= 16; &#125; &#125; else /* SM4_DECRYPT */ &#123; while( length &gt; 0 ) &#123; memcpy( temp, input, 16 ); sm4_one_round( ctx-&gt;sk, input, output ); for( i = 0; i &lt; 16; i++ ) output[i] = (unsigned char)( output[i] ^ iv[i] ); memcpy( iv, temp, 16 ); input += 16; output += 16; length -= 16; &#125; &#125;&#125; sm4.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * \\file sm4.h */#ifndef _SM4_H_#define _SM4_H_#include &quot;includes.h&quot;#include &quot;tools.h&quot;#define SM4_ENCRYPT 1#define SM4_DECRYPT 0/** * \\brief SM4 context structure */typedef struct&#123; int mode; /*!&lt; encrypt/decrypt */ unsigned long sk[32]; /*!&lt; SM4 subkeys */&#125;sm4_context;#ifdef __cplusplusextern &quot;C&quot; &#123;#endif/** * \\brief SM4 key schedule (128-bit, encryption) * * \\param ctx SM4 context to be initialized * \\param key 16-byte secret key */void sm4_setkey_enc( sm4_context *ctx, unsigned char key[16] );/** * \\brief SM4 key schedule (128-bit, decryption) * * \\param ctx SM4 context to be initialized * \\param key 16-byte secret key */void sm4_setkey_dec( sm4_context *ctx, unsigned char key[16] );/** * \\brief SM4-ECB block encryption/decryption * \\param ctx SM4 context * \\param mode SM4_ENCRYPT or SM4_DECRYPT * \\param length length of the input data * \\param input input block * \\param output output block */void sm4_crypt_ecb( sm4_context *ctx, int mode, int length, unsigned char *input, unsigned char *output);/** * \\brief SM4-CBC buffer encryption/decryption * \\param ctx SM4 context * \\param mode SM4_ENCRYPT or SM4_DECRYPT * \\param length length of the input data * \\param iv initialization vector (updated after use) * \\param input buffer holding the input data * \\param output buffer holding the output data */void sm4_crypt_cbc( sm4_context *ctx, int mode, int length, unsigned char iv[16], unsigned char *input, unsigned char *output );#ifdef __cplusplus&#125;#endif#endif /* sm4.h */","categories":[{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/tags/算法/"},{"name":"SM4","slug":"SM4","permalink":"https://lives.xtcgch.ink/tags/SM4/"}],"keywords":[{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/categories/算法/"}]},{"title":"【专项】 数据库之MySQL缓存","slug":"数据库之MySQL缓存-20211011","date":"2021-10-11T15:17:15.000Z","updated":"2021-10-11T15:41:47.839Z","comments":true,"path":"2021/10/11/数据库之MySQL缓存/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/11/数据库之MySQL缓存/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 其他模板的标题 MySQL查询缓存MySQL缓存规则缓存机制 开启了缓存，MySQL Server会自动将查询语句和结果集返回到内存，下次再查直接从内存中取 缓存的结果是通过sessions共享的，所以一个client查询的缓存结果，另一个client也可以使用 MySQL Query Cache内容为 select 的结果集, cache 使用完整的SQL字符串做 key, 并区分大小写，空格等。即两个SQL必须完全一致才会导致cache命中。即检查查询缓存时，MySQL Server不会对SQL做任何处理，它精确的使用客户端传来的查询，只要字符大小写或注释有点不同，查询缓存就认为是不同的查询 prepared statement永远不会cache到结果，即使参数完全一样。在 5.1 之后会得到改善 where条件中如包含任何一个不确定的函数将永远不会被cache, 比如current_date, now等 date 之类的函数如果返回是以小时或天级别的，最好先算出来再传进去 太大的result set不会被cache (&lt; query_cache_limit) MySQL缓存在分库分表环境下是不起作用的 执行SQL里有触发器,自定义函数时，MySQL缓存也是不起作用的 缓存失效 在表的结构或数据发生改变时，查询缓存中的数据不再有效。如INSERT、UPDATE、 DELETE、TRUNCATE、ALTER TABLE、DROP TABLE或DROP DATABASE会导致缓存数据失效。所以查询缓存适合有大量相同查询的应用，不适合有大量数据更新的应用 一旦表数据进行任何一行的修改，基于该表相关cache立即全部失效 缓存机制中的内存管理 如何配置和缓存MySQL缓存 开启缓存 12mysql&gt; set global query_cache_size = 600000; --设置缓存内存大小mysql&gt; set global query_cache_type = ON; --开启查询缓存 关闭缓存 12mysql&gt; set global query_cache_size = 0; --设置缓存内存大小为0， 即初始化是不分配缓存内存mysql&gt; set global query_cache_type = OFF; --关闭查询缓存 MySQL缓存的优缺点 优点Query Cache的查询，发生在MySQL接收到客户端的查询请求、查询权限验证之后和查询SQL解析之前。也就是说，当MySQL接收到客户端的查询SQL之后，仅仅只需要对其进行相应的权限验证之后，就会通过Query Cache来查找结果，甚至都不需要经过Optimizer模块进行执行计划的分析优化，更不需要发生任何存储引擎的交互。由于Query Cache是基于内存的，直接从内存中返回相应的查询结果，因此减少了大量的磁盘I/O和CPU计算，导致效率非常高 缺点 查询语句的hash计算和hash查找带来的资源消耗。如果将query_cache_type设置为1（也就是ON），那么MySQL会对每条接收到的SELECT类型的查询进行hash计算，然后查找这个查询的缓存结果是否存在。虽然hash计算和查找的效率已经足够高了，一条查询语句所带来的开销可以忽略，但一旦涉及到高并发，有成千上万条查询语句时，hash计算和查找所带来的开销就必须重视了 Query Cache的失效问题。如果表的变更比较频繁，则会造成Query Cache的失效率非常高。表的变更不仅仅指表中的数据发生变化，还包括表结构或者索引的任何变化 查询语句不同，但查询结果相同的查询都会被缓存，这样便会造成内存资源的过度消耗。查询语句的字符大小写、空格或者注释的不同，Query Cache都会认为是不同的查询（因为他们的hash值会不同） 相关系统变量设置不合理会造成大量的内存碎片，这样便会导致Query Cache频繁清理内存 MySQL缓存对性能的影响 MySQL缓存适用场景 1、查询缓存可以降低查询执行的时间，但是却不能减少查询结果传输的网络消耗，如果网络传输消耗是整个查询过程的主要瓶颈，那么查询缓存的作用也很小 2、对于那些需要消耗大量资源的查询通常都是非常适合缓存的，对于复杂的SELECT语句都可以使用查询缓存，不过需要注意的是，涉及表上的UPDATE、DELETE、INSERT操作相比SELECT来说要非常少才行 3、查询缓存命中率：Qcache_hits/(Qcahce_hits+Com_select)，查询缓存命中率多大才是好的命中率，需要具体情况具体分析。只要查询缓存带来的效率提升大于查询缓存带来的额外消耗，即使30%的命中率也是值得。另外，缓存了哪些查询也很重要，如果被缓存的查询本身消耗巨大，那么即使缓存命中率低，对系统性能提升仍然是有好处的。 4、任何SELECT语句没有从查询缓存中返回都称为“缓存未命中”，以如下列情况： 查询语句无法被缓存，可能因为查询中包含一个不确定的函数，或者查询结果太大而无法缓存 MySQL从未处理这个查询，所以结果也从不曾被缓存过 虽然之前缓存了查询结果，但由于查询缓存的内存用完了，MYSQL需要删除某些缓存，或者由于数据表被修改导致缓存失效 如果服务器上有大量缓存缓存未命中，但是实际上绝大查询都被缓存了，那么一定是有如下情况发生： 查询缓存还没有完成预热，即MySQL还没有机会将查询结果都缓存起来 查询语句之前从未执行过。如果应用程序不会重复执行一条查询语句，那么即使完成预热仍然会有很多缓存未命中 缓存失效操作太多，缓存碎片、内存不足、数据修改都会造成缓存失效。可以通过参数Com_*来查看数据修改的情况（包括Com_update，Com_delete等），还可以通过Qcache_lowmem_prunes来查看有多少次失效是由于内存不足导致的 5、有一个直观的方法能够反映查询缓存是否对系统有好处，推荐一个指标：”命中和写入“的比率，即Qcache_hits和Qcache_inserts的比值。根据经验来看，当这个比值大于3：1时通常查询缓存是有效的，如果能达到10：1最好 6、通常可以通过观察查询缓存内存的实际使用情况Qcache_free_memory，来确定是否需要缩小或者扩大查询缓存 总结 适用查询类的应用： 如博客","categories":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"},{"name":"MySQL","slug":"MySQL","permalink":"https://lives.xtcgch.ink/tags/MySQL/"},{"name":"缓存","slug":"缓存","permalink":"https://lives.xtcgch.ink/tags/缓存/"}],"keywords":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}]},{"title":"Linux之CentOS7环境检测","slug":"Linux之CentOS7环境检测-20211011","date":"2021-10-11T13:06:55.000Z","updated":"2021-10-11T14:23:36.807Z","comments":true,"path":"2021/10/11/Linux之CentOS7环境检测/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/11/Linux之CentOS7环境检测/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 CentOS7系统检测和加固脚本 系统检测脚本： CentOS_Check_Script.sh 转自https://github.com/xiaoyunjie/Shell_Script 123#包含2个文件CentOS_Check_Script.shREADME.txt 操作 12#执行CentOS-Check_Script.sh脚本文件进行检查,命令格式如下 sh CentOS_Check_Script.sh | tee check_`date +%Y%m%d_%H%M%S`.txt 此检查脚本包含以下几块内容： 系统基本信息 资源使用情况 系统用户情况 身份鉴别安全 访问控制安全 安全审计 剩余信息保护 入侵防范安全 恶意代码防范 资源控制安全 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303#!/bin/bash##Filename: CentOS_Check_Script.sh##Date: 2019-03-01##Description: Security detection scriptecho &quot;##########################################################################&quot;echo &quot;# #&quot;echo &quot;# Epoint health check script #&quot;echo &quot;# #&quot;echo &quot;#警告:本脚本只是一个检查的操作,未对服务器做任何修改,管理员可以根据此报告 #&quot;echo &quot;#进行相应的安全整改 #&quot;echo &quot;##########################################################################&quot;echo &quot; &quot;#read -p &quot;=====================Are You Ready,Please press enter==================&quot;echo &quot; &quot;echo &quot;##########################################################################&quot;echo &quot;# #&quot;echo &quot;# 主机安全检测 #&quot;echo &quot;# #&quot;echo &quot;##########################################################################&quot;echo &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;系统基本信息&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;hostname=$(uname -n)system=$(cat /etc/os-release | grep &quot;^NAME&quot; | awk -F\\&quot; &apos;&#123;print $2&#125;&apos;)version=$(cat /etc/redhat-release | awk &apos;&#123;print $4$5&#125;&apos;)kernel=$(uname -r)platform=$(uname -p)address=$(ip addr | grep inet | grep -v &quot;inet6&quot; | grep -v &quot;127.0.0.1&quot; | awk &apos;&#123; print $2; &#125;&apos; | tr &apos;\\n&apos; &apos;\\t&apos; )cpumodel=$(cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq)cpu=$(cat /proc/cpuinfo | grep &apos;processor&apos; | sort | uniq | wc -l)machinemodel=$(dmidecode | grep &quot;Product Name&quot; | sed &apos;s/^[ \\t]*//g&apos; | tr &apos;\\n&apos; &apos;\\t&apos; )date=$(date)echo &quot;主机名: $hostname&quot;echo &quot;系统名称: $system&quot;echo &quot;系统版本: $version&quot;echo &quot;内核版本: $kernel&quot;echo &quot;系统类型: $platform&quot;echo &quot;本机IP地址: $address&quot;echo &quot;CPU型号: $cpumodel&quot;echo &quot;CPU核数: $cpu&quot;echo &quot;机器型号: $machinemodel&quot;echo &quot;系统时间: $date&quot;echo &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;资源使用情况&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;summemory=$(free -h |grep &quot;Mem:&quot; | awk &apos;&#123;print $2&#125;&apos;)freememory=$(free -h |grep &quot;Mem:&quot; | awk &apos;&#123;print $4&#125;&apos;)usagememory=$(free -h |grep &quot;Mem:&quot; | awk &apos;&#123;print $3&#125;&apos;)uptime=$(uptime | awk &apos;&#123;print $2&quot; &quot;$3&quot; &quot;$4&quot; &quot;$5&#125;&apos; | sed &apos;s/,$//g&apos;)loadavg=$(uptime | awk &apos;&#123;print $9&quot; &quot;$10&quot; &quot;$11&quot; &quot;$12&quot; &quot;$13&#125;&apos;)echo &quot;总内存大小: $summemory&quot;echo &quot;已使用内存大小: $usagememory&quot;echo &quot;可使用内存大小: $freememory&quot;echo &quot;系统运行时间: $uptime&quot;echo &quot;系统负载: $loadavg&quot;echo &quot;=============================dividing line================================&quot;echo &quot;内存状态:&quot;vmstat 2 5echo &quot;=============================dividing line================================&quot;echo &quot;僵尸进程:&quot;ps -ef | grep zombie | grep -v grepif [ $? == 1 ];then echo &quot;&gt;&gt;&gt;无僵尸进程&quot;else echo &quot;&gt;&gt;&gt;有僵尸进程------[需调整]&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;耗CPU最多的进程:&quot;ps auxf |sort -nr -k 3 |head -5echo &quot;=============================dividing line================================&quot;echo &quot;耗内存最多的进程:&quot;ps auxf |sort -nr -k 4 |head -5echo &quot;=============================dividing line================================&quot;echo &quot;环境变量:&quot;envecho &quot;=============================dividing line================================&quot;echo &quot;路由表:&quot;route -necho &quot;=============================dividing line================================&quot;echo &quot;监听端口:&quot;netstat -tunlpecho &quot;=============================dividing line================================&quot;echo &quot;当前建立的连接:&quot;netstat -n | awk &apos;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&apos;echo &quot;=============================dividing line================================&quot;echo &quot;开机启动的服务:&quot;systemctl list-unit-files | grep enabledecho &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;系统用户情况&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;echo &quot;活动用户:&quot;w | tail -n +2echo &quot;=============================dividing line================================&quot;echo &quot;系统所有用户:&quot;cut -d: -f1,2,3,4 /etc/passwdecho &quot;=============================dividing line================================&quot;echo &quot;系统所有组:&quot;cut -d: -f1,2,3 /etc/groupecho &quot;=============================dividing line================================&quot;echo &quot;当前用户的计划任务:&quot;crontab -lecho &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;身份鉴别安全&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;grep -i &quot;^password.*requisite.*pam_cracklib.so&quot; /etc/pam.d/system-auth &gt; /dev/nullif [ $? == 0 ];then echo &quot;&gt;&gt;&gt;密码复杂度:已设置&quot;else grep -i &quot;pam_pwquality\\.so&quot; /etc/pam.d/system-auth &gt; /dev/null if [ $? == 0 ];then echo &quot;&gt;&gt;&gt;密码复杂度:已设置&quot; else echo &quot;&gt;&gt;&gt;密码复杂度:未设置,请加固密码--------[需调整]&quot; fifiecho &quot;=============================dividing line================================&quot;awk -F&quot;:&quot; &apos;&#123;if($2!~/^!|^*/)&#123;print &quot;&gt;&gt;&gt;(&quot;$1&quot;)&quot; &quot; 是一个未被锁定的账户,请管理员检查是否是可疑账户--------[需调整]&quot;&#125;&#125;&apos; /etc/shadowecho &quot;=============================dividing line================================&quot;more /etc/login.defs | grep -E &quot;PASS_MAX_DAYS&quot; | grep -v &quot;#&quot; |awk -F&apos; &apos; &apos;&#123;if($2!=90)&#123;print &quot;&gt;&gt;&gt;密码过期天数是&quot;$2&quot;天,请管理员改成90天------[需调整]&quot;&#125;&#125;&apos;echo &quot;=============================dividing line================================&quot;grep -i &quot;^auth.*required.*pam_tally2.so.*$&quot; /etc/pam.d/sshd &gt; /dev/nullif [ $? == 0 ];then echo &quot;&gt;&gt;&gt;登入失败处理:已开启&quot;else echo &quot;&gt;&gt;&gt;登入失败处理:未开启,请加固登入失败锁定功能----------[需调整]&quot;fiecho &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;访问控制安全&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;echo &quot;系统中存在以下非系统默认用户:&quot;more /etc/passwd |awk -F &quot;:&quot; &apos;&#123;if($3&gt;500)&#123;print &quot;&gt;&gt;&gt;/etc/passwd里面的&quot;$1 &quot;的UID为&quot;$3&quot;，该账户非系统默认账户，请管理员确认是否为可疑账户--------[需调整]&quot;&#125;&#125;&apos;echo &quot;=============================dividing line================================&quot;echo &quot;系统特权用户:&quot;awk -F: &apos;$3==0 &#123;print $1&#125;&apos; /etc/passwdecho &quot;=============================dividing line================================&quot;echo &quot;系统中空口令账户:&quot;awk -F: &apos;($2==&quot;!!&quot;) &#123;print $1&quot;该账户为空口令账户，请管理员确认是否为新增账户，如果为新建账户，请配置密码-------[需调整]&quot;&#125;&apos; /etc/shadowecho &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;安全审计&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;echo &quot;正常情况下登录到本机30天内的所有用户的历史记录:&quot;last | head -n 30echo &quot;=============================dividing line================================&quot;echo &quot;查看syslog日志审计服务是否开启:&quot;if service rsyslog status | egrep &quot; active \\(running&quot;;then echo &quot;&gt;&gt;&gt;经分析,syslog服务已开启&quot;else echo &quot;&gt;&gt;&gt;经分析,syslog服务未开启，建议通过service rsyslog start开启日志审计功能---------[需调整]&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;查看syslog日志是否开启外发:&quot;if more /etc/rsyslog.conf | egrep &quot;@...\\.|@..\\.|@.\\.|\\*.\\* @...\\.|\\*\\.\\* @..\\.|\\*\\.\\* @.\\.&quot;;then echo &quot;&gt;&gt;&gt;经分析,客户端syslog日志已开启外发--------[需调整]&quot;else echo &quot;&gt;&gt;&gt;经分析,客户端syslog日志未开启外发---------[无需调整]&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;审计的要素和审计日志:&quot;more /etc/rsyslog.conf | grep -v &quot;^[$|#]&quot; | grep -v &quot;^$&quot;echo &quot;=============================dividing line================================&quot;echo &quot;系统中关键文件修改时间:&quot;ls -ltr /bin/ls /bin/login /etc/passwd /bin/ps /etc/shadow|awk &apos;&#123;print &quot;&gt;&gt;&gt;文件名：&quot;$9&quot; &quot;&quot;最后修改时间：&quot;$6&quot; &quot;$7&quot; &quot;$8&#125;&apos;echo &quot;################################################################################################ ls文件:是存储ls命令的功能函数,被删除以后,就无法执行ls命令 ## login文件:login是控制用户登录的文件,一旦被篡改或删除,系统将无法切换用户或登陆用户 ## /etc/passwd是一个文件,主要是保存用户信息 ## /bin/ps 进程查看命令功能支持文件,文件损坏或被更改后,无法正常使用ps命令 ## /etc/shadow是/etc/passwd的影子文件,密码存放在该文件当中,并且只有root用户可读 ################################################################################################&quot;echo &quot;=============================dividing line================================&quot;echo &quot;检查重要日志文件是否存在:&quot;log_secure=/var/log/securelog_messages=/var/log/messageslog_cron=/var/log/cronlog_boot=/var/log/boot.loglog_dmesg=/var/log/dmesgif [ -e &quot;$log_secure&quot; ]; then echo &quot;&gt;&gt;&gt;/var/log/secure日志文件存在&quot;else echo &quot;&gt;&gt;&gt;/var/log/secure日志文件不存在------[需调整]&quot;fiif [ -e &quot;$log_messages&quot; ]; then echo &quot;&gt;&gt;&gt;/var/log/messages日志文件存在&quot;else echo &quot;&gt;&gt;&gt;/var/log/messages日志文件不存在------[需调整]&quot;fiif [ -e &quot;$log_cron&quot; ]; then echo &quot;&gt;&gt;&gt;/var/log/cron日志文件存在&quot;else echo &quot;&gt;&gt;&gt;/var/log/cron日志文件不存在--------[需调整]&quot;fiif [ -e &quot;$log_boot&quot; ]; then echo &quot;&gt;&gt;&gt;/var/log/boot.log日志文件存在&quot;else echo &quot;&gt;&gt;&gt;/var/log/boot.log日志文件不存在--------[需调整]&quot;fiif [ -e &quot;$log_dmesg&quot; ]; then echo &quot;&gt;&gt;&gt;/var/log/dmesg日志文件存在&quot;else echo &quot;&gt;&gt;&gt;/var/log/dmesg日志文件不存在--------[需调整]&quot;fiecho &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;剩余信息保护&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;echo &quot;分区情况:&quot;echo &quot;如果磁盘空间利用率过高，请及时调整---------[需调整]&quot;df -hecho &quot;=============================dividing line================================&quot;echo &quot;可用块设备信息:&quot;lsblkecho &quot;=============================dividing line================================&quot;echo &quot;文件系统信息:&quot;more /etc/fstab | grep -v &quot;^#&quot; | grep -v &quot;^$&quot;echo &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;入侵防范安全&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;echo &quot;系统入侵行为:&quot;more /var/log/secure |grep refusedif [ $? == 0 ];then echo &quot;有入侵行为，请分析处理--------[需调整]&quot;else echo &quot;&gt;&gt;&gt;无入侵行为&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;用户错误登入列表:&quot;lastb | head &gt; /dev/nullif [ $? == 1 ];then echo &quot;&gt;&gt;&gt;无用户错误登入列表&quot;else echo &quot;&gt;&gt;&gt;用户错误登入--------[需调整]&quot; lastb | head fiecho &quot;=============================dividing line================================&quot;echo &quot;ssh暴力登入信息:&quot;more /var/log/secure | grep &quot;Failed&quot; &gt; /dev/nullif [ $? == 1 ];then echo &quot;&gt;&gt;&gt;无ssh暴力登入信息&quot;else more /var/log/secure|awk &apos;/Failed/&#123;print $(NF-3)&#125;&apos;|sort|uniq -c|awk &apos;&#123;print &quot;&gt;&gt;&gt;登入失败的IP和尝试次数: &quot;$2&quot;=&quot;$1&quot;次---------[需调整]&quot;;&#125;&apos;fiecho &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;恶意代码防范&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;echo &quot;检查是否安装病毒软件:&quot;crontab -l | grep clamscan.sh &gt; /dev/nullif [ $? == 0 ];then echo &quot;&gt;&gt;&gt;已安装ClamAV杀毒软件&quot; crontab -l | grep freshclam.sh &gt; /dev/null if [ $? == 0 ];then echo &quot;&gt;&gt;&gt;已部署定时更新病毒库&quot; fielse echo &quot;&gt;&gt;&gt;未安装ClamAV杀毒软件,请部署杀毒软件加固主机防护--------[无需调整]&quot;fiecho &quot; &quot;echo &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;资源控制安全&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot;echo &quot;查看是否开启了xinetd服务:&quot;if ps -elf |grep xinet |grep -v &quot;grep xinet&quot;;then echo &quot;&gt;&gt;&gt;xinetd服务正在运行，请检查是否可以把xinetd服务关闭--------[无需调整]&quot;else echo &quot;&gt;&gt;&gt;xinetd服务未开启-------[无需调整]&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;查看是否开启了ssh服务:&quot;if service sshd status | grep -E &quot;listening on|active \\(running\\)&quot;; then echo &quot;&gt;&gt;&gt;SSH服务已开启&quot;else echo &quot;&gt;&gt;&gt;SSH服务未开启--------[需调整]&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;查看是否开启了Telnet-Server服务:&quot;if more /etc/xinetd.d/telnetd 2&gt;&amp;1|grep -E &quot;disable=no&quot;; then echo &quot;&gt;&gt;&gt;Telnet-Server服务已开启&quot;else echo &quot;&gt;&gt;&gt;Telnet-Server服务未开启--------[无需调整]&quot;fiecho &quot;=============================dividing line================================&quot;ps axu | grep iptables | grep -v grep || ps axu | grep firewalld | grep -v grep if [ $? == 0 ];then echo &quot;&gt;&gt;&gt;防火墙已启用&quot;iptables -nvL --line-numberselse echo &quot;&gt;&gt;&gt;防火墙未启用--------[需调整]&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;查看系统SSH远程访问设置策略(host.deny拒绝列表):&quot;if more /etc/hosts.deny | grep -E &quot;sshd&quot;; then echo &quot;&gt;&gt;&gt;远程访问策略已设置--------[需调整]&quot;else echo &quot;&gt;&gt;&gt;远程访问策略未设置--------[无需调整]&quot;fiecho &quot;=============================dividing line================================&quot;echo &quot;查看系统SSH远程访问设置策略(hosts.allow允许列表):&quot;if more /etc/hosts.allow | grep -E &quot;sshd&quot;; then echo &quot;&gt;&gt;&gt;远程访问策略已设置--------[需调整]&quot;else echo &quot;&gt;&gt;&gt;远程访问策略未设置--------[无需调整]&quot;fi echo &quot;=============================dividing line================================&quot;echo &quot;当hosts.allow和host.deny相冲突时,以hosts.allow设置为准&quot;echo &quot;=============================dividing line================================&quot;grep -i &quot;TMOUT&quot; /etc/profile /etc/bashrcif [ $? == 0 ];then echo &quot;&gt;&gt;&gt;已设置登入超时限制&quot;else echo &quot;&gt;&gt;&gt;未设置登入超时限制,请设置,设置方法:在/etc/profile或者/etc/bashrc里面添加参数TMOUT=600 --------[需调整]&quot;fiecho &quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;end&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&quot; 加固脚本： Protective_Script.sh 转自https://github.com/xiaoyunjie/Shell_Script 一键进行全部加固 设置密码复杂度 添加eproot账号 禁止root远程登入 设置history保存行数以及命令时间，设置窗口超时时间 更改SSH端口 登入失败处理 还原配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412#!/bin/bash##Filename: OS-centOS-Protective_v0.1.sh##Author: Browser##Date: 2019-02-24##Description: Operating system security reinforcement#########################variables############################restart_flag=1ostype=&apos;unknow&apos;###########################ostype############################if [ -f /etc/redhat-release ];then grep -i &apos;centos&apos; /etc/redhat-release &gt; /dev/null if [ $? == 0 ];then ostype=&apos;centos&apos; fi grep -i &apos;redhat&apos; /etc/redhat-release &gt; /dev/null if [ $? == 0 ];then ostype=&apos;redhat&apos; fifiif [ -f /etc/centos-release ];then grep -i &apos;centos&apos; /etc/centos-release &gt; /dev/null if [ $? == 0 ];then ostype=&apos;centos&apos; fifi echo -e &quot;###########################################################################################&quot; echo -e &quot;\\033[1;31m OS type is $ostype \\033[0m&quot; echo -e &quot;###########################################################################################&quot;#######################restart_ssh################################function restart_ssh()&#123; if [ $restart_flag == 0 ];then echo -e &quot;\\033[1;31mPlease restart SSH service manully by using &apos;service sshd restart&apos; or &apos;systemctl restart sshd&apos;\\033[0m&quot; fi&#125;###########################文件备份############################function backup()&#123;if [ ! -x &quot;backup&quot; ]; then mkdir backup if [ -f /etc/pam.d/system-auth ];then cp /etc/pam.d/system-auth backup/system-auth.bak elif [ -f /etc/pam.d/common-password ];then cp /etc/pam.d/common-password backup/common-password.bak fi if [ -f ~/.ssh/authorized_keys ];then cp ~/.ssh/authorized_keys backup/authorized_keys.bak fi cp /etc/pam.d/sshd backup/sshd.bak cp /etc/sudoers backup/sudoers.bak cp /etc/ssh/sshd_config backup/sshd_config.bak cp /etc/profile backup/profile.bak cp /etc/pam.d/su backup/su.bak echo -e &quot;###########################################################################################&quot; echo -e &quot;\\033[1;31m Auto backup successfully \\033[0m&quot; echo -e &quot;###########################################################################################&quot;else echo -e &quot;###########################################################################################&quot; echo -e &quot;\\033[1;31mBackup file already exist, to avoid overwriting these files, backup will not perform again\\033[0m &quot; echo -e &quot;###########################################################################################&quot;fi&#125;###########################执行备份############################backup###########################文件还原############################function recover()&#123;if [ -f backup/system-auth.bak ];then cp -rf backup/system-auth.bak /etc/pam.d/system-authelif [ -f backup/common-password.bak ];then cp -rf backup/common-password.bak /etc/pam.d/common-passwordfiif [ -f backup/authorized_keys.bak ];then cp -rf backup/authorized_keys.bak ~/.ssh/authorized_keysfi cp -rf backup/sshd.bak /etc/pam.d/sshd cp -rf backup/sudoers.bak /etc/sudoers cp -rf backup/sshd_config.bak /etc/ssh/sshd_config cp -rf backup/profile.bak /etc/profile source /etc/profile cp -rf backup/su.bak /etc/pam.d/su restart_flag=0 echo -e &quot;\\033[1;31m 8、 Recover success \\033[0m&quot;&#125;###########################口令复杂度设置############################function password()&#123; echo &quot;#########################################################################################&quot; echo -e &quot;\\033[1;31m 2、 set password complexity requirements \\033[0m&quot; echo &quot;#########################################################################################&quot;if [ -f /etc/pam.d/system-auth ];then config=&quot;/etc/pam.d/system-auth&quot;elif [ -f /etc/pam.d/common-password ];then config=&quot;/etc/pam.d/common-password&quot;else echo -e &quot;\\033[1;31m Doesn&apos;t support this OS \\033[0m&quot; return 1fi grep -i &quot;^password.*requisite.*pam_cracklib.so&quot; $config &gt; /dev/null if [ $? == 0 ];then sed -i &quot;s/^password.*requisite.*pam_cracklib\\.so.*$/password requisite pam_cracklib.so retry=3 difok=3 minlen=12 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1/g&quot; $config echo -e &quot;\\033[1;31m密码修改重试3次机会，新密码与老密码必须有3字符不同，最小密码长度12个字符，包含大写字符至少一个，小写字母至少一个，数字至少一个，特殊字符至少一个\\033[0m&quot; else grep -i &quot;pam_pwquality\\.so&quot; $config &gt; /dev/null if [ $? == 0 ];then sed -i &quot;s/password.*requisite.*pam_pwquality\\.so.*$/password requisite pam_pwquality.so retry=3 difok=3 minlen=12 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1/g&quot; $config echo -e &quot;\\033[1;31m密码修改重试3次机会，新密码与老密码必须有3字符不同，最小密码长度12个字符，包含大写字符至少一个，小写字母至少一个，数字至少一个，特殊字符至少一个\\033[0m&quot; else echo &apos;password requisite pam_cracklib.so retry=3 difok=3 minlen=12 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1&apos; &gt;&gt; $config echo -e &quot;\\033[1;31m密码修改重试3次机会，新密码与老密码必须有3字符不同，最小密码长度12个字符，包含大写字符至少一个，小写字母至少一个，数字至少一个，特殊字符至少一个\\033[0m&quot; fi fi if [ $? == 0 ];then echo -e &quot;\\033[37;5m [Password complexity set success] \\033[0m&quot; else echo -e &quot;\\033[31;5m [Password complexity set failed] \\033[0m&quot; exit 1 fi&#125;################################新增超级管理员用户################################function create_user()&#123; echo &quot;#########################################################################################&quot; echo -e &quot;\\033[1;31m 3、Create openroot account \\033[0m&quot; echo &quot;#########################################################################################&quot; read -p &quot;Be sure to create an openroot account?[y/n]:&quot; case $REPLY in y) grep -i &apos;openroot&apos; /etc/passwd if [ $? == 0 ];then echo -e &quot;\\033[1;31m An openroot account has been created \\033[0m&quot; else read -p &quot;Please enter your password:&quot; PASSWD useradd -g root openroot;echo &quot;$PASSWD&quot; | passwd --stdin openroot &gt; /dev/null if [ $? == 0 ];then echo -e &quot;\\033[1;31m openroot account created successfully \\033[0m&quot; grep -i &quot;openroot&quot; /etc/sudoers if [ $? != 0 ];then chmod u+w /etc/sudoers &gt; /dev/null sed -i &apos;/^root.*ALL=(ALL).*$/a\\openroot ALL=(ALL) NOPASSWD:ALL&apos; /etc/sudoers &gt; /dev/null if [ $? == 0 ];then echo -e &quot;\\033[37;5m [Permissions set success] \\033[0m&quot; else echo -e &quot;\\033[31;5m [Permissions set failed] \\033[0m&quot; fi chmod u-w /etc/sudoers &gt; /dev/null else echo -e &quot;\\033[1;31m Permissions have already been set \\033[0m&quot; fi else echo -e &quot;\\033[1;31m openroot account created failed \\033[0m&quot; exit 1 fi fi ;; n) ;; *) create_user esac&#125;############################限制超级管理员用户远程登录############################function remote_login()&#123; echo &quot;#########################################################################################&quot; echo -e &quot;\\033[1;31m 4、Set Remote Login Configuration(SSH) \\033[0m&quot; echo &quot;#########################################################################################&quot;#set Protocol 2 echo &gt;&gt; /etc/ssh/sshd_config grep -i &apos;^Protocol&apos; /etc/ssh/sshd_config &gt; /dev/null if [ $? == 0 ];then sed -i &apos;s/^Protocol.*$/Protocol 2/g&apos; /etc/ssh/sshd_config if [ $? != 0 ];then echo -e &quot;\\033[31;5m [##Error##]: Cannot to set Protocol to &apos;2&apos; \\033[0m&quot; else echo -e &quot;\\033[37;5m [Success: Set SSH Protocol to 2] \\033[0m&quot; fi else echo &apos;Protocol 2&apos; &gt;&gt; /etc/ssh/sshd_config echo -e &quot;\\033[37;5m [Success: Set SSH Protocol to 2] \\033[0m&quot; fi read -p &quot;Disable root remote login?[y/n](Please make sure you have created at least one another account):&quot; case $REPLY in y) grep -i &apos;^PermitRootLogin no&apos; /etc/ssh/sshd_config &gt; /dev/null if [ $? == 1 ];then grep -i &apos;.*PermitRootLogin yes&apos; /etc/ssh/sshd_config &gt;/dev/null if [ $? == 0 ];then sed -i &apos;s/.*PermitRootLogin yes/PermitRootLogin no/g&apos; /etc/ssh/sshd_config if [ $? != 0 ];then echo -e &quot;\\033[31;5m [##Error##]cannot to set PermitRootLogin to &apos;no&apos; \\033[0m&quot; else echo -e &quot;\\033[37;5m Disable root remote login[Success] \\033[0m&quot; restart_flag=0 fi else echo &apos;PermitRootLogin no&apos; &gt;&gt; /etc/ssh/sshd_config echo -e &quot;\\033[37;5m Disable root remote login[Success] \\033[0m&quot; restart_flag=0 fi else echo -e &quot;\\033[37;5m Already disable root remote login \\033[0m&quot; fi ;; n) ;; *) remote_login ;; esac&#125;#######################配置系统历史命令操作记录和定时帐户自动登出时间################################function set_history_tmout()&#123; echo &quot;#########################################################################################&quot; echo -e &quot;\\033[1;31m 5、set history and timeout \\033[0m&quot; echo &quot;#########################################################################################&quot; read -p &quot;set history size, format, and TMOUT?[y/n]:&quot; case $REPLY in y) #history_size grep -i &quot;^HISTSIZE=&quot; /etc/profile &gt;/dev/null if [ $? == 0 ];then #history记录保留一万条 sed -i &quot;s/^HISTSIZE=.*$/HISTSIZE=10000/g&quot; /etc/profile else echo &apos;HISTSIZE=10000&apos; &gt;&gt; /etc/profile fi echo -e &quot;\\033[1;31m HISTSIZE has been set to 10000 \\033[0m&quot; #history_format grep -i &quot;^export HISTTIMEFORMAT=&quot; /etc/profile &gt; /dev/null if [ $? == 0 ];then sed -i &apos;s/^export HISTTIMEFORMAT=.*$/export HISTTIMEFORMAT=&quot;%F %T `whoami`&quot;/g&apos; /etc/profile else echo &apos;export HISTTIMEFORMAT=&quot;%F %T `whoami` &quot;&apos; &gt;&gt; /etc/profile fi echo -e &apos;\\033[1;31m HISTTIMEFORMAT has been set to &quot;Number-Time-User-Command&quot; \\033[0m&apos; #TIME_OUT read -p &quot;set shell TMOUT?[300-600]seconds:&quot; tmout : $&#123;tmout:=600&#125; grep -i &quot;^TMOUT=&quot; /etc/profile &gt; /dev/null if [ $? == 0 ];then sed -i &quot;s/^TMOUT=.*$/TMOUT=$tmout/g&quot; /etc/profile else echo &quot;TMOUT=$tmout&quot; &gt;&gt; /etc/profile fi source /etc/profile echo -e &quot;\\033[37;5m [Success] \\033[0m&quot; ;; n) ;; *) set_history_tmout;; esac&#125;#######################SSH端口配置################################function ssh_port()&#123; echo &quot;#########################################################################################&quot; echo -e &quot;\\033[1;31m 6、set ssh port \\033[0m&quot; echo &quot;#########################################################################################&quot; read -p &apos;change ssh port?[y/n]:&apos; case $REPLY in y) read -p &apos;please input the new ssh port(recommend to between 1024 and 65534, please make sure the port is not in used):&apos; port ##验证端口是否被占用 if [[ $port -gt 1024 &amp;&amp; $port -lt 65535 ]];then netstat -tlnp|awk -v port=$port &apos;&#123;lens=split($4,a,&quot;:&quot;);if(a[lens]==port)&#123;exit 2&#125;&#125;&apos; &gt;/dev/null #2&gt;&amp;1 res=$? if [ $res == 2 ];then echo -e &quot;\\033[1;31m The port $port is already in used, try again \\033[0m&quot; ssh_port elif [ $res == 1 ];then echo -e &quot;\\033[31;5m [##Error##] \\033[0m&quot; exit 1 else ##修改ssh端口 grep -i &quot;^#Port &quot; /etc/ssh/sshd_config &gt; /dev/null if [ $? == 0 ];then sed -i &quot;s/^#Port.*$/Port $port/g&quot; /etc/ssh/sshd_config else grep -i &quot;^Port &quot; /etc/ssh/sshd_config &gt; /dev/null if [ $? == 0 ];then sed -i &quot;s/^Port.*$/Port $port/g&quot; /etc/ssh/sshd_config else echo &quot;Port $port&quot; &gt;&gt; /etc/ssh/sshd_config fi fi echo -e &quot;\\033[37;5m [Success] \\033[0m&quot; restart_flag=0 fi else echo -e &quot;\\033[31;5m [##The port $port is error, please input new ssh port between 1024 and 65534 ##] \\033[0m&quot; ssh_port fi ;; n) ;; *) echo -e &quot;\\033[31;5m [##Error##]:invalid input \\033[0m&quot; ssh_port ;; esac&#125;#######################Logon failure handling################################function logon()&#123; echo &quot;#########################################################################################&quot; echo -e &quot;\\033[1;31m 7、set logon failure handling \\033[0m&quot; echo &quot;#########################################################################################&quot;logonconfig=/etc/pam.d/sshd read -p &apos;Are you sure set logon failure handling?[y/n]:&apos; case $REPLY in y) grep -i &quot;^auth.*required.*pam_tally2.so.*$&quot; $logonconfig &gt; /dev/null if [ $? == 0 ];then sed -i &quot;s/auth.*required.*pam_tally2.so.*$/auth required pam_tally2.so deny=3 unlock_time=300 even_deny_root root_unlock_time=300/g&quot; $logonconfig &gt; /dev/null else sed -i &apos;/^#%PAM-1.0/a\\auth required pam_tally2.so deny=3 unlock_time=300 even_deny_root root_unlock_time=300&apos; $logonconfig &gt; /dev/null fi if [ $? == 0 ];then echo &quot;#########################################################################################&quot; echo -e &quot;\\033[37;5m [Logon failure handling set success] \\033[0m&quot; echo -e &quot;\\033[1;31m限制登入失败三次，普通账号锁定5分钟，root账号锁定5分钟\\033[0m&quot; echo &quot;#########################################################################################&quot; else echo &quot;#########################################################################################&quot; echo -e &quot;\\033[31;5m [Logon failure handling set failed] \\033[0m&quot; echo &quot;#########################################################################################&quot; exit 1 fi ;; n) ;; *) echo -e &quot;\\033[31;5m [##Error##]:invalid input \\033[0m&quot; logon ;; esac&#125;#######################main################################function main()&#123; echo -e &quot;\\033[1;31m########################################################################################## Menu ## 1:ALL protective ## 2:Set Password Complexity Requirements ## 3:Create openroot account ## 4:Set Remote Login Configuration(SSH) ## 5:Set Shell History and TMOUT ## 6:Set SSH Port ## 7:Set Logon failure handling ## 8:Recover Configuration ## 9:Exit ########################################################################################## \\033[0m&quot; read -p &quot;Please choice[1-9]:&quot; case $REPLY in 1) password create_user remote_login set_history_tmout ssh_port logon restart_ssh ;; 2) password ;; 3) create_user ;; 4) remote_login restart_ssh ;; 5) set_history_tmout ;; 6) ssh_port restart_ssh ;; 7) logon restart_ssh ;; 8) recover restart_ssh ;; 9) exit 0 ;; *) echo -e &quot;\\033[31;5m invalid input \\033[0m&quot; main ;; esac&#125;######################main 环境检测: CheckEnv.sh 不完全转自网络… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218#!/bin/bash# 界面输出区optimize() &#123; echo &quot;----系统优化选择项目---- 1.网络信息获取 2.CPU信息获取 3.内存信息获取 4.系统基本信息 5.网络测试 0.退出监测 &quot;&#125; # 函数命令区-orderip_get()&#123; echo &quot;--网卡列表--&quot; cat /proc/net/dev | sed -n &apos;3,$p&apos; | awk -F &apos;:&apos; &#123;&apos;print $1&apos;&#125; |sed s/[[:space:]]//g|grep -v lo echo &quot;------------&quot; read -ep &quot;请选择您想要获取IP的网卡名称:&quot; wangka zw=`ifconfig |grep -n1 $wangka |grep inet|awk &apos;&#123;print $5&#125;&apos;` ip=`ifconfig |grep -n1 $wangka |grep inet|awk &apos;&#123;print $3&#125;&apos;` wg=`ifconfig |grep -n1 $wangka |grep inet|awk &apos;&#123;print $7&#125;&apos;` echo &quot;网卡 $wangka IP为: $ip &quot; echo &quot;网卡 $wangka 网关为: $wg &quot; echo &quot;网卡 $wangka 子网掩码为: $zw &quot; &#125;# cpu信息获取cpu_get()&#123; echo &quot; ----cpu查询内容---- 1.cpu的数量 2.cpu的空闲值 3.cpu的核心数 4.cpu的型号 0.返回上一层 e.直接退出监测 &quot; while : do read -ep &quot;输入您的选择项:&quot; cp case $cp in 1) cpu_shu=`cat /proc/stat | grep cpu[0-9]|wc -l` echo &quot;CPU的数量为:$cpu_shu 个&quot; ;; 2) cpu_kong=`vmstat |tail -n1|awk &apos;&#123;print $15&#125;&apos;` echo &quot;CPU空闲率为:$cpu_kong %&quot; ;; 3) cpu_he=`cat /proc/cpuinfo |grep &quot;cores&quot;|head -n1|awk -F &apos;: &apos; &apos;&#123;print $2&#125;&apos;` echo &quot;CPU核心数:$cpu_he 个&quot; ;; 4) cpu_xing=`grep &quot;model name&quot; /proc/cpuinfo|sort|uniq|awk -F: &apos;&#123;print $2&#125;&apos;|sed s/[[:space:]]//g` echo &quot;CPU的型号:$cpu_xing&quot; ;; 0) break ;; e) exit ;; *) echo &quot;选项输出有误,从新输入&quot; esac done&#125;# 内存信息获取mem_get()&#123; echo &quot; --- 内存信息选项--- 1.系统总物理内存 2.系统总交换内存 3.系统以使用内存 4.系统剩余内存 0.返回上一级 e.直接退出监测 &quot; while : do read -ep &quot;输入您的选择项:&quot; cp case $cp in 1) free_wu=`free -h|grep Mem|awk &#123;&apos;print $2&apos;&#125;` echo &quot;系统总物理内存:$free_wu&quot; ;; 2) free_jiao=`free -h|grep Swap|awk &#123;&apos;print $2&apos;&#125;` echo &quot;系统总交换内存:$free_jiao&quot; ;; 3) free_yong=`free -m|grep Mem|awk &#123;&apos;print $3&apos;&#125;` echo &quot;系统以使用内存:$free_yong M&quot; ;; 4) free_yu=`free -m|grep Mem|awk &#123;&apos;print $4&apos;&#125;` echo &quot;系统剩余内存:$free_yu M&quot; ;; 0) break ;; e) exit ;; *) echo &quot;选项输出有误,从新输入&quot; esac done&#125;#系统基本信息centos_get()&#123; echo &quot; ---系统信息选项--- 1.系统类型 2.系统版本 3.系统内核 4.本机名称 5.当前时间 6.运行时长 7.启动时间 0.返回上一级 e.直接退出监测 &quot; while : do read -ep &quot;输入您的选择项:&quot; cp case $cp in 1) os_lei=`uname` echo &quot;系统类型:$os_lei&quot; ;; 2) os_ban=`cat /etc/redhat-release` echo &quot;系统版本:$os_ban&quot; ;; 3) os_he=`uname -a|awk &apos;&#123;print $3&#125;&apos;` echo &quot;系统内核:$os_he&quot; ;; 4) host=`hostname` echo &quot;本机名称:$host&quot; ;; 5) date_dang=`date +%F_%T` echo &quot;系统当前时间:$date_dang&quot; ;; 6) date_yun=`uptime |awk &apos;&#123;print $3&#125;&apos;|awk -F, &apos;&#123;print $1&#125;&apos;` echo &quot;系统运行时长:$date_yun&quot; ;; 7) date_xi=`who -b|awk &apos;&#123;print $2,$3&#125;&apos;` echo &quot;系统启动时间:$date_xi&quot; ;; 8) who_i=`who |wc -l` echo &quot;系统登陆用户数:$who_i 个 &quot; ;; 0) break ;; e) exit ;; *) echo &quot;选项输出有误,从新输入&quot; esac done&#125;#网络wang_get()&#123; curl -I http://www.baidu.com &amp;&gt;/dev/null # 测试 if [ $? -eq 0 ];then echo &quot; 访问外网：成功&quot; else echo &quot; 访问外网：失败&quot; fi&#125; # 函数执行区-execute while :do optimize read -ep &quot;输入需要监控查看的选项:&quot; kong case $kong in 1) #IP获取 ip_get ;; 2) #CPU信息获取 cpu_get ;; 3) #内存信息获取 mem_get ;; 4) #系统基本信息 centos_get ;; 5) #网络测试 wang_get ;; 0) exit 0 ;; *) echo &quot;选项输出有误,从新输入&quot; esac done","categories":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"}],"keywords":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}]},{"title":"【专项】 数据库之日志","slug":"数据库之日志-20211011","date":"2021-10-11T13:02:18.000Z","updated":"2021-10-11T16:09:43.310Z","comments":true,"path":"2021/10/11/数据库之日志/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/11/数据库之日志/","excerpt":"摘要：本文主要介绍mysql的日志系统。","text":"摘要：本文主要介绍mysql的日志系统。 脑图 MySQL日志 bin日志 redo日志 redo日志： 物理日志 , 被称之为重做日志，是在数据库发生意外时，进行数据恢复，redo log会备份是事务执行过程中的修改数据，redo log备份的是事务过程中最新的数据位置 redo log包括两部分： 一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的 二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的 工作原理 ： 写入机制 write point：这个指针记录当前位置，一边写，一边移动，写到最后一个文件末尾后就回到 0 号文件重新覆盖写 check point：这个指针记录当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件 redo log写满时候，指针回到原点，重新开始覆盖保存，如果 write pos 追上checkpoint，表示写满，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下节点 持久策略 0：设置值为0，表示Log Buffer中的数据不经过OS缓存，直接调用fsync直接刷到磁盘文件保存 1：设置值为1（默认值），事务提交后，会保存到log buffer，接着保存到os buffer缓存，同时调用fsync同步刷到磁盘 2：设置值为2，数据不写到log buffer，直接缓存到os buffer，每隔一秒，调用fsync刷数据到磁盘 log group redo log file undo日志 undo日志： 逻辑日志,用于回滚 保证事务原子性","categories":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"}],"keywords":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}]},{"title":"开源之poco","slug":"开源之poco-20211010","date":"2021-10-10T13:45:26.000Z","updated":"2021-10-10T17:05:11.102Z","comments":true,"path":"2021/10/10/开源之poco/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/10/开源之poco/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 poco下载和安装12345git clone https://github.com/pocoproject/poco.gitcd pococmake .sudo make sudo make install 安装成功后 include路径：/usr/local/include/Poco lib路径：/usr/local/lib/libPoco*.so 配置动态库12sudo vim /etc/ld.so.conf/usr/local/lib #加入该行 退出，保存文件，刷新缓存1sudo /sbin/ldconfig -v 数据库读写用到的头文件 Poco/Data/Session.h Poco/Data/MySQL/Connector.h 数据库读写用到的动态库 PocoData PocoFoundation PocoDataMySQL 常用的编译参数1-I /usr/local/include -L /usr/local/lib/ -lPocoData -lPocoFoundation -lpthread -ldl -lrt -lPocoDataMySQL demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &quot;Poco/Data/Session.h&quot;#include &quot;Poco/Data/MySQL/Connector.h&quot;#include &lt;vector&gt;#include &lt;iostream&gt; using namespace Poco::Data::Keywords;using Poco::Data::Session;using Poco::Data::Statement; struct Person&#123; std::string name; std::string address; int age;&#125;; int main(int argc, char** argv)&#123; Poco::Data::MySQL::Connector::registerConnector(); // 创建 session Session session(&quot;MySQL&quot;, &quot;host=192.168.1.111;port=3306;db=db_test;user=xtcgch;password=123456;compress=true;auto-reconnect=true&quot;); // 删除已存在的表 session &lt;&lt; &quot;DROP TABLE IF EXISTS Person&quot;, now; // 创建新表 session &lt;&lt; &quot;CREATE TABLE Person (Name char(20),Address char(30) ,Age integer)&quot;, now;//varchar 会报错 // 插入数据 Person person = &#123; &quot;Bart Simpson&quot;, &quot;Springfield&quot;, 12 &#125;; Statement insert(session); insert &lt;&lt; &quot;INSERT INTO Person VALUES(?, ?, ?)&quot;, use(person.name), use(person.address), use(person.age); insert.execute(); person.name = &quot;Lisa Simpson&quot;; person.address = &quot;Springfield&quot;; person.age = 10; insert.execute(); //查询数据 Statement select(session); select &lt;&lt; &quot;select Name, Address, Age FROM Person&quot;, into(person.name), into(person.address), into(person.age), range(0, 1); // 只查询前两行 while (!select.done()) &#123; select.execute(); std::cout &lt;&lt; person.name &lt;&lt; &quot; &quot; &lt;&lt; person.address &lt;&lt; &quot; &quot; &lt;&lt; person.age &lt;&lt; std::endl; &#125; std::string addr = &quot;hubeilichuan&quot;; std::string name = &quot;Lisa Simpson&quot;; session &lt;&lt; &quot;update Person set Address = ? WHERE Name= ?&quot;, use(addr),use(name),now; // 另一种查询方式 std::vector&lt;std::string&gt; names; session &lt;&lt; &quot;SELECT Address FROM Person&quot;, into(names), now; for (std::vector&lt;std::string&gt;::const_iterator it = names.begin(); it != names.end(); ++it) &#123; std::cout &lt;&lt; *it &lt;&lt; std::endl; &#125; return 0;&#125;","categories":[{"name":"开源","slug":"开源","permalink":"https://lives.xtcgch.ink/categories/开源/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"POCO","slug":"POCO","permalink":"https://lives.xtcgch.ink/tags/POCO/"},{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"}],"keywords":[{"name":"开源","slug":"开源","permalink":"https://lives.xtcgch.ink/categories/开源/"}]},{"title":"编程语言之C++17特性","slug":"编程语言之C++17特性-20211010","date":"2021-10-10T08:42:38.000Z","updated":"2021-10-10T08:44:36.353Z","comments":true,"path":"2021/10/10/编程语言之C++17特性/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/10/编程语言之C++17特性/","excerpt":"摘要：本文主要介绍C++17特性。","text":"摘要：本文主要介绍C++17特性。 脑图 其他模板的标题 知识理解拓展扩展点一扩展点二应用和反馈 2、看开源的模板2.1 简介（1）名称 （2）作者 （3）官网 （4）下载地址 github： git： （5）类型 中间件/框架 -[中间件]：日志库、线程库、-[框架]： （6）技术语言 （7）适用平台 （8）开源协议 （9）benchmark 2.2 源码解读组织结构模块一总结 参考文献 推荐书籍","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"C++17","slug":"C-17","permalink":"https://lives.xtcgch.ink/tags/C-17/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"编程语言之C++14特性","slug":"编程语言之C++14特性-20211010","date":"2021-10-10T08:40:12.000Z","updated":"2021-10-10T08:44:46.853Z","comments":true,"path":"2021/10/10/编程语言之C++14特性/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/10/编程语言之C++14特性/","excerpt":"摘要：本文主要介绍C++14特性。","text":"摘要：本文主要介绍C++14特性。 脑图 其他模板的标题 知识理解拓展扩展点一扩展点二应用和反馈 2、看开源的模板2.1 简介（1）名称 （2）作者 （3）官网 （4）下载地址 github： git： （5）类型 中间件/框架 -[中间件]：日志库、线程库、-[框架]： （6）技术语言 （7）适用平台 （8）开源协议 （9）benchmark 2.2 源码解读组织结构模块一总结 参考文献 推荐书籍","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"C++14","slug":"C-14","permalink":"https://lives.xtcgch.ink/tags/C-14/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"编译原理","slug":"编译原理-20211010","date":"2021-10-10T07:56:01.000Z","updated":"2021-10-10T08:01:53.494Z","comments":true,"path":"2021/10/10/编译原理/","link":"","permalink":"https://lives.xtcgch.ink/2021/10/10/编译原理/","excerpt":"摘要：这是编译原理的总览篇","text":"摘要：这是编译原理的总览篇 脑图 其他模板的标题 知识理解拓展扩展点一扩展点二应用和反馈 2、看开源的模板2.1 简介（1）名称 （2）作者 （3）官网 （4）下载地址 github： git： （5）类型 中间件/框架 -[中间件]：日志库、线程库、-[框架]： （6）技术语言 （7）适用平台 （8）开源协议 （9）benchmark 2.2 源码解读组织结构模块一总结 参考文献 推荐书籍","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"编译原理","slug":"编译原理","permalink":"https://lives.xtcgch.ink/tags/编译原理/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"求职之笔试篇","slug":"求职之笔试篇-20210927","date":"2021-09-26T16:32:24.000Z","updated":"2021-11-22T01:50:15.073Z","comments":true,"path":"2021/09/27/求职之笔试篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/27/求职之笔试篇/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 ★★★ 导航 ★★★★★★ 字符串翻转 ★★★ 1 static关键字的作用 ★★★ 链表 ★★★ 1 map和set有什么区别，分别又是怎么实现的 ★★★ 数组 ★★★ 1 map和set有什么区别，分别又是怎么实现的 ★★★ 哈希表 ★★★ 1 从数组中找出只出现一次的两个数，数组中其他数都出现两次 ★★★ 滑动窗口篇 ★★★ 无重复字符的最长子串 串联所有单词的子串 最小覆盖子串 至多包含两个不同字符的最长子串 长度最小的子数组 滑动窗口最大值 字符串的排列 最小区间 最小窗口子序列 ★★★ 马拉车算法篇 ★★★ 最长回文子串 ★★★ 动态规划篇 ★★★ 最长回文子串 括号生成 青蛙跳台阶问题 连续子数组的最大和 礼物的最大价值 n个骰子的点数 正则表达式匹配 ★★★ 回文树(回文自动机)篇 ★★★ 最长回文子串 ★★★ 大数据篇 ★★★ 最长回文子串 ★★★ 双指针篇 ★★★ 盛最多水的容器 最接近的三数之和 ★★★ 回溯篇 ★★★ 关键字： 所有组合 电话号码的字母组合 括号生成 ★★★ 递归篇 ★★★ 括号生成 ★★★ 分治篇 ★★★ pow(x,b)实现 ★★★ 贪心算法篇 ★★★ 整数转罗马数字","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/tags/求职/"},{"name":"笔试","slug":"笔试","permalink":"https://lives.xtcgch.ink/tags/笔试/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"【架构】架构之微服务篇","slug":"架构之微服务篇-20210913","date":"2021-09-13T06:17:04.000Z","updated":"2021-09-13T06:59:46.109Z","comments":true,"path":"2021/09/13/架构之微服务篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/13/架构之微服务篇/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 总体介绍微服务框架 功能图 zookeeper RPC框架gRPCgRPC通信协议protubufRabbitMQZeroMQ注册中心Zookeeper数据库方案数据库之MYSQL消息队列之RabbitMQ流量控制负载均衡LB之Nginx服务中心日志系统之log4j项目管理之git项目发布之jenkins接口服务之Open API监控中心 Prometheus 监控对象 系统层 CPU 磁盘 内存 网络利用率 应用层 调用量 延迟 错误 业务层 端用户体验层 基础资源监控 网络监控 网络性能监控：主要涉及网络监测，网络实时流量监控（网络延迟、访问量、成功率）和历史数据统计、汇总和历史数据分析等功能 网络检测：主要针对内网或者外网的网络。如DDoS的。通过分析异常流量来确定网络行为 设备监控：主要针对数据中心内的多种网络设备进行监控。包括路由器，防火墙和交换机等硬件设备，可以通过snmp等协议收集数据 存储监控 存储性能监控方面：存储通常监控块的读写速率，IOPS。读写延迟，磁盘用量等；文件存储通常监控文件系统inode。读写速度、目录权限等。 存储系统监控方面：不同的存储系统有不同的指标，例如，对于ceph存储需要监控OSD, MON的运行状态，各种状态pg的数量以及集群IOPS等信息。 存储设备监控方面：对于构建在x86服务器上的存储设备，设备监控通过每个存储节点上的采集器统一收集磁盘、SSD、网卡等设备信息；存储厂商以黑盒方式提供商业存储设备，通常自带监控功能，可监控设备的运行状态，性能和容量的。 服务器监控 CPU：涉及整个 CPU 的使用量、用户态百分比、内核态百分比，每个 CPU 的使用量、等待队列长度、I/O 等待百分比、CPU 消耗最多的进程、上下文切换次数、缓存命中率等。 内存：涉及内存的使用量、剩余量、内存占用最高的进程、交换分区大小、缺页异常等。 网络 I/O：涉及每个网卡的上行流量、下行流量、网络延迟、丢包率等。 磁盘 I/O：涉及硬盘的读写速率、IOPS、磁盘用量、读写延迟等。 中间件监控 消息中间件： RabbitMQ、Kafka Web 服务中间件：Tomcat、Jetty 缓存中间件：Redis、Memcached 数据库中间件：MySQL、PostgreSQL 应用程序监控(APM) APM主要是针对应用程序的监控，包括应用程序的运行状态监控，性能监控，日志监控及调用链跟踪等。 调用链跟踪是指追踪整个请求过程（从用户发送请求，通常指浏览器或者应用客户端）到后端API服务以及API服务和关联的中间件，或者其他组件之间的调用，构建出一个完整的调用拓扑结构，不仅如此，APM 还可以监控组件内部方法的调用层次（Controller–&gt;service–&gt;Dao）获取每个函数的执行耗时，从而为性能调优提供数据支撑。 应用程序监控工具除了有 Pinpoint，还有 Twitter 开源的 Zipkin，Apache SkyWalking，美团开源的 CAT等 优点 强大的多维度数据模型： 时间序列数据通过 metric 名和键值对来区分。 所有的 metrics 都可以设置任意的多维标签。 数据模型更随意，不需要刻意设置为以点分隔的字符串。 可以对数据模型进行聚合，切割和切片操作。 支持双精度浮点类型，标签可以设为全 unicode。 灵活而强大的查询语句（PromQL）：在同一个查询语句，可以对多个 metrics 进行乘法、加法、连接、取分数位等操作。 易于管理： Prometheus server 是一个单独的二进制文件，可直接在本地工作，不依赖于分布式存储。 高效：平均每个采样点仅占 3.5 bytes，且一个 Prometheus server 可以处理数百万的 metrics。 使用 pull 模式采集时间序列数据，这样不仅有利于本机测试而且可以避免有问题的服务器推送坏的 metrics。 可以采用 push gateway 的方式把时间序列数据推送至 Prometheus server 端。 可以通过服务发现或者静态配置去获取监控的 targets。 有多种可视化图形界面。 易于伸缩。 log4j","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://lives.xtcgch.ink/tags/微服务/"},{"name":"架构","slug":"架构","permalink":"https://lives.xtcgch.ink/tags/架构/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【开源】开源之zeromq","slug":"开源之zeromq-20210913","date":"2021-09-12T16:52:53.000Z","updated":"2021-10-02T13:47:26.092Z","comments":true,"path":"2021/09/13/开源之zeromq/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/13/开源之zeromq/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 其他模板的标题 知识理解三种模型 应答模式 订阅发布模式 基于分布式处理（管道模式） 扩展点一扩展点二应用和反馈 2、看开源的模板2.1 简介（1）名称 （2）作者 （3）官网 （4）下载地址 github： git： （5）类型 中间件/框架 -[中间件]：日志库、线程库、-[框架]： （6）技术语言 （7）适用平台 （8）开源协议 （9）benchmark 2.2 源码解读组织结构模块一总结 参考文献 推荐书籍","categories":[{"name":"开源","slug":"开源","permalink":"https://lives.xtcgch.ink/categories/开源/"}],"tags":[{"name":"开源","slug":"开源","permalink":"https://lives.xtcgch.ink/tags/开源/"},{"name":"ZEROMQ","slug":"ZEROMQ","permalink":"https://lives.xtcgch.ink/tags/ZEROMQ/"}],"keywords":[{"name":"开源","slug":"开源","permalink":"https://lives.xtcgch.ink/categories/开源/"}]},{"title":"【求职】求职之版本管理篇","slug":"求职之版本管理篇-20210910","date":"2021-09-10T15:02:58.000Z","updated":"2021-11-23T15:02:05.246Z","comments":true,"path":"2021/09/10/求职之版本管理篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/10/求职之版本管理篇/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ git工作流 Git常见工作流 集中式工作流 功能开发工作流 Gitflow工作流 Forking工作流 Pull Requests工作流（特殊，不能算独立的工作流） Git主要优点 分布式存储，本地仓库包含了远程仓库的所有内容。 安全性高，远程仓库文件丢失了也不怕。 优秀的分支模型，创建/合并分支都非常快速便捷。 Git分支管理我们在实际工作中会创建很多分支以便于不同场景下的开发，但是如果没有分支规范就会造成分支杂乱，大家往往也搞不清楚某一个分支是在做什么，下面我们就介绍一下我们常用的并且推荐大家使用的分支类型。 Git分支类型master 分支 master 为产品主分支，该分支为只读唯一分支，也是用于部署生产环境的分支，需确保master分支的稳定性。master 分支一般由release分支或hotfix分支合并，任何情况下都不应该直接修改master分支代码。产品的功能全部实现后，最终在master分支对外发布，另外所有在master分支的推送应该打标签（tag）做记录，方便追溯。master 分支不可删除。 develop 分支 develop 为主开发分支，基于master分支创建，始终保持最新完成功能的代码以及bug修复后的代码。develop 分支为只读唯一分支，只能从其他分支合并，不可以直接在该分支做功能开发或bug修复。一般开发新功能时，feature分支都是基于develop分支下创建的。develop 分支包含所有要发布到下一个release的代码。feature功能分支完成后, 开发人员需合并到develop分支(不推送远程)，需先将develop分支合并到feature，解决完冲突后再合并到develop分支。当所有新功能开发完成后，开发人员并自测完成后，此时从develop拉取release分支，进行提测。release或hotfix 分支上线完成后, 开发人员需合并到develop分支并推送远程。develop 分支不可删。 feature 分支 feature 分支通常为新功能或新特性开发分支，以develop分支为基础创建feature分支。分支命名: feature/ 开头的为新特性或新功能分支，建议的命名规则: feature/user_createtime_feature，例如：feature/ftd_20201018_alipay，含义为：开发人员ftd在2020年10月18日时创建了一个支付宝支付的功能分支。新特性或新功能开发完成后，开发人员需合到develop分支。feature 分支可同时存在多个，用于团队中多个功能同时开发。feature 分支属于临时分支，功能完成后可选删除。 release 分支 release 分支为预上线分支，基于本次上线所有的feature分支合并到develop分支之后，从develop分支创建。分支命名: release/ 开头的为预上线分支，建议的命名规则: release/version_publishtime，例如：release/v2.1.1_20201018，含义为：版本号v2.1.1计划于2020年10月18日时发布。release 分支主要用于提交给测试人员进行功能测试。发布提测阶段，会以release分支代码为基准进行提测。测试过程中发现的bug在本分支进行修复，上线完成后需合并到develop/master分支并推送远程。release 分支属于临时分支，产品上线后可选删除。❝ 当有一组feature开发完成后，首先开发人员会各自将最新功能代码合并到develop分支。进入提测阶段时，开发组长在develop分支上创建release分支。 如果在测试过程中发现bug需要修复，则直接由开发者在release分支修复并提交。当测试完成后，开发组长将release分支合并到master和develop分支，此时master为最新可发布代码，用作产品发布上线。❞hotfix 分支 hotfix 分支为线上bug修复分支或叫补丁分支，主要用于对线上的版本进行bug修复。分支命名: hotfix/ 开头的为修复分支，它的命名规则与 feature 分支类似，建议的命名规则: hotfix/user_createtime_hotfix，例如：hotfix/ftd_20201018_alipaybugfix，含义为：开发人员ftd在2020年10月18日时创建了一个支付宝支付bug修复的分支。hotfix 分支用于线上出现紧急问题时，需要及时修复，以master分支为基线，创建hotfix分支。当问题修复完成后，需要合并到master分支和develop分支并推送远程。所有hotfix分支的修改会进入到下一个release。hotfix 分支属于临时分支，bug修复上线后可选删除。以上就是在工作中常用到的6种分支类型，覆盖了开发中的常见场景，大家也可以根据实际工作情况进行调整，重点是让团队小伙伴都能对整个分支的类型及作用了解即可。 分支创建好了，小伙伴们也都开始按照流程开始开发了，但是在日常开发中由于缺少对于commit message的约束，导致填写内容随意、质量参差不齐，可读性低亦难以维护。在项目中引入commit message规范已是迫在眉睫。书写良好的commit message能大大提高代码维护的效率。 Git Flow工作流我们现在已经了解了Git的分支，包括分支有哪些类型，什么情况下使用什么类型的分支，以及提交的格式规范等。不过往往在一个团队人数较多，创建的分支也比较多的时候，还是会带来很多分支操作上的困扰。那有没有一个什么好的流程来规范大家呢，针对这些问题，建议大家使用Git Flow的工作流模式。 Git Flow 流程图「1，主分支流程」 master分支记录了每次版本发布历史和tag标记。develop分支记录了所有开发的版本历史。develop分支仅第一次创建时从master分支拉取。 「2，开发流程」 feature分支是从develop分支拉取的分支。每个feature完成后需合并到develop分支。 「3，提测发布流程」 release分支是在所有功能开发自测完成后，从develop分支拉取的分支。 release分支一旦创建后，通常不再从develop分支拉取，该分支只做bug修复，文档生成和其他面向发布的任务。 release分支测试完成，达到上线标准后，需合并回master分支和develop分支。 「4，bug修复流程」 hotfix分支是在线上出现bug之后，从master分支拉取的分支。 hotfix分支测试完成后，需合并回master分支和develop分支。 历史分支 使用两个分支来记录项目的历史。 master分支记录了正式发布的历史，而develop分支作为功能的集成分支。因此，master分支的每次提交都应分配一个版本号。 功能分支 功能分支是从develop中checkout出来的新分支，每个功能对应一个分支。 假设开发a功能：1git checkout -b feature-a develop 当新功能完成时，合并回develop分支。1234git checkout developgit merge --no-ff feature-agit pushgit branch -d feature-a 发布分支 当develop分支开发到需要发布时，从develop分支拉出一个发布分支，命名为release-或release/。 1git checkout -b release-0.1 develop 该分支用于发布循环，只做bug修复、文档生成等面向发布的任务。新功能不再添加到这个分支上。一旦发布完成，把发布分支merge到master分支上。 123git checkout mastergit merge --no-ff release-0.1git push 打tag记录版本号，方便跟踪每次发布。 12git tag v0.1git push --tags 把这些从新建发布分支以来做的修改merge到develop分支。 123git checkout developgit merge --no-ff release-0.1git push 最后删除发布分支1git branch -d release-0.1 维护分支/热修复 当线上版本出现bug时，就需要用到维护分支，它用于快速给产品发布版本打补丁。 从master分支拉一个维护分支（这是唯一从master分支拉出来的分支）。1git checkout -b hotfix master 修复完成后，马上合并回master和develop。 1234567git checkout mastergit merge --no-ff hotfixgit pushgit checkout developgit merge --no-ff developgit push git branch -d hotfix master用新版本号打tag 12git tag v0.2 git push --tags 优点 单个功能独立开发，并行开发互不干扰 master和develop分支分别记录发布和功能开发的历史 由于有发布分支，其他暂不发布的功能的开发不受发布的影响，可以继续提交 维护分支能快速打补丁，不影响正在开发的功能 缺点 复杂，分支繁多 Git GUI不支持，纯命令行 对开发者要求高（理解工作流，熟悉Git命令） 所有功能分支基于不稳定的develop 需要维护两个长期分支master和develop Git Flow实战Git Flow的流程搞清楚后，我们下面开始实际的项目实战，假设我们现在有一个商城的项目，并且我们已经建好了Git仓库。 我们通过命令行和图形界面的方式分别向大家展示如何使用Git Flow工作流。 Git Flow 命令示例开始 Feature 12345# 创建feature分支git flow feature start ftd_20201018_wechatpay# 指定当前分支pull的源为developgit branch --set-upstream-to=origin/develop feature/ftd_20201018_wechatpay 完成 Feature12345# 发布featuregit flow feature publish ftd_20201018_wechatpay# 完成featuregit flow feature finish ftd_20201018_wechatpay 开始 Release1git flow release start v1.0_20201031 完成 Release1git flow release finish v1.0_20201031 开始 Hotfix1git flow hotfix start ftd_20201031_bugfix 完成 Hotfix1git flow hotfix finish ftd_20201031_bugfix 大家可以看到，简简单单几行命令就可以完成比较复杂的流程管理，如果对于命令行不太擅长的小伙伴还可以使用图形工具，这里推荐使用sourcetree，sourcetree也是著名的Git管理工具，可以大大方便我们对Git的操作和使用，下面就来介绍一下sourcetree中如何使用Git Flow。 ❝ 注：以下内容为Windows版本的sourcetree为例，Mac类似。❞初始化GitFlow打开sourcetree，选择想使用Git Flow工作流的项目，在右上角点击Git工作流按钮，如下图所示： 开始 Release 完成 Release Hotfixhotfix流程与上述流程操作方法类似 参考文章：git常见工作流","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"},{"name":"GIT","slug":"GIT","permalink":"https://lives.xtcgch.ink/tags/GIT/"},{"name":"SVN","slug":"SVN","permalink":"https://lives.xtcgch.ink/tags/SVN/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"【求职】求职之操作系统篇","slug":"求职之操作系统篇-20210910","date":"2021-09-09T17:36:12.000Z","updated":"2021-11-22T12:11:22.587Z","comments":true,"path":"2021/09/10/求职之操作系统篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/10/求职之操作系统篇/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 ★★★ 一、基础篇 ★★★目录★★★ 一、基础篇 ★★★ 1 CPU调度策略★★★ 二、进阶篇 ★★★ ★★★ 一、基础篇 ★★★1 CPU调度策略 先来先服务调度算法 短作业（进程） 优先调度算法 优先权调度算法 高响应比优先调度算法 基于时间片的轮转调度算法 多级反馈队列调度算法 ★★★ 二、进阶篇 ★★★","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"},{"name":"操作系统","slug":"操作系统","permalink":"https://lives.xtcgch.ink/tags/操作系统/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"求职之C++篇","slug":"求职之C++篇-20210909","date":"2021-09-09T08:09:16.000Z","updated":"2021-11-25T09:22:28.357Z","comments":true,"path":"2021/09/09/求职之C++篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/09/求职之C++篇/","excerpt":"摘要：带着问题来学基础是最高效的方式！","text":"摘要：带着问题来学基础是最高效的方式！ 脑图 二、基础篇 (1) 14 虚函数的实现的基本原理 (1) 16 讲一下KMP算法 三、进阶篇 (1) 1 如何设计内存管理系统 (1) 1 如何进行内存碎片的管理 一、基础篇段错误★ 热度: ★★★ 考核内容(1) 什么是段错误(2) 什么时候会发生段错误(3) 如何检测造成段错误的原因 ★★ 什么是段错误 指程序运行时遇到严重错误从而异常退出 ★★ 什么时候会发生段错误 1. 使用野指针2. 试图修改字符串常量 ★★ 如何检测造成段错误的原因 1. 在linux系统中开启core down日志2. 使用gdb 运行core down文件，复现段错误的状态机 并发和并行★ 热度: ★★ 考核内容1. 什么是并发和并行2. 优缺点 ★★ 什么是并发和并行 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。 操作系统中的结构体对齐，字节对齐★ 热度: ★★★★★★ 考核内容(1) 什么是内存对齐(1) 为什么要内存对齐(1) 内存对齐规则(1) 如何使用内存对齐 ★★ 什么是内存对齐 元素是按照定义顺序一个一个放到内存中去的，但并不是紧密排列的。从结构体存储的首地址开始，每个元素放置到内存中时，它都会认为内存是按照自己的大小（通常它为4或8）来划分的，因此元素放置的位置一定会在自己宽度的整数倍上开始，这就是所谓的内存对齐。 ★★ 为什么要内存对齐 (1) 平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。(2) 性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。 (2.1) 假如没有内存对齐机制，数据可以任意存放，现在一个int变量存放在从地址1开始的联系四个字节地址中，该处理器去取数据时，要先从0地址开始读取第一个4字节块,剔除不想要的字节（0地址）,然后从地址4开始读取下一个4字节块,同样剔除不要的数据（5，6，7地址）,最后留下的两块数据合并放入寄存器。这需要做很多工作。 (2.2) 现在有了内存对齐的，int类型数据只能存放在按照对齐规则的内存中，比如说0地址开始的内存。那么现在该处理器在取数据时一次性就能将数据读出来了，而且不需要做额外的操作，提高了效率。 ★★ 内存对齐规则 (1) 数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员的对齐按照#pragma pack指定的数值和这个数据成员自身长度中，比较小的那个进行。(2) 结构(或联合)的整体对齐规则：在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行。(3) 结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。 ★★ 如何使用内存对齐 1. 定义结构体对齐可以通过预编译命令#pragma pack(n)，n=1,2,4,8,16来改变这一系数，其中的n就是指定的“对齐系数”。2. 举例123456789101112131415#pragma pack(2)struct AA &#123; int a; //长度4 &gt; 2 按2对齐；偏移量为0；存放位置区间[0,3] char b; //长度1 &lt; 2 按1对齐；偏移量为4；存放位置区间[4] short c; //长度2 = 2 按2对齐；偏移量要提升到2的倍数6；存放位置区间[6,7] char d; //长度1 &lt; 2 按1对齐；偏移量为7；存放位置区间[8]；共九个字节&#125;;#pragma pack() 虚函数的实现的基本原理★ 热度: ★★★★★★ 考核内容1. 单继承2. 多重继承3. 菱形继承★★ 单继承1. 虚函数表构造过程2. 虚函数调用过程★★ 多重继承★★ 菱形继承 硬链接和软链接★ 热度: ★★★★★★ 考核内容1. inode2. 硬链接和软链接★★ inode1. inode是什么理解inode，要从文件储存说起。文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 2. inode的内容 inode包含文件的元信息，具体来说有以下内容：(1) 文件的字节数(2) 文件拥有者的User ID(3) 文件的Group ID(4) 文件的读、写、执行权限(5) 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。(6) 链接数，即有多少文件名指向这个inode(7) 文件数据block的位置可以用stat命令，查看某个文件的inode信息：1stat example.txt 3. inode的大小 inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。1 df -i查看每个inode节点的大小，可以用如下命令：1 sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot; 4. inode号码 每个inode都有一个号码，操作系统用inode号码来识别不同的文件。这里值得重复一遍，Unix/linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。使用ls -i命令，可以看到文件名对应的inode号码：1ls -i example.txt 5. inode的特殊作用 由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。(1) 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。(2) 移动文件或重命名文件，只是改变文件名，不影响inode号码。(3) 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。 ★★ 硬链接和软链接 1. 硬链接 (1) 具有相同inode节点号的多个文件互为硬链接文件；(2) 删除硬链接文件或者删除源文件任意之一，文件实体并未被删除；(3) 只有删除了源文件和所有对应的硬链接文件，文件实体才会被删除；(4) 硬链接文件是文件的另一个入口；(5) 可以通过给文件设置硬链接文件来防止重要文件被误删；(6) 创建硬链接命令 ln 源文件 硬链接文件；(7) 硬链接文件是普通文件，可以用rm删除；(8) 对于静态文件（没有进程正在调用），当硬链接数为0时文件就被删除。注意：如果有进程正在调用，则无法删除或者即使文件名被删除但空间不会释放。 2. 软链接 (1) 软链接类似windows系统的快捷方式；(2) 软链接里面存放的是源文件的路径，指向源文件；(3) 删除源文件，软链接依然存在，但无法访问源文件内容；(4) 软链接失效时一般是白字红底闪烁；(5) 创建软链接命令 ln -s 源文件 软链接文件；(6) 软链接和源文件是不同的文件，文件类型也不同，inode号也不同；(7) 软链接的文件类型是“l”，可以用rm删除。 3. 硬链接和软链接的区别 (1) 原理上，硬链接和源文件的inode节点号相同，两者互为硬链接。软连接和源文件的inode节点号不同，进而指向的block也不同，软连接block中存放了源文件的路径名。(2) 实际上，硬链接和源文件是同一份文件，而软连接是独立的文件，类似于快捷方式，存储着源文件的位置信息便于指向。(3) 使用限制上，不能对目录创建硬链接，不能对不同文件系统创建硬链接，不能对不存在的文件创建硬链接。可以对目录创建软连接，可以跨文件系统创建软连接，可以对不存在的文件创建软连接。 函数指针★ 热度: ★★★★★★ 考核内容1. 普通函数指针2. 静态函数指针3. 类的成员函数指针4. 类的静态成员函数指针★★ 普通函数指针123456789101112131415161718#include &lt;iostream&gt; using namespace std; int addNums(int a,int b)&#123; return a+b;&#125; int main() &#123; (int*)func(int,int); func = addNums; cout&lt;&lt;&quot;sum:&quot;&gt;&gt;func(4,5)&lt;&lt;endl; system(&quot;PAUSE&quot;); return 0;&#125;c++11标准：12★★ 静态函数指针C风格：123456789101112131415161718#include &lt;iostream&gt; using namespace std; static int addNums(int a,int b)&#123; return a+b;&#125; int main() &#123; (int*)func(int,int); func = addNums; cout&lt;&lt;&quot;sum:&quot;&gt;&gt;func(4,5)&lt;&lt;endl; system(&quot;PAUSE&quot;); return 0;&#125;c++11标准：12★★ 类的成员函数指针1234567891011121314151617181920212223#include &lt;iostream&gt; using namespace std; class A &#123; public : void test1() &#123; cout &lt;&lt; &quot;test&quot; &lt;&lt; endl; &#125;;public : &#125;; typedef void (A::*PFunc)(); int main() &#123; A a; PFunc f = &amp;(A::test1); (a.*f)(); system(&quot;PAUSE&quot;); return 0;&#125;c++11标准：12★★ 类的静态成员函数指针12345678910111213141516171819202122#include &lt;iostream&gt; using namespace std; class A &#123; public : static void test1() &#123; printf(&quot;test\\n&quot;); &#125;;public : &#125;; typedef void (*PFunc)(); int main() &#123; PFunc f = &amp;(A::test1); (*f)(); system(&quot;PAUSE&quot;); return 0;&#125;c++11标准：12 设计模式23种设计模式 设计模式的六大原则 (1) 单一职责原则(1) 里氏替换原则(1) 依赖倒置原则(1) 接口隔离原则(1) 迪米特法则（最少知道原则）(1) 合成复用原则 设计模式的三大类 (1) 创建型模式:对类的实例化过程进行了抽象，能够将软件模块中对象的创建和对象的使用分离。 (1) 工厂模式、抽象工厂模式、单例模式、建造者模式、原型模式(1) 结构型模式:关注于对象的组成以及对象之间的依赖关系，描述如何将类或者对象结合在一起形成更大的结构 (1) 适配器模式、装饰者模式、代理模式、外观模式、桥接模式、组合模式、享元模式(1) 行为型模式:关注于对象的行为问题，是对在不同的对象之间划分责任和算法的抽象化；不仅仅关注类和对象的结构，而且重点关注它们之间的相互作用 (1) 策略模式、模板方法模式、观察者模式、迭代器模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式 各种排序算法内部排序 外部排序 是否稳定？ 二叉树定理平衡二叉树(AVL) 红黑树 B+树 B树 基类的析构函数一定是虚函数吗★ 热度: ★★★★★★ 考核内容1. 虚析构函数执行的过程2. 基类的析构函数是否必须为虚函数★★ 虚析构函数执行的过程 demo1：1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;class A&#123;public: A()&#123;cout &lt;&lt; &quot;A&quot; &lt;&lt; endl;&#125; virtual ~A()&#123;cout &lt;&lt; &quot;~A&quot; &lt;&lt; endl;&#125;&#125;;class B : public A&#123;public: B()&#123;cout &lt;&lt; &quot;B&quot; &lt;&lt; endl;&#125; virtual ~B()&#123;cout &lt;&lt; &quot;~B&quot; &lt;&lt; endl;&#125;&#125;;int main()&#123; A *p = new B; delete p; return 0;&#125;输出：1234AB~B~Ademo1：1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;class A&#123;public: A()&#123;cout &lt;&lt; &quot;A&quot; &lt;&lt; endl;&#125; ~A()&#123;cout &lt;&lt; &quot;~A&quot; &lt;&lt; endl;&#125;&#125;;class B : public A&#123;public: B()&#123;cout &lt;&lt; &quot;B&quot; &lt;&lt; endl;&#125; virtual ~B()&#123;cout &lt;&lt; &quot;~B&quot; &lt;&lt; endl;&#125;&#125;;int main()&#123; A *p = new B; delete p; return 0;&#125;输出：123AB~A★★ 基类的析构函数是否必须为虚函数 虚析构函数的目的在于在使用delete运算符删除一个对象时，能保析构函数被正确地执行。如果派生类自定义了operator delete()函数，这时不管基类中是否有没有虚函数都要虚析构。 构造函数可以是虚函数吗★ 热度: ★★★★★★ 考核内容1. 虚函数表的创建过程★★ 虚函数表的创建过程 当类中声明虚函数时，编译器会在类中生成一个虚函数表，虚函数表是一个存储成员函数指针的数据结构。虚函数表是由编译器自动生成与维护的，virtual成员函数会被编译器放入虚函数表中，当存在虚函数时，每个对象都有一个指向虚函数的指针（vptr指针）。在实现多态的过程中，父类和派生类都有vptr指针。vptr的初始化：当对象在创建时，由编译器对vptr指针进行初始化。在定义子类对象时，vptr先指向父类的虚函数表，在父类构造完成之后，子类的vptr才指向自己的虚函数表。如果构造函数时虚函数，那么调用构造函数就需要去找vptr，而此时vptr还没有初始化。因此，构造函数不可以是虚函数 new和malloc★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 手动实现strcpy★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 虚函数多态机制★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 override overload overwrite的区别: overload(重载)（不是多态） 在C++程序中，可以将语义、功能相似的几个函数用同一个名字表示，但参数不同（包括类型、顺序不同），即函数重载 （1）相同的范围（在同一个类中）；（2）函数名字相同；（3）参数不同；（4）virtual 关键字可有可无。 override(覆盖)（运行时多态、虚函数） 是指派生类函数覆盖基类函数，特征是： （1）不同的范围（分别位于派生类与基类）（2）函数名字相同；（3）参数相同；（4）基类函数必须有virtual 关键字。 overwrite(重写)（编译时多态） 是指派生类的函数屏蔽了与其同名的基类函数，规则如下： （1）如果派生类的函数与基类的函数同名，但是参数不同。此时，不论有无virtual关键字，基类的函数将被隐藏（注意别与重载混淆）（2）如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字。此时，基类的函数被隐藏（注意别与覆盖混淆） 静态联编和动态联编（运行时多态和编译时多态） 在C++中，多态性的实现和联编这一概念有关。一个源程序经过编译，链接，成为可执行文件的过程是把可执行代码连接在一起的过程。 在编译过程中进行联编被称为静态联编（static binding），编译器生成的能够在程序运行时选择正确的虚方法的代码，被称为动态联编（dynamic binding）。 静态联编也称为编译时多态性，主要通过函数重写实现。动态联编也称为运行时多态性。主要通过继承和虚函数来实现。 编译器对非虚方法使用静态联编，一个父类指针指向一个子类时，静态联编调用的是父类函数。编译器对虚方法使用动态联编，运行时程序才确定对象的类型，此时一个父类指针指向一个子类，调用的是子类的函数。 动态联编的工作原理（虚函数表） (1) 编译器处理虚函数的方法是：给每个对象添加一个隐藏成员，用于保存一个指向函数地址数组的指针。这个数组称为“虚函数表”。(1) 没有虚函数的C++类，是不会有虚函数表的。(1) 虚函数表（virtual function table，vtbl）：存储了为类对象进行声明的虚函数的地址。 多重继承时的虚函数表 重载与多态的区别★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 多态的实现主要分为静态多态和动态多态，***静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定 RAII 机制★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 Sizeof 考察★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 在c99没有出现之前，sizeof是由编译时确定的，sizeof对一个类型求出的值可以当一个常量来用。但C99中引入了动态数组（定义一个数组，其大小由运行时确定）导致sizeof作用于动态数组时的值不再是常量。 demo 1234567891011#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char *argv[]) &#123; int n; scanf(&quot;%d&quot;,&amp;n); int arr[n]; printf(&quot;%d\\n&quot;,sizeof(n++)); printf(&quot;%d\\n&quot;,sizeof(arr)); printf(&quot;%d&quot;,n); return 0;&#125; 输入：3输出： 4 12 3 sizeof(n++)中的++未执行。 结论 sizeof是一种运算符不是函数，所得出的值在编译期确定，可以求出静态分配内存的数组的长度，但不能求出动态分配的内存的大小。 union的内存分配1.空间大小 各成员共享一段内存空间，一个联合变量的长度等于各成员中最长的长度 (1) 要大于等于最长的一个结构变量的空间(1) 并且要能够整除其他结构变量的数据长度，即联合体空间对其他成员的元类型要能够整除（int a[5]，其元类型为int，元类型长度为4），实际上就是要取一个元类型的最小公倍数。 123456union &#123; float fuel_load; //4 Bytes char a[5]; // 1 * 5 = 5 Bytes int pallets; // 4 Bytes&#125;fighter; fighter的空间大小为：8。float：4 Bytes，char：1 Bytes，int：4 Bytes 。8可以整除1和4，并且8&gt;5。 2.内存分布 1234567891011union &#123; int i; char x[2];&#125;a;int main(void)&#123; a.x[0] = 10; a.x[1] = 1; printf(&quot;%d\\n&quot;,a.i); return 0;&#125; 高地址-&gt;低地址 字节0 字节1 字节2 字节3 0000 0000 0000 0000 0000 0001 0000 1010 应用：判断大小端 空悬指针极其危害★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 空悬指针简单地说，空悬指针是对象的指针的生存周期比对象更长所导致的，也就是说，对象销毁、删除了，不存在了，指针仍然存在，这时这个指针就成了空悬指针。 当对象被析构、删除时，如果指向它的指针没有被同时修改，那么指针仍然会指向那块内存（但是那块内存已经没有东西了）。系统此时可能会重新分配这块已经free掉的内存，如果程序再通过这个指针读这块内存，就可能会有不可预见的事情发生，因为这块内存可能被分配了完全不同的内容。如果程序此时要写这块内存，就可能会造成数据污染，进而可能带来超级难被发现的bug。如果内存已经被其它进程重新分配，此时再去访问指针指向的内容，就可能会发生片段错误(UNIX,Linux)或者一般性保护错误(Windows).如果程序有足够的权限去重写内核内存分配器的内容，还可能造成系统的不稳定。在有垃圾回收机制的面向对象语言中，阻止空悬引用的方法是销毁所有访问不到的对象，也就是说他们也就没有所谓的指针了，这是由追踪或引用计数而确保的。然而finalizer可能会创建新的对象的引用，这就要求对象要再生来防止空悬引用。 野指针作为一个指针，甚至都没有被初始化，也就是说虽然它的类型是一个指针，但它根本没有值。它跟NULL指针还有差别，NULL是指向了0地址，而野指针是没有地址。也就相当于，int a=0;和int a;的区别。 情形一： 指针和指向的对象的作用域不同时 123456789&#123; char *dp = NULL; /* ... */ &#123; char c; dp = &amp;c; &#125; //到这里，c已经被销毁了，dp就变成了空悬指针&#125; 情形二： free或者delete后，指针没有赋NULL值 12345678910111213141516#include &lt;stdlib.h&gt;void func()&#123; char *dp = malloc(A_CONST); /* ... */ free(dp); /* dp 现在是空悬指针 */ dp = NULL; /* dp 不再是空悬指针*/ /* ... */&#125;int *func(void)&#123; int num = 1234; /* ... */ return &amp;num;//返回了一个指针，但是指针指向的对象，在函数结束时已经销毁了&#125; 情形三： 局部定义的指针变量返回变空悬指针1234567891011121314151617181920212223#include&lt;iostream&gt;using namespace std;int *test_array(int *a)&#123; int length = sizeof(a)/sizeof(a[0]); int *b = new int [length]; for (int i = 0; i &lt; length; ++i) &#123; *b++=a[i]; &#125; return b;&#125;int main()&#123; int a [5] = &#123;1,2,3,4,5&#125;; int *b = test_array(a); for (int i = 0; i &lt; 5; ++i) &#123; cout&lt;&lt;b[i]&lt;&lt;endl; &#125; return 0;&#125; 常用的单元测试库(1) CUnit(1) GTest、GMock(1) CppUnit(1) CppUTest(1) CppUTest 常见的*_cast★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 (1) const_cast:删除const变量的属性(1) dynamic_cast:用于将一个父类对象的指针转换为子类对象的指针或引用(1) reinterpret_cast:将一种类型转换为另一种不同的类型(1) static_cast:用于静态转换，任何转换都可以用它，但他不能用于两个不相关的类型转换 #pragma指令与#ifndef指令★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 在C/C++中，在使用预编译指令#include的时候，为了防止重复引用造成二义性，通常有两种方式—— (1) #ifndef指令防止代码块重复引用(1) 第二种就是#pragma once指令，在想要保护的文件开头写入 区别： (1) #ifndef方式是C/C++语言的标准支持，#ifndef的方式依赖于自定义的宏名(_INCLUDE_H_)。#pragma once则不需要声明宏名(1) 由于编译器每次都需要打开头文件才能判定是否有重复定义，因此在编译大型项目时，#ifndef会使得编译时间相对较长。(1) #pragma once一般由编译器提供保证：同一个物理文件不会被包含多次(1) #pragma once方式产生于#ifndef之后。#ifndef方式受C/C++语言标准的支持，不受编译器的任何限制；而#pragma once方式有些编译器不支持(较老编译器不支持，如GCC 3.4版本之前不支持#pragmaonce)，兼容性不够好 mutable的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 Mutable的含义是可变的，它和const关键字是相对的。mutable声明一个类的成员变量，它告诉编译器类的常成员函数可以修改这个变量。示例如下： 12345678class MyClass&#123; mutable int member; void constFun()const &#123; member=0; &#125;&#125;; 如果不使用mutable修饰member定义，就会编译报错。 typeid的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 从名字直观看来，该关键字应该是获取语言元素的类型ID。有时候代码可能需要获取某个变量或者类型的名字，这时候使用typeid就比较合适。示例如下 1234567891011121314// GCC9.2 (C++2a)int myint = 50;std::string mystr = &quot;string&quot;;double *mydoubleptr = nullptr; std::cout &lt;&lt;typeid(int).name() &lt;&lt; &apos;\\n&apos;; std::cout &lt;&lt; &quot;myint has type: &quot; &lt;&lt; typeid(myint).name() &lt;&lt; &apos;\\n&apos; &lt;&lt; &quot;mystr has type: &quot; &lt;&lt; typeid(mystr).name() &lt;&lt; &apos;\\n&apos; &lt;&lt; &quot;mydoubleptr has type: &quot; &lt;&lt; typeid(mydoubleptr).name() &lt;&lt; &apos;\\n&apos;;//i//myint has type: i//mystr has type: NSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE//mydoubleptr has type: Pd virtual的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 静态函数不可以声明为虚函数，同时也不能被const 和 volatile关键字修饰 static成员函数不属于任何类对象或类实例，所以即使给此函数加上virutal也是没有任何意义。虚函数依靠vptr和vtable来处理。vptr是一个指针，在类的构造函数中创建生成，并且只能用this指针来访问它，静态成员函数没有this指针，所以无法访问vptr。 构造函数不可声明为虚函数，除inline|explicit之外，构造函数不允许使用其它关键字 尽管虚函数表vtable是在编译阶段就已经建立的，但指向虚函数表的指针vptr是在运行阶段实例化对象时才产生的。 如果类含有虚函数，编译器会在构造函数中添加代码来创建vptr。 问题来了，如果构造函数是虚的，那么它需要vptr来访问vtable，可这个时候vptr还没产生。 因此，构造函数不可以为虚函数 我们之所以使用虚函数，是因为需要在信息不全的情况下进行多态运行。而构造函数是用来初始化实例的，实例的类型必须是明确的。 因此，构造函数没有必要被声明为虚函数 析构函数可以声明为虚函数 如果我们需要删除一个指向派生类的基类指针时，应该把析构函数声明为虚函数。 事实上，只要一个类有可能会被其它类所继承， 就应该声明虚析构函数(哪怕该析构函数不执行任何操作) 虚函数可以被内联吗虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。 内联是在编译器建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联 extern的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 引入外部cpp定义的变量 123456//file1.cppint a = 0;//file2.cppextern int a; 告诉编译器使用c语言库来编译代码 123456#include &lt;iostream&gt;using namespace std;extern &quot;C&quot; &#123; #include &quot;add.h&quot;&#125; using的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 局部与全局using 1using namespace std; 改变访问性 123456789101112class Base&#123;public: std::size_t size() const &#123; return n; &#125;protected: std::size_t n;&#125;;class Derived : private Base &#123;public: using Base::size;protected: using Base::n;&#125;; 类Derived私有继承了Base，对于它来说成员变量n和成员函数size都是私有的 如果使用了using语句，可以改变他们的可访问性，如上述例子中，size可以按public的权限访问，n可以按protected的权限访问 取代typedef C++11 使用 using 引入了下面这种形式的写法，并且同时支持对传统 typedef 相同的功效 123456789typedef int (*process)(void *);using NewProcess = int(*)(void *);template&lt;typename T&gt;using TrueDarkMagic = MagicType&lt;std::vector&lt;T&gt;, std::string&gt;;int main() &#123; TrueDarkMagic&lt;bool&gt; you;&#125; register的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 由于受硬件寄存器长度的限制，所以寄存器变量只能是char、int或指针型 寄存器说明符只能用于说明函数中的变量和函数中的形参，因此不允许将外部变量或静态变量说明为”register” register型变量常用于作为循环控制变量，这是使用它的高速特点的最佳场合 由于register变量使用的是硬件CPU中的寄存器，寄存器变量无地址，所以不能使用取地址运算符”&amp;”求寄存器变量的地址 volatile的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 介绍 C/C++ 中的 volatile 关键字和 const 对应，用来修饰变量，通常用于建立语言级别的 memory barrier 编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问 当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存 volatile语法 1volatile int vInt demo1: 123456789101112131415161718#include &lt;stdio.h&gt; void main()&#123; int i = 10; int a = i; printf(&quot;i = %d&quot;, a); // 下面汇编语句的作用就是改变内存中 i 的值 // 但是又不让编译器知道 __asm &#123; mov dword ptr [ebp-4], 20h &#125; int b = i; printf(&quot;i = %d&quot;, b);&#125; 输出： DEBUG版本(结果正确)12i = 10i = 32 RELEASE版本(结果错误)12i = 10i = 10 结果分析： ，Release 模式下,编译器对代码进行了优化。由于编译器发现两次从 i读数据的代码之间的代码没有对 i 进行过操作,它会自动把上次读的数据放在 b 中。而不是重新从 i 里面读。 demo2: 123456789101112131415#include &lt;stdio.h&gt; void main()&#123; volatile int i = 10; int a = i; printf(&quot;i = %d&quot;, a); __asm &#123; mov dword ptr [ebp-4], 20h &#125; int b = i; printf(&quot;i = %d&quot;, b);&#125; 输出： Debug 和 Release 版本12i = 10i = 32 volatile用法 volatile用在如下的几个地方： (1) 中断服务程序中修改的供其它程序检测的变量需要加 volatile(1) 多任务环境下各任务间共享的标志应该加 volatile(1) 存储器映射的硬件寄存器通常也要加 volatile 说明，因为每次对它的读写都可能由不同意义 volatile 指针 和 const 修饰词类似，const 有常量指针和指针常量的说法，volatile 也有相应的概念： 修饰由指针指向的对象、数据是 const 或 volatile 的： 12const char* cpch;volatile char* vpch; 或 12char* const pchc;char* volatile pchv; 注意： (1) 可以把一个非volatile int赋给volatile int，但是不能把非volatile对象赋给一个volatile对象。(1) 除了基本类型外，对用户定义类型也可以用volatile类型进行修饰。(1) C++中一个有volatile标识符的类只能访问它接口的子集，一个由类的实现者控制的子集。用户只能用const_cast来获得对类型接口的完全访问。此外，volatile向const一样会从类传递到它的成员。 多线程下的volatile 有些变量是用 volatile 关键字声明的。 当两个线程都要用到某一个变量且该变量的值会被改变时，应该用 volatile 声明，该关键字的作用是防止优化编译器把变量从内存装入 CPU 寄存器中。 如果变量被装入寄存器，那么两个线程有可能一个使用内存中的变量，一个使用寄存器中的变量，这会造成程序的错误执行。 volatile 的意思是让编译器每次操作该变量时一定要从内存中真正取出，而不是使用已经存在寄存器中的值，如下： volatile与多线程 (1) volatile 不能解决多线程中的问题(1) volatile 只在三种场合下是合适的 (1) 和信号处理（signal handler）相关的场合 (1) 和内存映射硬件（memory mapped hardware）相关的场合 (1) 和非本地跳转（setjmp 和 longjmp）相关的场合 constexptr的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 constexpr 关键字使得代码在编译过程中，如果编译器对于某个表达式已经得到足够多的信息，那么编译器会在编译器一结束就把该表达式的结果求出来。 对于无 constexpr 关键字的表达式是在运行期执行，对于有 constexpr 关键字的表达式是在编译期执行。 12345678910111213141516171819202122#include &quot;pch.h&quot;#include &lt;iostream&gt; int fact(int n) &#123; return (n == 1 ? 1 : n * fact(n (1) 1));&#125; constexpr int fact_const(int n) &#123; return (n == 1 ? 1 : n * fact_const(n (1) 1));&#125; int main(int ac, char* av[]) &#123; int arr1[fact(4)]; // 错误，数组大小不确定 int array2[fact_const(4)]; //@1 正确。等价于写了 4 * 3 * 2 char group[fact_const(6)]; //@2 正确 if (ac &gt; 1) std::cout &lt;&lt; fact_const(ac); // @3 return 0; 对于在 @1 @2 行，fact_const 的参数值在编译期就已确定，所以其结果作为一个常量值使用，而对于 @3 行，其参数值在编译期是不确定值，此时 fact_const 又转化为普通的函数调用。 explicit的作用★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 explicit的知识点: (1) explicit 关键字只能用于类内部的构造函数声明上。(1) explicit 关键字作用于单个参数的构造函数。(1) 在C++中，explicit关键字用来修饰类的构造函数，被修饰的构造函数的类，不能发生相应的隐式类型转换 加了explicit关键字后，可防止隐式类型转换发生 12345678910111213141516171819202122232425262728293031class Circle &#123; public: explicit Circle(double r) : R(r) &#123;&#125; explicit Circle(int x, int y = 0) : X(x), Y(y) &#123;&#125; explicit Circle(const Circle&amp; c) : R(c.R), X(c.X), Y(c.Y) &#123;&#125; private: double R; int X; int Y; &#125;; int _tmain(int argc, _TCHAR* argv[]) &#123; //一下3句，都会报错 //Circle A = 1.23; //Circle B = 123; //Circle C = A; //只能用显示的方式调用了 //未给拷贝构造函数加explicit之前可以这样 Circle A = Circle(1.23); Circle B = Circle(123); Circle C = A; //给拷贝构造函数加了explicit后只能这样了 Circle A(1.23); Circle B(123); Circle C(A); return 0; &#125; ET和LT的区别?★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 static关键字的作用★ 热度: ★★★★★★ 考核内容1. 面向过程设计中的static2. 面向对象的static关键字★★ 面向过程设计中的static 1.1 全局静态变量(1) 变量在全局数据区分配内存(1) 未经初始化的静态全局变量会被程序自动初始化为0（自动变量的值是随机的，除非它被显式初始化）(1) 静态全局变量在声明它的整个文件都是可见的，而在文件之外是不可见的1.2 局部静态变量(1) 变量在全局数据区分配内存(1) 静态局部变量在程序执行到该对象的声明处时被首次初始化，即以后的函数调用不再进行初始化；(1) 静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为0；(1) 它始终驻留在全局数据区，直到程序运行结束。但其作用域为局部作用域，当定义它的函数或语句块结束时，其作用域随之结束；1.3 静态函数(1) 静态函数不能被其它文件所用(1) 其它文件中可以定义相同名字的函数，不会发生冲突★★ 面向对象的static关键字 2.1 类的静态数据成员2.2 类的静态成员函数(1) 出现在类体外的函数定义不能指定关键字static(2) 静态成员之间可以相互访问，包括静态成员函数访问静态数据成员和访问静态成员函数(3) 非静态成员函数可以任意地访问静态成员函数和静态数据成员(4) 静态成员函数不能访问非静态成员函数和非静态数据成员(5) 由于没有this指针的额外开销，因此静态成员函数与类的全局函数相比速度上会有少许的增长(6) 调用静态成员函数，可以用成员访问操作符(.)和(-&gt;)为一个类的对象或指向类对象的指针调用静态成员函数 二、编译篇gcc编译优化选项★ 热度: ★★★★★★ 考核内容1. 编译参数: -O0 -O1 -O2 -O3 -OS2. 常用级别★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 GCC对编译时间，目标文件长度，执行效率三个维度进行不同的取舍和平衡 在开启编译优化的开关时，GCC编译器的目的是：优化程序的性能和减少代码的大小，尽管会以牺牲编译时间和程序的可调试能力为代价 GCC优化选项 -O0：不做任何优化，这是默认的编译选项 默认的优化选项，减少编译时间和生成完整的调试信息 -O1：优化会消耗少多的编译时间，它主要对代码的分支，常量以及表达式等进行优化 -O和-O1： 对程序做部分编译优化，对于大函数,优化编译占用稍微多的时间和相当大的内存。使用本项优化，编译器会尝试减小生成代码的尺寸，以及缩短执行时间，但并不执行需要占用大量编译时间的优化。 打开的优化选项： (1) -fdefer-pop：延迟栈的弹出时间。当完成一个函数调用，参数并不马上从栈中弹出，而是在多个函数被调用后，一次性弹出。 (1) -fmerge-constants：尝试横跨编译单元合并同样的常量(string constants and floating point constants) (1) -fthread-jumps：如果某个跳转分支的目的地存在另一个条件比较,而且该条件比较包含在前一个比较语句之内,那么执行本项优化.根据条件是true或者false,前面那条分支重定向到第二条分支的目的地或者紧跟在第二条分支后面. (1) -floop-optimize：执行循环优化,将常量表达式从循环中移除，简化判断循环的条件，并且optionally do strength-reduction，或者将循环打开等。在大型复杂的循环中，这种优化比较显著。 (1) -fif-conversion：尝试将条件跳转转换为等价的无分支型式。优化实现方式包括条件移动，min，max，设置标志，以及abs指令，以及一些算术技巧等。 (1) -fif-conversion2基本意义相同，没有找到更多的解释。 (1) -fdelayed-branch：这种技术试图根据指令周期时间重新安排指令。 它还试图把尽可能多的指令移动到条件分支前, 以便最充分的利用处理器的治理缓存。 (1) -fguess-branch-probability：当没有可用的profiling feedback或__builtin_expect时，编译器采用随机模式猜测分支被执行的可能性，并移动对应汇编代码的位置，这有可能导致不同的编译器会编译出迥然不同的目标代码。 (1) -fcprop-registers：因为在函数中把寄存器分配给变量, 所以编译器执行第二次检查以便减少调度依赖性(两个段要求使用相同的寄存器)并且删除不必要的寄存器复制操作 O2：会尝试更多的寄存器级的优化以及指令级的优化，它会在编译期间占用更多的内存和编译时间 Gcc将执行几乎所有的不包含时间和空间折中的优化。当设置O2选项时，编译器并不进行循环打开（）loop unrolling以及函数内联。与O1比较而言，O2优化增加了编译时间的基础上，提高了生成代码的执行效率。 O2打开所有的O1选项，并打开以下选项： (1) -fforce-mem：在做算术操作前，强制将内存数据copy到寄存器中以后再执行。这会使所有的内存引用潜在的共同表达式，进而产出更高效的代码，当没有共同的子表达式时，指令合并将排出个别的寄存器载入。这种优化对于只涉及单一指令的变量, 这样也许不会有很大的优化效果. 但是对于再很多指令(必须数学操作)中都涉及到的变量来说, 这会时很显著的优化, 因为和访问内存中的值相比 ,处理器访问寄存器中的值要快的多。 (1) -foptimize-sibling-calls：优化相关的以及末尾递归的调用。通常, 递归的函数调用可以被展开为一系列一般的指令， 而不是使用分支。 这样处理器的指令缓存能够加载展开的指令并且处理他们, 和指令保持为需要分支操作的单独函数调用相比, 这样更快。 (1) -fstrength-reduce：这种优化技术对循环执行优化并且删除迭代变量。 迭代变量是捆绑到循环计数器的变量, 比如使用变量, 然后使用循环计数器变量执行数学操作的for-next循环。 (1) -fcse-follow-jumps：在公用子表达式消元时，当目标跳转不会被其他路径可达，则扫描整个的跳转表达式。例如，当公用子表达式消元时遇到if…else…语句时，当条为false时，那么公用子表达式消元会跟随着跳转。 (1) -fcse-skip-blocks：与-fcse-follow-jumps类似，不同的是，根据特定条件，跟随着cse跳转的会是整个的blocks (1) -frerun-cse-after-loop：在循环优化完成后，重新进行公用子表达式消元操作。 (1) -frerun-loop-opt：两次运行循环优化(1) -fgcse：执行全局公用子表达式消除pass。这个pass还执行全局常量和copy propagation。这些优化操作试图分析生成的汇编语言代码并且结合通用片段， 消除冗余的代码段。如果代码使用计算性的goto, gcc指令推荐使用-fno-gcse选项。 (1) -fgcse-lm：全局公用子表达式消除将试图移动那些仅仅被自身存储kill的装载操作的位置。这将允许将循环内的load/store操作序列中的load转移到循环的外面（只需要装载一次），而在循环内改变成copy/store序列。在选中-fgcse后，默认打开。 (1) -fgcse-sm：当一个存储操作pass在一个全局公用子表达式消除的后面，这个pass将试图将store操作转移到循环外面去。如果与-fgcse-lm配合使用，那么load/store操作将会转变为在循环前load，在循环后store，从而提高运行效率，减少不必要的操作。 (1) -fgcse-las：全局公用子表达式消除pass将消除在store后面的不必要的load操作，这些load与store通常是同一块存储单元（全部或局部） (1) -fdelete-null-pointer-checks：通过对全局数据流的分析，识别并排出无用的对空指针的检查。编译器假设间接引用空指针将停止程序。 如果在间接引用之后检查指针，它就不可能为空。 (1) -fexpensive-optimizations：进行一些从编译的角度来说代价高昂的优化（这种优化据说对于程序执行未必有很大的好处，甚至有可能降低执行效率，具体不是很清楚） (1) -fregmove：编译器试图重新分配move指令或者其他类似操作数等简单指令的寄存器数目，以便最大化的捆绑寄存器的数目。这种优化尤其对双操作数指令的机器帮助较大。 (1) -fschedule-insns：编译器尝试重新排列指令，用以消除由于等待未准备好的数据而产生的延迟。这种优化将对慢浮点运算的机器以及需要load memory的指令的执行有所帮助，因为此时允许其他指令执行，直到load memory的指令完成，或浮点运算的指令再次需要cpu。(1) -fschedule-insns2：与-fschedule-insns相似。但是当寄存器分配完成后，会请求一个附加的指令计划pass。这种优化对寄存器较小，并且load memory操作时间大于一个时钟周期的机器有非常好的效果。 (1) -fsched-interblock：这种技术使编译器能够跨越指令块调度指令。 这可以非常灵活地移动指令以便等待期间完成的工作最大化。 (1) -fsched-spec-load：允许一些load指令进行一些投机性的动作。（具体不详）相同功能的还有-fsched-spec-load-dangerous，允许更多的load指令进行投机性操作。这两个选项在选中-fschedule-insns时默认打开。 (1) -fcaller-saves：通过存储和恢复call调用周围寄存器的方式，使被call调用的value可以被分配给寄存器，这种只会在看上去能产生更好的代码的时候才被使用。（如果调用多个函数, 这样能够节省时间, 因为只进行一次寄存器的保存和恢复操作, 而不是在每个函数调用中都进行。） (1) -fpeephole2：允许计算机进行特定的观察孔优化(这个不晓得是什么意思)，-fpeephole与-fpeephole2的差别在于不同的编译器采用不同的方式，由的采用-fpeephole，有的采用-fpeephole2，也有两种都采用的。 (1) -freorder-blocks：在编译函数的时候重新安排基本的块，目的在于减少分支的个数，提高代码的局部性。 (1) -freorder-functions：在编译函数的时候重新安排基本的块，目的在于减少分支的个数，提高代码的局部性。这种优化的实施依赖特定的已存在的信息：.text.hot用于告知访问频率较高的函数，.text.unlikely用于告知基本不被执行的函数。 (1) -fstrict-aliasing：这种技术强制实行高级语言的严格变量规则。 对于c和c++程序来说, 它确保不在数据类型之间共享变量. 例如, 整数变量不和单精度浮点变量使用相同的内存位置。 (1) -funit-at-a-time：在代码生成前，先分析整个的汇编语言代码。这将使一些额外的优化得以执行，但是在编译器间需要消耗大量的内存。（有资料介绍说：这使编译器可以重新安排不消耗大量时间的代码以便优化指令缓存。） (1) -falign-functions：这个选项用于使函数对准内存中特定边界的开始位置。 大多数处理器按照页面读取内存，并且确保全部函数代码位于单一内存页面内, 就不需要叫化代码所需的页面。 (1) -falign-jumps：对齐分支代码到2的n次方边界。在这种情况下，无需执行傀儡指令（dummy operations） (1) -falign-loops：对齐循环到2的n次幂边界。期望可以对循环执行多次，用以补偿运行dummy operations所花费的时间。 (1) -falign-labels：对齐分支到2的n次幂边界。这种选项容易使代码速度变慢，原因是需要插入一些dummy operations当分支抵达usual flow of the code. (1) -fcrossjumping：这是对跨越跳转的转换代码处理， 以便组合分散在程序各处的相同代码。 这样可以减少代码的长度， 但是也许不会对程序性能有直接影响 O3： 在O2的基础上进行更多的优化 例如使用伪寄存器网络，普通函数的内联，以及针对循环的更多优化。在包含了O2所有的优化的基础上，又打开了以下优化选项： (1) -finline-functions：内联简单的函数到被调用函数中。(1) -fweb：构建用于保存变量的伪寄存器网络。 伪寄存器包含数据, 就像他们是寄存器一样, 但是可以使用各种其他优化技术进行优化,比如cse和loop优化技术。这种优化会使得调试变得更加的不可能，因为变量不再存放于原本的寄存器中。(1) -frename-registers：在寄存器分配后，通过使用registers left over来避免预定代码中的虚假依赖。这会使调试变得非常困难，因为变量不再存放于原本的寄存器中了。(1) -funswitch-loops：将无变化的条件分支移出循环，取而代之的将结果副本放入循环中。 Os：相当于-O2.5。是使用了所有-O2的优化选项，但又不缩减代码尺寸的方法 GCC 调试选项 GCC允许您将-g与-O配合使用。GCC开启优化编译选项的结果有时可能会令人惊讶： (1) 声明的某些变量可能被删除；(1) 控制流走到您意想不到的位置；(1) 有些语句可能不会执行，因为它们计算的是常量结果或它们的值已经在手边；(1) 有些语句可能会在不同的位置执行，因为它们已经移出了循环。 GCC允许编译时添加额外的调试信息，以便程序进行调试，大部分情况下，你需要编译选项-g就可以满足调试需求。 如果没有使用其他优化选项，请考虑将-Og与-g一起使用。在完全没有-O选项的情况下，一些编译器收集对调试有用的信息根本不会运行，因此-Og可能会带来更好的调试体验。 (1) -g0：不生成调试信息，相当于没有使用-g(1) -g1：生成最小的调试信息，足够在不打算调试的程序中进行堆栈查看。最小调试信息包括函数描述，外部变量，行数表，但不包括局部变量信息(1) -g2：默认-g的调试级别(1) -g3：相对-g，生成额外的信息，例如所有的宏定义 和-O一样，如果多个级别的-g选项同时存在，最后的选项会被生效 很多项目的线上版本都是使用”-O2 -g”的编译选项进行编译 三、IPC篇 epoll原理★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 调用顺序： 123int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout); 首先创建一个epoll对象 使用epoll_ctl对这个对象进行操作，把需要监控的描述添加进去，这些描述如将会以epoll_event结构体的形式组成一颗红黑树 阻塞在epoll_wait，进入大循环，当某个fd上有事件发生时，内核将会把其对应的结构体放入到一个链表中，返回有事件发生的链表 线程和进程的区别★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 僵尸进程★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 单核机器上写多线程程序，是否需要考虑加锁★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。 例如变量自增操作，++i，并非原子操作，汇编层面分为3步：获取变量值，变量值+1，保存。 死锁发生的条件以及如何解决死锁★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的相互等待的现象。死锁发生的四个必要条件如下： 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源； 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链 解决死锁的方法即破坏上述四个条件之一，主要方法如下： 资源一次性分配，从而剥夺请求和保持条件 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 多线程和多进程的区别?分别独占什么资源?★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 重点: 面试官最最关心的一个问题,必须从cpu调度,上下文切换,数据共享,多核cpu利用率,资源占用,等等各方面回答 然后有一个问题必须会被问到：哪些东西是一个线程私有的？答案中必须包含寄存器，否则悲催 多线程和多进程的区别 概览： | 维度 | 多进程 | 多线程 | 总结 || ————-(1) | ————————————————————-(1) | ——————————–(1) | ——-(1) || 数据共享、同步 | 数据是分开的:共享复杂，需要用IPC;同步简单 | 共享简单；同步复杂 | 各有优势 || 内存、CPU | 占用内存多，切换复杂，CPU利用率低 | 占用内存少，切换简单，CPU利用率高 | 线程占优 || 创建销毁、切换 | 创建销毁、切换复杂，速度慢 | 创建销毁、切换简单，速度快 | 线程占优 || 编程调试 | 编程简单，调试简单 | 编程复杂，调试复杂 | 进程占优 || 可靠性 | 进程间不会相互影响 | 一个线程挂掉将导致整个进程挂掉 | 进程占优 || 分布式 | 适应于多核、多机分布，如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布 | 进程占优 | 详细： | 子进程继承父进程的属性 | 子线程继承主线程的属性： || ——————————————-(1) | ———————————————————————————————————————(1) | —————(1) || 实际用户ID，实际组ID，有效用户ID，有效组ID； | 进程中的所有信息对该进程的所有线程都是共享的； || 附加组ID； | 可执行的程序文本； | 程序的全局内存； | 堆内存； || 进程组ID； | 文件描述符； || 会话ID； | 信号的处理是进程中所有线程共享的（注意：如果信号的默认处理是终止该进程那么即是把信号传给某个线程也一样会将进程杀掉）； |控制终端；设置用户ID标志和设置组ID标志；当前工作目录；根目录；文件模式创建屏蔽字（umask）；信号屏蔽和安排；针对任一打开文件描述符的在执行时关闭（close-on-exec）标志；环境；连接的共享存储段；存储映射；资源限制； 进程调度 需要进行CPU调度的情况可以分为四种： (1) 当一个进程从运行状态切换到等待状态时（如I/O请求，wait()调用以便等待一个子进程的结束）(1) 当一个进程从运行状态切换到就绪状态时（如出现了中断）(1) 当一个进程从等待状态切换到就绪状态时（如I/O完成）(1) 当一个进程终止时 如果调度只能发生在第一种和第四种情况下，那么调度方案称为非抢占的或协作的；否则调度方案就是抢占的。 进程调度算法 (1) 先到先服务调度（FCFS）(1) 最短作业优先调度（SJF）(1) 优先级调度(1) 轮转调度（RR）(1) 多级队列调度(1) 多级反馈队列调度 线程调度 在支持线程的操作系统上，内核级线程才是操作系统所调度的。用户级线程是由线程库来进行管理的，而内核并不知道他们 (1) 进程竞争范围(PCS)：通常情况下，PCS通常采用优先级调用，即调度程序选择具有最高优先级的，可运行的线程，且允许一个更高优先级的线程来抢占当前运行的线程(1) 系统竞争范围(SCS)：采用SCS调度来竞争CPU，发生在系统内所有线程之间。采用一对一模型的系统，如Window、Linux、Solaris，只采用SCS调度 进程竞争范围(PCS)涉及到的函数： 12pthread_attr_setscope(pthread_attr_t *attr, int scope)pthread_attr_getscope(pthread_attr_t *attr, int *scope) 线程共享的环境包括: (1) 进程代码段(1) 进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)(1) 进程打开的文件描述符(1) 信号的处理器(1) 进程的当前目录(1) 进程用户ID与进程组ID 线程独享的环境包括: (1) 线程ID(1) 寄存器组的值(1) 线程的堆栈(1) 错误返回码(1) 线程的信号屏蔽码(1) 线程的优先级 总结： (1) 需要频繁创建销毁的优先用线程。实例：web服务器。来一个建立一个线程，断了就销毁线程。要是用进程，创建和销毁的代价是很难承受的。(1) 需要进行大量计算的优先使用线程。所谓大量计算，当然就是要消耗很多cpu，切换频繁了，这种情况先线程是最合适的。实例：图像处理、算法处理(1) 强相关的处理用线程，若相关的处理用进程。什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。一般的server需要完成如下任务：消息收发和消息处理。消息收发和消息处理就是弱相关的任务，而消息处理里面可能又分为消息解码、业务处理，这两个任务相对来说相关性就要强多了。因此消息收发和消息处理可以分进程设计，消息解码和业务处理可以分线程设计。(1) 可能扩展到多机分布的用进程，多核分布的用线程。(1) 都满足需求的情况下，用你最熟悉、最拿手的方式 进程间通信★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 共享内存 消息队列 信号 信号量 套接字 管道 线程通信★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 锁机制 信号量机制 信号机制 进程的状态，以及进程生命周期流程★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 创建状态：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态 就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行 执行状态：进程处于就绪状态被调度后，进程进入执行状态 阻塞状态：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用 终止状态：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 线程锁★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 互斥锁 mutex 自旋锁 读写锁 以前是boost库，在C++17之后添加到std标准库中 无锁 CAS（compare and swap）无锁机制 （1）与锁相比，使用比较交换（下文简称CAS），由于其非阻塞性，它对死锁问题天生免疫，并且，线程间的相互影响也远远比基于锁的方式要小。更为重要的是，使用无锁的方式完全没有锁竞争带来的系统开销，也没有线程间频繁调度带来的开销，因此，它要比基于锁的方式拥有更优越的性能。 （2）无锁的好处： 第一，在高并发的情况下，它比有锁的程序拥有更好的性能； 第二，它天生就是死锁免疫的。 就凭借这两个优势，就值得我们冒险尝试使用无锁的并发。 （3）CAS算法的过程是这样：它包含三个参数CAS(V,E,N): V表示要更新的变量，E表示预期值，N表示新值。 仅当V值等于E值时，才会将V的值设为N， 如果V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。 最后，CAS返回当前V的真实值。 （4）CAS操作是抱着乐观的态度进行的，它总是认为自己可以成功完成操作。当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，CAS操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。 （5）简单地说，CAS需要你额外给出一个期望值，也就是你认为这个变量现在应该是什么样子的。如果变量不是你想象的那样，那说明它已经被别人修改过了。你就重新读取，再次尝试修改就好了。 （6）在硬件层面，大部分的现代处理器都已经支持原子化的CAS指令。在JDK 5.0以后，虚拟机便可以使用这个指令来实现并发操作和并发数据结构，并且，这种操作在虚拟机中可以说是无处不在。 死锁 进程之间调度方式★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 分类 系统进程：操作系统用来管理资源的进程，当系统进程处于运行态时，CPU处于管态，系统之间的关系由操作系统负责 用户进程：操作系统可以独立执行的的用户程序段，当用户进程处于运行态时，CPU处于目态，用户进程之间的关系由用户负责 调度方法 先来先服务调度算法 短作业（进程） 优先调度算法 优先权调度算法 高响应比优先调度算法 基于时间片的轮转调度算法 多级反馈队列调度算法 四、版本特性篇C++11有哪些新特性★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 五、STL篇STL中MAP数据存放形式★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 有序的MAP是红黑树，unordered map底层结构是哈希表 (1) Map映射，map 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。不允许键值重复。 底层实现：红黑树 适用场景：有序键值对不重复映射 unordered map：最长的无重复子字符串 (1) Multimap多重映射。multimap 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。允许键值重复。 底层实现：红黑树 适用场景：有序键值对可重复映射 STL中的智能指针是线程安全的吗★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 同一个shared_ptr被多个线程“读”是安全的。 同一个shared_ptr被多个线程“写”是不安全的。 共享引用计数的不同的shared_ptr被多个线程”写“ 是安全的。 即使多线程下，也能确保最后只析构一次 STL中的容器是线程安全的吗★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 六、数据结构篇map和set考核热度: ★★考核内容 (1) map和set的底层数据结构(1) map和set的共同点和区别(1) map和set的优缺点(1) map和set的使用场景 ★ map和set的底层数据结构 map和set都是C++的关联容器，其底层实现都是红黑树（RB-Tree） ★ map和set的共同点 map和set都是C++的关联容器，其底层实现都是红黑树（RB-Tree）。由于 map 和set所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 map 和set的操作行为，都只是转调 RB-tree 的操作行为。 ★ map和set的区别 map中的元素是key-value（关键字—值）对：关键字起到索引的作用，值则表示与索引相关联的数据；Set与之相对就是关键字的简单集合，set中每个元素只包含一个关键字。 set的迭代器是const的，不允许修改元素的值；map允许修改value，但不允许修改key。其原因是因为map和set是根据关键字排序来保证其有序性的，如果允许修改key的话，那么首先需要删除该键，然后调节平衡，再插入修改后的键值，调节平衡，如此一来，严重破坏了map和set的结构，导致iterator失效，不知道应该指向改变前的位置，还是指向改变后的位置。所以STL中将set的迭代器设置成const，不允许修改迭代器的值；而map的迭代器则不允许修改key值，允许修改value值。 map支持下标操作，set不支持下标操作。map可以用key做下标，map的下标运算符[ ]将关键码作为下标去执行查找，如果关键码不存在，则插入一个具有该关键码和mapped_type类型默认值的元素至map中，因此下标运算符[ ]在map应用中需要慎用，const_map不能用，只希望确定某一个关键值是否存在而不希望插入元素时也不应该使用，mapped_type类型没有默认值也不应该使用。如果find能解决需要，尽可能用find。 ★ map和set的优缺点 优点map:(1) 查询快 缺点map:(1) 频繁的增加、删除操作会让红黑树频繁的调整高度，资源消耗大 set: ★★ map和set的使用场景 map:(1) 临时存储key-value结构的数据 unordered_map和hash_map考核热度: ★★ 考核内容 (1) 底层数据结构(1) 共同点和区别(1) 优缺点(1) 使用场景(1) hash_map处理冲突的方法 ★ 底层数据结构 map和set都是C++的关联容器，其底层实现都是红黑树（RB-Tree） ★ 共同点 都是key-value容器 底层数据结构都是hash表 ★ 区别 unordered_map是C++11标准的产物 unordered_map ★ 优缺点 七、内存管理篇 malloc 、brk和mmap系统调用★ 热度: ★★★★★★ 考核内容1. malloc2. brk系统调用3. mmap系统调用★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 Malloc函数用于动态分配内存。为了减少内存碎片和系统调用的开销，malloc其采用内存池的方式，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。当用户申请内存时，直接从堆区分配一块合适的空闲块。Malloc采用隐式链表结构将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时malloc采用显示链表结构来管理所有的空闲块，即使用一个双向链表将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。当进行内存分配时，Malloc会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配；当进行内存合并时，malloc采用边界标记法，根据每个块的前后块是否已经分配来决定是否进行块合并。Malloc在申请内存时，一般会通过brk或者mmap系统调用进行申请。其中当申请内存小于128K时，会使用系统函数brk在堆区中分配；而当申请内存大于128K时，会使用系统函数mmap在映射区分配。 C++的内存管理★ 热度: ★★★★★★ 考核内容1. 代码段2. 数据段3. bss段4. 堆区5. 栈6. 映射区★★ 什么是C++内存泄漏 在C++中，虚拟内存分为代码段、数据段、BSS段、堆区、文件映射区以及栈区六部分。代码段:包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码。数据段：存储程序中已初始化的全局变量和静态变量bss段：存储未初始化的全局变量和静态变量（局部+全局），以及所有被初始化为0的全局变量和静态变量。堆区：调用new/malloc函数时在堆区动态分配内存，同时需要调用delete/free来手动释放申请的内存。映射区:存储动态链接库以及调用mmap函数进行的文件映射栈：使用栈空间存储函数的返回地址、参数、局部变量、返回值 C++的内存泄漏★ 热度: ★★★★★★ 考核内容1. 什么是内存泄漏2. 造成内存泄漏的原因3. 内存泄漏检测工具4. 防止内存泄漏★★ 什么是内存泄漏 内存泄漏通常是由于调用了malloc/new等内存申请的操作，但是缺少了对应的free/delete。内存泄漏(memory leak)是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。★★ 造成内存泄漏的原因 1. 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak.2. 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。3. 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。★★ 内存泄漏检测工具 1. gdb的mtrace2. Valgrind工具★★ 防止内存泄漏 1. 统一内存管理，如设计内存池2. 考虑用智能指针管理内存的使用 无锁内存池、无锁队列和顺序锁★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 常见问题 关于CAS等原子操作无锁队列的链表实现CAS的ABA问题解决ABA的问题用数组实现无锁队列 关于CAS等原子操作 Compare &amp; Swap 12345678910111213bool compare_and_swap (int* reg, int oldval, int newval)&#123; int old_reg_val = \\*reg; if (old_reg_val == oldval) &#123; \\*reg = newval; return true; &#125; return false;&#125; 与CAS相似的还有下面的原子操作：（这些东西大家自己看Wikipedia，也没什么复杂的） (1) Fetch And Add，一般用来对变量做 +1 的原子操作(1) Test-and-set，写值到某个内存位置并传回其旧值。汇编指令BST(1) Test and Test-and-set，用来低低Test-and-Set的资源争夺情况 在实际的C/C++程序中，CAS的各种实现版本如下： (1) GCC的CAS123bool __sync_bool_compare_and_swap (type *ptr, type oldval type newval, ...)type __sync_val_compare_and_swap (type *ptr, type oldval type newval, ...) (1) C++11中的CAS C++11中的STL中的atomic类的函数可以让你跨平台。（完整的C++11的原子操作可参看 Atomic Operation Library）1234567template&lt; class T &gt;bool atomic_compare_exchange_weak( std::atomic* obj, T* expected, T desired );template&lt; class T &gt;bool atomic_compare_exchange_weak( volatile std::atomic* obj, T* expected, T desired ); CAS的缺点 循环时间长开销很大 CAS配合无限循环使用，如果CAS失败，会一直尝试，带给CPU很大的开销 只能保证一个变量的原子操作 CAS只能保证一个变量的原子操作,无法直接保证多个变量操作的原子性。 但是可以通过以下两种办法来解决：(1) 使用互斥锁来保证原子性(1) 将多个变量封装成对象，通过 AtomicReference 来保证原子性。 ABA问题 CAS需要三步：(1) 从内存V中读取A(1) 比较A值和目标值B(1) 用原子操作将内存V中的A值修改为B值，试想如果在比较过程中，另外一个线程将内存V中的A修改成了C，又被修改回去，CAS会认为这段时间内存的值从未被修改过，这个问题叫做ABA问题。因此，使用CAS时需要注意ABA问题是否会影响并发程序的正确性，如果有影响，则传统的互斥同步可能会比原子更高效。 无锁队列方案1。 boost方案boost提供了三种无锁方案，分别适用不同使用场景。 (1) boost::lockfree::queue是支持多个生产者和多个消费者线程的无锁队列。(1) boost::lockfree::stack是支持多个生产者和多个消费者线程的无锁栈。(1) boost::lockfree::spsc_queue是仅支持单个生产者和单个消费者线程的无锁队列，比boost::lockfree::queue性能更好。 Boost无锁数据结构的API通过轻量级原子锁实现lock-free，不是真正意义的无锁。Boost提供的queue可以设置初始容量，添加新元素时如果容量不够，则总容量自动增长；但对于无锁数据结构，添加新元素时如果容量不够，总容量不会自动增长。 ConcurrentQueueConcurrentQueue是基于C实现的工业级无锁队列方案。 ZeroMQ 无锁队列实现 内存池★ 热度: ★★★★★★ 考核内容1.什么是C++内存泄漏2.如何检测内存泄漏3.如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 Gtcmalloc：谷歌内存分配库 Jemalloc：Facebook内存分配库 Ptmalloc：Linux内存分配库","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"(1) 面试 (1) C++","slug":"1-面试-1-C","permalink":"https://lives.xtcgch.ink/tags/1-面试-1-C/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"【求职】求职之Linux篇","slug":"求职之Linux篇-20210909","date":"2021-09-09T07:58:17.000Z","updated":"2021-11-23T14:57:11.703Z","comments":true,"path":"2021/09/09/求职之Linux篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/09/求职之Linux篇/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 ★★★ 目录 ★★★★★★ 一、基础篇 ★★★ 1 select，epoll的区别 2 Linux虚拟地址空间 3 fork和vfork的区别 3 虚函数的实现的基本原理 4 如何判断一个程序是死锁还是死循环 5 gdb调试命令 6 gdb step和next的区别 7 gdb 查看内存 8 gdb多线程调试 9 gdb查看调用堆栈 10 gdb 带参数调试 11 gdb list命令 12 用户态到内核态的转化原理 13 系统调用 14 6种微服务RPC框架 15 软硬链接 ★★★ 二、进阶篇 ★★★ 一、基础篇 select，epoll的区别 Linux虚拟地址空间为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。 虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。 还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。 请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 虚拟内存的好处： 1.扩大地址空间 2.内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。 3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。 4.当进程通信时，可采用虚存共享的方式实现。 5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存 6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高 7.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片 虚拟内存的代价： 1.虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存 2.虚拟地址到物理地址的转换，增加了指令的执行时间。 3.页面的换入换出需要磁盘I/O，这是很耗时的 4.如果一页中只有一部分数据，会浪费内存。 fork和vfork的区别fork的基础知识：fork:创建一个和当前进程映像一样的进程可以通过fork( )系统调用： 12345#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;pid_t fork(void); 成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。 最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。 在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。 vfork的基础知识： 在实现写时复制之前，Unix的设计者们就一直很关注在fork后立刻执行exec所造成的地址空间的浪费。BSD的开发者们在3.0的BSD系统中引入了vfork( )系统调用。12345#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;pid_t vfork(void); 除了子进程必须要立刻执行一次对exec的系统调用，或者调用_exit( )退出，对vfork( )的成功调用所产生的结果和fork( )是一样的。vfork( )会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork( )避免了地址空间的按页复制。在这个过程中，父进程和子进程共享相同的地址空间和页表项。实际上vfork( )只完成了一件事：复制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。 vfork( )是一个历史遗留产物，Linux本不应该实现它。需要注意的是，即使增加了写时复制，vfork( )也要比fork( )快，因为它没有进行页表项的复制。然而，写时复制的出现减少了对于替换fork( )争论。实际上，直到2.2.0内核，vfork( )只是一个封装过的fork( )。因为对vfork( )的需求要小于fork( )，所以vfork( )的这种实现方式是可行的。 补充知识点：写时复制 Linux采用了写时复制的方法，以减少fork时对父进程空间进程整体复制带来的开销。 写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。 写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。 在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享。 现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。 在调用fork( )时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。 fork和vfork的区别： fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段 fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。 vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。 当需要改变共享数据段中变量的值，则拷贝父进程。 如何判断一个程序是死锁还是死循环1. 定位 死循环 线程： 活跃中 死锁 线程： 挂起中 命令： top 、 ps 用户态到内核态的转化原理用户态切换到内核态的3种方式 系统调用 这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。 异常 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。 外围设备的中断 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 切换操作 从出发方式看，可以在认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括： 从当前进程的描述符中提取其内核栈的ss0及esp0信息。 使用ss0和esp0指向的内核栈将当前进程的cs,eip，eflags，ss,esp信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。 将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。 软硬链接inode是什么 理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 inode的内容 inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode 文件数据block的位置 可以用stat命令，查看某个文件的inode信息：1stat example.txt inode的大小 inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。1 df -i 查看每个inode节点的大小，可以用如下命令： 1 sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot; inode号码 每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。 表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 使用ls -i命令，可以看到文件名对应的inode号码： 1ls -i example.txt 硬链接 具有相同inode节点号的多个文件互为硬链接文件； 删除硬链接文件或者删除源文件任意之一，文件实体并未被删除； 只有删除了源文件和所有对应的硬链接文件，文件实体才会被删除； 硬链接文件是文件的另一个入口； 可以通过给文件设置硬链接文件来防止重要文件被误删； 创建硬链接命令 ln 源文件 硬链接文件； 硬链接文件是普通文件，可以用rm删除； 对于静态文件（没有进程正在调用），当硬链接数为0时文件就被删除。注意：如果有进程正在调用，则无法删除或者即使文件名被删除但空间不会释放。 软链接 软链接类似windows系统的快捷方式； 软链接里面存放的是源文件的路径，指向源文件； 删除源文件，软链接依然存在，但无法访问源文件内容； 软链接失效时一般是白字红底闪烁； 创建软链接命令 ln -s 源文件 软链接文件； 软链接和源文件是不同的文件，文件类型也不同，inode号也不同； 软链接的文件类型是“l”，可以用rm删除。 硬链接和软链接的区别 原理上，硬链接和源文件的inode节点号相同，两者互为硬链接。软连接和源文件的inode节点号不同，进而指向的block也不同，软连接block中存放了源文件的路径名。 实际上，硬链接和源文件是同一份文件，而软连接是独立的文件，类似于快捷方式，存储着源文件的位置信息便于指向。 使用限制上，不能对目录创建硬链接，不能对不同文件系统创建硬链接，不能对不存在的文件创建硬链接。可以对目录创建软连接，可以跨文件系统创建软连接，可以对不存在的文件创建软连接。 inode的特殊作用 由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 移动文件或重命名文件，只是改变文件名，不影响inode号码。 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。 二、进阶篇","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"求职之网络通信篇","slug":"求职之网络通信篇-20210909","date":"2021-09-09T07:53:39.000Z","updated":"2021-11-23T14:59:18.775Z","comments":true,"path":"2021/09/09/求职之网络通信篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/09/求职之网络通信篇/","excerpt":"摘要： 记录网络通信常见面试题","text":"摘要： 记录网络通信常见面试题 一、基础知识二、HTTP/HTTPS HTTP长短连接区别 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 HTTPS建立连接的过程 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 IP分片与重组 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 在HTTP通信中如何防止报文被篡改 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 在浏览器中输入URL后执行的全部过程 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 网络层分片的原因与具体实现 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 糊涂窗口综合症 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 三、TCP/UDP TCP怎么保证可靠性，并且简述一下TCP建立连接和断开连接的过程★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 TCP保证可靠性：（1）序列号、确认应答、超时重传 数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是2*RTT(报文段往返时间）+一个偏差值。 （2）窗口控制与高速重发控制/快速重传（重复确认应答） TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。 使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒…… （3）拥塞控制 如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制。 慢启动：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个rtt），将拥塞窗口大小*2。 拥塞避免：设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小+1），以此来避免拥塞。 将报文段的超时重传看做拥塞，则一旦发生超时重传，我们需要先将阈值设为当前窗口大小的一半，并且将窗口大小设为初值1，然后重新进入慢启动过程。 快速重传：在遇到3次重复确认应答（高速重发控制）时，代表收到了3个报文段，但是这之前的1个段丢失了，便对它进行立即重传。 然后，先将阈值设为当前窗口大小的一半，然后将拥塞窗口大小设为慢启动阈值+3的大小。 这样可以达到：在TCP通信时，网络吞吐量呈现逐渐的上升，并且随着拥堵来降低吞吐量，再进入慢慢上升的过程，网络不会轻易的发生瘫痪。 三次握手： Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 四次挥手： 由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 1.数据传输结束后，客户端的应用进程发出连接释放报文段，并停止发送数据，客户端进入FIN_WAIT_1状态，此时客户端依然可以接收服务器发送来的数据。 2.服务器接收到FIN后，发送一个ACK给客户端，确认序号为收到的序号+1，服务器进入CLOSE_WAIT状态。客户端收到后进入FIN_WAIT_2状态。 3.当服务器没有数据要发送时，服务器发送一个FIN报文，此时服务器进入LAST_ACK状态，等待客户端的确认 4.客户端收到服务器的FIN报文后，给服务器发送一个ACK报文，确认序列号为收到的序号+1。此时客户端进入TIME_WAIT状态，等待2MSL（MSL：报文段最大生存时间），然后关闭连接 2 TCP的模型，状态转移 4 TCP拥塞控制 拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口——cwnd。1、慢开始 最开始发送方的拥塞窗口为1，由小到大逐渐增大发送窗口和拥塞窗口。每经过一个传输轮次，拥塞窗口cwnd加倍。当cwnd超过慢开始门限，则使用拥塞避免算法，避免cwnd增长过大。 2、拥塞避免 每经过一个往返时间RTT，cwnd就增长1。 在慢开始和拥塞避免的过程中，一旦发现网络拥塞，就把慢开始门限设为当前值的一半，并且重新设置cwnd为1，重新慢启动。（乘法减小，加法增大） 3、快重传 接收方每次收到一个失序的报文段后就立即发出重复确认，发送方只要连续收到三个重复确认就立即重传（尽早重传未被确认的报文段）。 4、快恢复 当发送方连续收到了三个重复确认，就乘法减半（慢开始门限减半），将当前的cwnd设置为慢开始门限，并且采用拥塞避免算法（连续收到了三个重复请求，说明当前网络可能没有拥塞）。 采用快恢复算法时，慢开始只在建立连接和网络超时才使用。 达到什么情况的时候开始减慢增长的速度？ 采用慢开始和拥塞避免算法的时候 一旦cwnd&gt;慢开始门限，就采用拥塞避免算法，减慢增长速度 一旦出现丢包的情况，就重新进行慢开始，减慢增长速度 采用快恢复和快重传算法的时候 一旦cwnd&gt;慢开始门限，就采用拥塞避免算法，减慢增长速度 一旦发送方连续收到了三个重复确认，就采用拥塞避免算法，减慢增长速度 5 阻塞，非阻塞，同步，异步 阻塞和非阻塞：调用者在事件没有发生的时候，一直在等待事件发生，不能去处理别的任务这是阻塞。调用者在事件没有发生的时候，可以去处理别的任务这是非阻塞。 同步和异步：调用者必须循环自去查看事件有没有发生，这种情况是同步。调用者不用自己去查看事件有没有发生，而是等待着注册在事件上的回调函数通知自己，这种情况是异步 10 TCP半包、粘包 TCP半包、粘包产生的原因 TCP发送数据原因： 因为TCP本身传输的数据包大小就有限制，所以应用发出的消息包过大，TCP会把应用消息包拆分为多个TCP数据包发送出去。 Negal算法的优化，当应用发送数据包太小，TCP为了减少网络请求次数的开销，它会等待多个消息包一起，打成一个TCP数据包一次发送出去。 TCP接收方的原因 因为TCP缓冲区里的数据都是字符流的形式，没有明确的边界，因为数据没边界，所以应用从TCP缓冲区中读取数据时就没办法指定一个或几个消息一起读，而只能选择一次读取多大的数据流，而这个数据流中就可能包含着某个消息包的一部分数据 应用层定义消息边界的几种方式 长度边界 应用层在发送消息的时候指定每个消息的固定长度，比如固定每个消息为1K，那么当发送时消息不满1K时，用固定的字符串填充，当接收方读取消息的时候，每次也截取1k长度的流作为一个消息l来解析。这种方式的问题在于应用层不能发送超过1K大小的数据，所以使用这种方式的前提知道了消息大小会在哪个范围之内，如果不能确定消息的大小范围不太适合用这种方式，这样会导致大的消息发出去会有问题，小的消息又需要大量的数据填充，不划算。 符号边界 应用层在发送消息前和发送消息后标记一个特殊的标记符，比如 &amp;符号，当接收方读取消息时，根据&amp;符号的流码来截取消息的开始和结尾。这种方式的问题在于发送的消息内容里面本身就包含用于切分消息的特殊符号，所以在定义消息切分符时候尽量用特殊的符号组合。 组合边界 这种方式先是定义一个Header+Body格式，Header消息头里面定义了一个开始标记+一个内容的长度，这个内容长度就是Body的实际长度，Body里面是消息内容，当接收方接收到数据流时，先根据消息头里的特殊标记来区分消息的开始，获取到消息头里面的内容长度描述时，再根据内容长度描述来截取Body部分。 28 优雅的关闭连接 优雅关闭：如果发送缓存中还有数据未发出则其发出去，并且收到所有数据的ACK之后，发送FIN包，开始关闭过程。TCP连接线关闭一个方向，此时另外一个方向还是可以正常进行数据传输。 强制关闭：如果缓存中还有数据，则这些数据都将被丢弃，然后发送RST包，直接重置TCP连接。两边都关闭了，服务端处理完的信息没有正常传给客户端。 一、使用shudown优雅的关闭连接 close()和shutdown()的区别 close会关闭连接了，并释放所有连接对应的资源，而shutdown并不会释放掉套接字和所有资源。 close有引用计数，例如父子进程都打开了某个文件描述符，其中某个进程调用了close函数，会使close函数的引用计数减1，直到套接字的引用计数为0，才会真正的关闭连接。而shutdown函数可以无视引用计数，直接关闭连接。 close的引用计数的存在导致不一定会发出FIN结束报文，而shutdown一定会发出FIN报文。 shutdown() 用来关闭连接，而不是套接字，不管调用多少次 shutdown()，套接字依然存在，直到调用 close() / closesocket() 将套接字从内存清除。 调用 close()关闭套接字时，或调用 shutdown() 关闭输出流时，都会向对方发送 FIN 包。FIN 包表示数据传输完毕，计算机收到 FIN 包就知道不会再有数据传送过来。 默认情况下，close()引用计数为0后会立即往网络中发送FIN包，不管输出缓冲区中是否还有数据，而shutdown() 会等输出缓冲区中的数据传输完毕再发送FIN包。也就意味着，调用 close()将丢失输出缓冲区中的数据，而调用 shutdown() 不会。 二、使用setsockopt设置SO_LINGER实现优雅的关闭连接 LINGER LINGER结构包含了指定套接字的信息，当调用了close()函数关闭该套接字时，LINGER结构中的信息指定了如何处理未发送的数据。 1234567typedef struct linger &#123; u_short l_onoff; u_short l_linger; &#125; LINGER, *PLINGER, *LPLINGER; l_onoff l_linger close行为 发送队列 底层行为 零 忽略 立即返回 保持直至发送完成 系统接管套接字并保证将数据发送至对端。（就是正常的close） 非零 零 立即返回 立即放弃 直接发送RST包，自身立即复位，不用经过2MSL状态。对端收到复位错误号 非零 非零 阻塞直到l_linger时间超时或数据发送完成。(套接字必须设置为阻塞) 在超时时间段内保持尝试发送，若超时则立即放弃 超时则同第二种情况，若发送完成则皆大欢喜 setsockopt 1234567#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt; int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen);int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); 通过setsockopt可以设置SO_LINGER,从而实现优雅的关闭连接12struct linger tmp = &#123;1, 1&#125;;setsockopt(sockfd, SOL_SOCKET, SO_LINGER, &amp;tmp, sizeof(tmp)); UDP包的最大大小是多少? 65507字节 udp包包头有2个byte表示长度，2^16-1=64K-1=65535，udp包头占8字节, ip包头占20字节, 65535-28 = 65507 如果要发送的udp报文大于65507怎么办? 需要在应用层由开发者自己分片发送. 分片的粒度最大65507字节. 系统的sendto函数是不支持大于65507字节的单包发送的. ET和LT的区别? 29 io多路复用? 半连接队列和 SYN Flood 攻击的关系 TCP快速打开的原理(TFO) QUIC协议 tcp 怎么保证数据包有序 tcp 怎么保证数据包有序 四、项目实战 Linux如何查看一个端口号被哪些进程使用 ★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 lsof -i:端口号 netstat -tunlp|grep 端口号 五、特定场景 网络通信发现延迟大，如何定位和解决★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 ★ 定位原因 ★ Netsensor高延迟快速定位解码 ★ 解决方案 ★ 针对传输距离延迟：分析TCP连接中三次握手数据包的时间间隔，查看客户端网络延迟、服务端网络延迟，定位延迟位置采用多连接或其他传输层协议，避免网络延迟给TCP传输带来的影响 针对带宽延迟：通过分析TCP传输的性能，确定是否存在带宽延迟看。通过计算传输的数据量和链路带宽容量，来确定带宽对传输延迟的影响。增加网络带宽 针对TCP连接慢：利用科来网络回溯分析系统捕获应用通讯数据，通过定义应用直接查看三次握手延迟，及客户端、服务器延迟，快速判断TCP连接较慢是发生在客户端还是服务器。提升网络传输过程中的传输性能 针对应用交易处理慢：利用科来网络回溯分析系统捕获应用通讯数据，通过定义应用直接查看客户端请求时间和服务器响应时间，判断服务器是否存在应用交易处理响应慢的现象 针对DNS服务器响应慢：利用科来网络回溯分析系统捕获DNS通讯数据，分析DNS请求和响应数据包，查看是否存在DNS服务器响应慢的现象。优化DNS服务器的软硬件设置 针对数据库服务器响应慢：利用科来网络回溯分析系统捕获数据库通讯数据，分析后台数据库的交易处理请求和响应数据包，查看是否存在数据库交易处理慢的现象。优化数据库服务器的软硬件配置，优化数据库操作脚本 网络通信发现延迟大，如何定位和解决★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏 网络通信发现延迟大，如何定位和解决★ 热度: ★★★★★★ 考核内容1. 什么是C++内存泄漏2. 如何检测内存泄漏3. 如何防止内存泄漏★★ 什么是C++内存泄漏 ★★ 如何检测内存泄漏 ★★ 如何防止内存泄漏","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"},{"name":"网络通信","slug":"网络通信","permalink":"https://lives.xtcgch.ink/tags/网络通信/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"【求职】求职之数据库篇","slug":"求职之数据库篇-20210908","date":"2021-09-08T15:26:24.000Z","updated":"2021-11-23T14:53:36.641Z","comments":true,"path":"2021/09/08/求职之数据库篇/","link":"","permalink":"https://lives.xtcgch.ink/2021/09/08/求职之数据库篇/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 面经一 一、基础知识 什么是MySQL 百度百科上的解释：MySQL是一种开放源代码的关系型数据库管理系统（RDBMS），使用最常用的数据库管理语言–结构化查询语言（SQL）进行数据库管理。MySQL是开放源代码的，因此任何人都可以在General Public License的许可下下载并根据个性化的需要对其进行修改。 什么是最左前缀原则？什么是最左匹配原则 就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 数据库的三大范式 第一范式：确保每列保持原子性，数据表中的所有字段值都是不可分解的原子值。第二范式：确保表中的每列都和主键相关第三范式：确保每列都和主键列直接相关而不是间接相关 二、数据类型 MySQL的数据类型有哪些 整数 TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT分别占用8、16、24、32、64位存储空间。值得注意的是，INT(10)中的10只是表示显示字符的个数，并无实际意义。一般和UNSIGNED ZEROFILL配合使用才有实际意义，例如，数据类型INT(3)，属性为UNSIGNED ZEROFILL，如果插入的数据为3的话，实际存储的数据为003。 浮点数 FLOAT、DOUBLE及DECIMAL为浮点数类型，DECIMAL是利用字符串进行处理的，能存储精确的小数。相比于FLOAT和DOUBLE，DECIMAL的效率更低些。FLOAT、DOUBLE及DECIMAL都可以指定列宽，例如FLOAT(5,2)表示一共5位，两位存储小数部分，三位存储整数部分。 字符串 字符串常用的主要有CHAR和VARCHAR，VARCHAR主要用于存储可变长字符串，相比于定长的CHAR更节省空间。CHAR是定长的，根据定义的字符串长度分配空间。 应用场景：对于经常变更的数据使用CHAR更好，CHAR不容易产生碎片。对于非常短的列也是使用CHAR更好些，CHAR相比于VARCHAR在效率上更高些。一般避免使用TEXT/BLOB等类型，因为查询时会使用临时表，造成严重的性能开销。 日期 比较常用的有year、time、date、datetime、timestamp等，datetime保存从1000年到9999年的时间，精度位秒，使用8字节的存储空间，与时区无关。timestamp和UNIX的时间戳相同，保存从1970年1月1日午夜到2038年的时间，精度到秒，使用四个字节的存储空间，并且与时区相关。 应用场景：尽量使用timestamp，相比于datetime它有着更高的空间效率。 三、引擎 MySQL常用的存储引擎有什么？它们有什么区别？ InnoDB InnoDB是MySQL的默认存储引擎，支持事务、行锁和外键等操作。 MyISAM MyISAM是MySQL5.1版本前的默认存储引擎，MyISAM的并发性比较差，不支持事务和外键等操作，默认的锁的粒度为表级锁。 事项 InnoDB MyISAM 外键 支持 不支持 事务 支持 不支持 锁 支持表锁和行锁 支持表锁 可恢复性 根据事务日志进行恢复 无事务日志 表结构 数据和索引是集中存储的，.ibd和.frm 数据和索引是分开存储的，数据.MYD，索引.MYI 查询性能 一般情况相比于MyISAM较差 一般情况相比于InnoDB较好 索引 聚簇索引 非聚簇索引 四、索引 什么是索引 索引是对数据库表的一列或者多列的值进行排序一种结构，使用索引可以快速访问数据表中的特定信息 索引的优缺点 优点： 大大加快数据检索的速度。将随机I/O变成顺序I/O(因为B+树的叶子节点是连接在一起的)加速表与表之间的连接 缺点： 从空间角度考虑，建立索引需要占用物理空间从时间角度 考虑，创建和维护索引都需要花费时间，例如对数据进行增删改的时候都需要维护索引。 索引的数据结构 B+树索引 B+树的索引又可以分为主索引和辅助索引。其中主索引为聚簇索引，辅助索引为非聚簇索引 B树索引 覆盖索引 哈希索引 哈希索引是基于哈希表实现的，对于每一行数据，存储引擎会对索引列通过哈希算法进行哈希计算得到哈希码，并且哈希算法要尽量保证不同的列值计算出的哈希码值是不同的，将哈希码的值作为哈希表的key值，将指向数据行的指针作为哈希表的value值。这样查找一个数据的时间复杂度就是o(1)，一般多用于精确查找 Hash索引和B+树的区别 因为两者数据结构上的差异导致它们的使用场景也不同，哈希索引一般多用于精确的等值查找，B+索引则多用于除了精确的等值查找外的其他查找。在大多数情况下，会选择使用B+树索引。 哈希索引不支持排序，因为哈希表是无序的。 哈希索引不支持范围查找。 哈希索引不支持模糊查询及多列索引的最左前缀匹配。 因为哈希表中会存在哈希冲突，所以哈希索引的性能是不稳定的，而B+树索引的性能是相对稳定的，每次查询都是从根节点到叶子节点 B树和B+树的区别 B树中的内部节点和叶子节点均存放键和值，而B+树的内部节点只有键没有值，叶子节点存放所有的键和值。 B＋树的叶子节点是通过相连在一起的，方便顺序检索 数据库为什么使用B+树而不是B树 B树适用于随机检索，而B+树适用于随机检索和顺序检索 B+树的空间利用率更高，因为B树每个节点要存储键和值，而B+树的内部节点只存储键，这样B+树的一个节点就可以存储更多的索引，从而使树的高度变低，减少了I/O次数，使得数据检索速度更快。 B+树的叶子节点都是连接在一起的，所以范围查找，顺序查找更加方便 B+树的性能更加稳定，因为在B+树中，每次查询都是从根节点到叶子节点，而在B树中，要查询的值可能不在叶子节点，在内部节点就已经找到 索引的类型有哪些 MySQL主要的索引类型主要有FULLTEXT，HASH，BTREE，RTREE FULLTEXT FULLTEXT即全文索引，MyISAM存储引擎和InnoDB存储引擎在MySQL5.6.4以上版本支持全文索引，一般用于查找文本中的关键字，而不是直接比较是否相等，多在CHAR，VARCHAR，TAXT等数据类型上创建全文索引。全文索引主要是用来解决WHERE name LIKE “%zhang%”等针对文本的模糊查询效率低的问题。 HASH HASH即哈希索引，哈希索引多用于等值查询，时间复杂夫为o(1)，效率非常高，但不支持排序、范围查询及模糊查询等。 BTREE BTREE即B+树索引，INnoDB存储引擎默认的索引，支持排序、分组、范围查询、模糊查询等，并且性能稳定。 RTREE RTREE即空间数据索引，多用于地理数据的存储，相比于其他索引，空间数据索引的优势在于范围查找 索引的种类有哪些 主键索引：数据列不允许重复，不能为NULL，一个表只能有一个主键索引 组合索引：由多个列值组成的索引。 唯一索引：数据列不允许重复，可以为NULL，索引列的值必须唯一的，如果是组合索引，则列值的组合必须唯一。 全文索引：对文本的内容进行搜索。 普通索引：基本的索引类型，可以为NULL 什么是聚簇索引，什么是非聚簇索引 聚簇索引和非聚簇索引最主要的区别是数据和索引是否分开存储。 聚簇索引：将数据和索引放到一起存储，索引结构的叶子节点保留了数据行。非聚簇索引：将数据进和索引分开存储，索引叶子节点存储的是指向数据行的地址。在InnoDB存储引擎中，默认的索引为B+树索引，利用主键创建的索引为主索引，也是聚簇索引，在主索引之上创建的索引为辅助索引，也是非聚簇索引。为什么说辅助索引是在主索引之上创建的呢，因为辅助索引中的叶子节点存储的是主键。 在MyISAM存储引擎中，默认的索引也是B+树索引，但主索引和辅助索引都是非聚簇索引，也就是说索引结构的叶子节点存储的都是一个指向数据行的地址。并且使用辅助索引检索无需访问主键的索引 非聚簇索引一定会进行回表查询吗上面是说了非聚簇索引的叶子节点存储的是主键，也就是说要先通过非聚簇索引找到主键，再通过聚簇索引找到主键所对应的数据，后面这个再通过聚簇索引找到主键对应的数据的过程就是回表查询，那么非聚簇索引就一定会进行回表查询吗？ 答案是不一定的，这里涉及到一个索引覆盖的问题，如果查询的数据再辅助索引上完全能获取到便不需要回表查询。例如有一张表存储着个人信息包括id、name、age等字段。假设聚簇索引是以ID为键值构建的索引，非聚簇索引是以name为键值构建的索引，select id,name from user where name = ‘zhangsan’;这个查询便不需要进行回表查询因为，通过非聚簇索引已经能全部检索出数据，这就是索引覆盖的情况。如果查询语句是这样，select id,name,age from user where name = ‘zhangsan’;则需要进行回表查询，因为通过非聚簇索引不能检索出age的值。那应该如何解决那呢？只需要将索引覆盖即可，建立age和name的联合索引再使用select id,name,age from user where name = ‘zhangsan’;进行查询即可。 所以通过索引覆盖能解决非聚簇索引回表查询的问题 五、事务 事务的四大特性是什么（ACID）原子性：原子性是指包含事务的操作要么全部执行成功，要么全部失败回滚。一致性：一致性指事务在执行前后状态是一致的。隔离性：一个事务所进行的修改在最终提交之前，对其他事务是不可见的。持久性：数据一旦提交，其所作的修改将永久地保存到数据库中。 六、锁 判断锁的级别例子: 假设表foods ，存在有id跟name、status三个字段，id是主键，status有索引。 例1: (明确指定主键，并且有此记录，行级锁)SELECT * FROM foods WHERE id=1 FOR UPDATE; SELECT * FROM foods WHERE id=1 and name=’咖啡色的羊驼’ FOR UPDATE; 例2: (明确指定主键/索引，若查无此记录，无锁)SELECT * FROM foods WHERE id=-1 FOR UPDATE; 例3: (无主键/索引，表级锁)SELECT * FROM foods WHERE name=’咖啡色的羊驼’ FOR UPDATE; 例4: (主键/索引不明确，表级锁)SELECT * FROM foods WHERE id&lt;&gt;’3’ FOR UPDATE; SELECT * FROM foods WHERE id LIKE ‘3’ FOR UPDATE; for update的注意点1.for update 仅适用于InnoDB，并且必须开启事务，在begin与commit之间才生效 MySQL中的锁升级锁升级是指将当前锁的粒度降低，如一把行锁升级唯一把页锁，或者将页锁升级为表锁，如果在数据库设计中认为锁是一中稀有资源，哪么就会频繁有锁升级的现象 发生锁升级的情况: 当一条SQL语句对一个对象上持有的锁数量超锁了阈值，默认这个阈值为5000，但是对于不同对象不会发生锁升级 锁资源占用的内存超过激活内存的百分之40 就会发生锁升级 注意： innoDB 引擎不存在锁升级的问题 数据库锁的类型有哪些 级别 资源开销 上锁速度 是否会死锁 锁的粒度 并发度 表级锁 小 快 不会 大 低 行级锁 大 慢 会 小 高 页级锁 一般 一般 不会 一般 一般 对象 InnoDB MyIsAM 默认锁 行锁 表锁 锁的类型 排他锁 共享锁 什么是死锁？如何避免 死锁是指两个或者两个以上进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象。在MySQL中，MyISAM是一次获得所需的全部锁，要么全部满足，要么等待，所以不会出现死锁。在InnoDB存储引擎中，除了单个SQL组成的事务外，锁都是逐步获得的，所以存在死锁问题。 如何避免MySQL发生死锁或锁冲突： 如果不同的程序并发存取多个表，尽量以相同的顺序访问表。 在程序以批量方式处理数据的时候，如果已经对数据排序，尽量保证每个线程按照固定的顺序来处理记录。 在事务中，如果需要更新记录，应直接申请足够级别的排他锁，而不应该先申请共享锁，更新时在申请排他锁，因为在当前用户申请排他锁时，其他事务可能已经获得了相同记录的共享锁，从而造成锁冲突或者死锁。 尽量使用较低的隔离级别 尽量使用索引访问数据，使加锁更加准确，从而减少锁冲突的机会 合理选择事务的大小，小事务发生锁冲突的概率更低 尽量用相等的条件访问数据，可以避免Next-Key锁对并发插入的影响。 不要申请超过实际需要的锁级别，查询时尽量不要显示加锁 对于一些特定的事务，可以表锁来提高处理速度或减少死锁的概率。 什么是数据库的乐观锁和悲观锁，如何实现 乐观锁：系统假设数据的更新在大多数时候是不会产生冲突的，所以数据库只在更新操作提交的时候对数据检测冲突，如果存在冲突，则数据更新失败。 乐观锁实现方式：一般通过版本号和CAS算法实现。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。通俗讲就是每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁。 悲观锁的实现方式：通过数据库的锁机制实现，对查询语句添加for updata。 数据库锁的类型有哪些按照锁的粒度可以将MySQL锁分为三种： MySQL锁类别 资源开销 加锁速度 是否会出现死锁 锁的粒度 并发度 表级锁 小 快 不会 大 低 行级锁 大 慢 会 小 高 页面锁 一般 一般 不会 一般 一般 MyISAM默认采用表级锁，InnoDB默认采用行级锁。 从锁的类别上区别可以分为共享锁和排他锁 共享锁：共享锁又称读锁，简写为S锁，一个事务对一个数据对象加了S锁，可以对这个数据对象进行读取操作，但不能进行更新操作。并且在加锁期间其他事务只能对这个数据对象加S锁，不能加X锁。排他锁：排他锁又称为写锁，简写为X锁，一个事务对一个数据对象加了X锁，可以对这个对象进行读取和更新操作，加锁期间，其他事务不能对该数据对象进行加X锁或S锁。 MySQL中InnoDB引擎的行锁模式及其是如何实现的 数据库的锁与隔离级别的关系 隔离级别 实现方式 未提交读 总是读取最新的数据，无需加锁 提交读 读取数据时加共享锁，读取数据后释放共享锁 可重复读 读取数据时加共享锁，事务结束后释放共享锁 串行化 锁定整个范围的键，一直持有锁直到事务结 lock和latch七、视图 什么是视图？以及视图的使用场景有哪些？八、日志 MySQL日志系统：redo log、binlog、undo log 区别与作用日志是mysql数据库的重要组成部分，记录着数据库运行期间各种状态信息。mysql日志主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。 binlog binlog用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志。 逻辑日志：可以简单理解为记录的就是sql语句。物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更。binlog是通过追加的方式进行写入的，可以通过max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。 binlog使用场景在实际应用中，binlog的主要使用场景有两个，分别是主从复制和数据恢复。 主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。数据恢复：通过使用mysqlbinlog工具来恢复数据。binlog刷盘时机对于InnoDB存储引擎而言，只有在事务提交时才会记录biglog，此时记录还在内存中，那么biglog是什么时候刷到磁盘中的呢？mysql通过sync_binlog参数控制biglog的刷盘时机，取值范围是0-N： 0：不去强制要求，由系统自行判断何时写入磁盘；1：每次commit的时候都要将binlog写入磁盘；N：每N个事务，才会将binlog写入磁盘。从上面可以看出，sync_binlog最安全的是设置是1，这也是MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。 推荐阅读：Java面试题拆解 binlog日志格式binlog日志有三种格式，分别为STATMENT、ROW和MIXED。 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定。STATMENT 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 从而提高了性能；缺点：在某些情况下会导致主从数据不一致，比如执行sysdate()、slepp()等。ROW 基于行的复制(row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。 优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题；缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨MIXED 基于STATMENT和ROW两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog redo log redo log包括两部分：一个是内存中的日志缓冲(redo log buffer)，另一个是磁盘上的日志文件(redo log file)。mysql每执行一条DML语句，先将记录写入redo log buffer，后续某个时间点再一次性将多个操作记录写到redo log file。这种先写日志，再写磁盘的技术就是MySQL里经常说到的WAL(Write-Ahead Logging) 技术。 在计算机操作系统中，用户空间(user space)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间(kernel space)缓冲区(OS Buffer)。因此，redo log buffer写入redo log file实际上是先写入OS Buffer，然后再通过系统调用fsync()将其刷到redo log file中 redo log与binlog区别 由binlog和redo log的区别可知：binlog日志只用于归档，只依靠binlog是没有crash-safe能力的。但只有redo log也不行，因为redo log是InnoDB特有的，且日志上的记录落盘后会被覆盖掉。因此需要binlog和redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。 undo log 数据库事务四大特性中有一个是原子性，具体来说就是 原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。 实际上，原子性底层就是通过undo log实现的。undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。 同时，undo log也是MVCC(多版本并发控制)实现的关键 了解慢日志查询吗？统计过慢查询吗？对慢查询如何优化慢查询一般用于记录执行时间超过某个临界值的SQL语句的日志。 相关参数： slow_query_log：是否开启慢日志查询，1表示开启，0表示关闭。slow_query_log_file：MySQL数据库慢查询日志存储路径。long_query_time：慢查询阈值，当SQL语句查询时间大于阈值，会被记录在日志上。log_queries_not_using_indexes：未使用索引的查询会被记录到慢查询日志中。log_output：日志存储方式。“FILE”表示将日志存入文件。“TABLE”表示将日志存入数据库。 如何对慢查询进行优化？ 分析语句的执行计划，查看SQL语句的索引是否命中 优化数据库的结构，将字段很多的表分解成多个表，或者考虑建立中间表。 优化LIMIT分页 主键一般用自增ID还是UUID1.使用自增ID的好处： 字段长度较uuid会小很多。 数据库自动编号，按顺序存放，利于检索 无需担心主键重复问题 2.使用自增ID的缺点： 因为是自增，在某些业务场景下，容易被其他人查到业务量。 发生数据迁移时，或者表合并时会非常麻烦 在高并发的场景下，竞争自增锁会降低数据库的吞吐能力 UUID：通用唯一标识码，UUID是基于当前时间、计数器和硬件标识等数据计算生成的。 3.使用UUID的优点： 唯一标识，不会考虑重复问题，在数据拆分、合并时也能达到全局的唯一性。可以在应用层生成，提高数据库的吞吐能力。无需担心业务量泄露的问题。 4.使用UUID的缺点： 因为UUID是随机生成的，所以会发生随机IO，影响插入速度，并且会造成硬盘的使用率较低。 UUID占用空间较大，建立的索引越多，造成的影响越大。 UUID之间比较大小较自增ID慢不少，影响查询速度。 最后说下结论，一般情况MySQL推荐使用自增ID。因为在MySQL的InnoDB存储引擎中，主键索引是一种聚簇索引，主键索引的B+树的叶子节点按照顺序存储了主键值及数据，如果主键索引是自增ID，只需要按顺序往后排列即可，如果是UUID，ID是随机生成的，在数据插入时会造成大量的数据移动，产生大量的内存碎片，造成插入性能的下降 九、优化 十、并发类问题 数据库的并发一致性问题当多个事务并发执行时，可能会出现以下问题： 脏读：事务A更新了数据，但还没有提交，这时事务B读取到事务A更新后的数据，然后事务A回滚了，事务B读取到的数据就成为脏数据了。 不可重复读：事务A对数据进行多次读取，事务B在事务A多次读取的过程中执行了更新操作并提交了，导致事务A多次读取到的数据并不一致。 幻读：事务A在读取数据后，事务B向事务A读取的数据中插入了几条数据，事务A再次读取数据时发现多了几条数据，和之前读取的数据不一致。 丢失修改：事务A和事务B都对同一个数据进行修改，事务A先修改，事务B随后修改，事务B的修改覆盖了事务A的修改。不可重复度和幻读看起来比较像，它们主要的区别是：在不可重复读中，发现数据不一致主要是数据被更新了。在幻读中，发现数据不一致主要是数据增多或者减少了。 十一、其他 什么是MySQL InnoDB下的当前读和快照读？ ★ 当前读 ★ 它读取的数据库记录，都是当前最新的版本，会对当前读取的数据进行加锁，防止其他事务修改数据。是悲观锁的一种操作。 如下操作都是当前读： select lock in share mode (共享锁) select for update (排他锁) update (排他锁) insert (排他锁) delete (排他锁) 串行化事务隔离级别 ★ 快照读 ★ 快照读的实现是基于多版本并发控制，即MVCC，既然是多版本，那么快照读读到的数据不一定是当前最新的数据，有可能是之前历史版本的数据。 如下操作是快照读： 不加锁的select操作（注：事务级别不是串行化） 百万级别或以上的数据如何删除关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。 先删除索引 然后删除其中无用数据 删除完成后重新创建索引 读写分离 读写分离主要依赖于主从复制，主从复制为读写分离服务。 读写分离的优势： 主服务器负责写，从服务器负责读，缓解了锁的竞争 从服务器可以使用MyISAM，提升查询性能及节约系统开销 增加冗余，提高可用性 MySQL的复制原理及流程？如何实现主从复制 MySQL复制：为保证主服务器和从服务器的数据一致性，在向主服务器插入数据后，从服务器会自动将主服务器中修改的数据同步过来。 主从复制的原理： 主从复制主要有三个线程：binlog线程，I/O线程，SQL线程。 binlog线程：负责将主服务器上的数据更改写入到二进制日志（Binary log）中。 I/O线程：负责从主服务器上读取二进制日志（Binary log），并写入从服务器的中继日志（Relay log）中。 SQL线程：负责读取中继日志，解析出主服务器中已经执行的数据更改并在从服务器中重放 Master在每个事务更新数据完成之前，将操作记录写入到binlog中。 Slave从库连接Master主库，并且Master有多少个Slave就会创建多少个binlog dump线程。当Master节点的binlog发生变化时，binlog dump会通知所有的Slave，并将相应的binlog发送给Slave。 I/O线程接收到binlog内容后，将其写入到中继日志（Relay log）中。 SQL线程读取中继日志，并在从服务器中重放。 主从复制的作用： 高可用和故障转移 负载均衡 数据备份 升级测试 分库分表后，ID键如何处理分库分表后不能每个表的ID都是从1开始，所以需要一个全局ID，设置全局ID主要有以下几种方法： UUID：优点：本地生成ID，不需要远程调用；全局唯一不重复。缺点：占用空间大，不适合作为索引。 数据库自增ID：在分库分表表后使用数据库自增ID，需要一个专门用于生成主键的库，每次服务接收到请求，先向这个库中插入一条没有意义的数据，获取一个数据库自增的ID，利用这个ID去分库分表中写数据。优点：简单易实现。缺点：在高并发下存在瓶颈。 Redis生成ID：优点：不依赖数据库，性能比较好。缺点：引入新的组件会使得系统复杂度增加 Twitter的snowflake算法：是一个64位的long型的ID，其中有1bit是不用的，41bit作为毫秒数，10bit作为工作机器ID，12bit作为序列号。 1bit：第一个bit默认为0，因为二进制中第一个bit为1的话为负数，但是ID不能为负数. 41bit：表示的是时间戳，单位是毫秒。 10bit：记录工作机器ID，其中5个bit表示机房ID，5个bit表示机器ID。 12bit：用来记录同一毫秒内产生的不同ID。 美团的Leaf分布式ID生成系统： SQL语句执行的很慢原因是什么 如果SQL语句只是偶尔执行很慢，可能是执行的时候遇到了锁，也可能是redo log日志写满了，要将redo log中的数据同步到磁盘中去。 如果SQL语句一直都很慢，可能是字段上没有索引或者字段有索引但是没用上索引 什么是垂直分表、垂直分库、水平分表、水平分库 垂直分表： 将一个表按照字段分成多个表，每个表存储其中一部分字段。一般会将常用的字段放到一个表中，将不常用的字段放到另一个表中。 垂直分表的优势： 避免IO竞争减少锁表的概率。因为大的字段效率更低，第一数据量大，需要的读取时间长。第二，大字段占用的空间更大，单页内存储的行数变少，会使得IO操作增多。 可以更好地提升热门数据的查询效率。 垂直分库： 按照业务对表进行分类，部署到不同的数据库上面，不同的数据库可以放到不同的服务器上面。 垂直分库的优势： 降低业务中的耦合，方便对不同的业务进行分级管理。 可以提升IO、数据库连接数、解决单机硬件资源的瓶颈问题。 垂直拆分（分库、分表）的缺点： 主键出现冗余，需要管理冗余列 事务的处理变得复杂 仍然存在单表数据量过大的问题 水平分表： 在同一个数据库内，把同一个表的数据按照一定规则拆分到多个表中。 水平分表的优势： 解决了单表数据量过大的问题 避免IO竞争并减少锁表的概率 水平分库：把同一个表的数据按照一定规则拆分到不同的数据库中，不同的数据库可以放到不同的服务器上。 例如学生表，按照学号后3位进行分库分表，总共10库100表 水平分库的优势： 解决了单库大数据量的瓶颈问题 IO冲突减少，锁的竞争减少，某个数据库出现问题不影响其他数据库（可用性），提高了系统的稳定性和可用性 水平拆分（分表、分库）的缺点： 分片事务一致性难以解决 跨节点JOIN性能差，逻辑会变得复杂 数据扩展难度大，不易维护 在系统设计时应根据业务耦合来确定垂直分库和垂直分表的方案，在数据访问压力不是特别大时应考虑缓存、读写分离等方法，若数据量很大，或持续增长可考虑水平分库分表，水平拆分所涉及的逻辑比较复杂，常见的方案有客户端架构和恶代理架构 字段为什么要设置成not nullNULL和空值是不一样的，空值是不占用空间的，而NULL是占用空间的，所以字段设为NOT NULL后仍然可以插入空值。 字段设置成not null主要有以下几点原因： NULL值会影响一些函数的统计，如count，遇到NULL值，这条记录不会统计在内。 B树不存储NULL，所以索引用不到NULL，会造成第一点中说的统计不到的问题。 NOT IN子查询在有NULL值的情况下返回的结果都是空值。 例如user表如下 id username 0 zhangsan 1 lisi 2 null 1select * from `user` where username NOT IN (select username from `user` where id != 0) 这条查询语句应该查到zhangsan这条数据，但是结果显示为null。 MySQL在进行比较的时候，NULL会参与字段的比较，因为NULL是一种比较特殊的数据类型，数据库在处理时需要进行特数处理，增加了数据库处理记录的复杂性。 数据库的隔离级别有哪些 未提交读：一个事务在提交前，它的修改对其他事务也是可见的。 提交读：一个事务提交之后，它的修改才能被其他事务看到。 可重复读：在同一个事务中多次读取到的数据是一致的。 串行化：需要加锁实现，会强制事务串行执行。 数据库的隔离级别分别可以解决数据库的脏读、不可重复读、幻读等问题。 隔离级别 脏读 不可重复读 幻读 未提交读 允许 允许 允许 提交读 不允许 允许 允许 可重复读 不允许 不允许 允许 串行化 不允许 不允许 不允许 MySQL的默认隔离级别是可重复读 隔离级别是如何实现的事务的隔离机制主要是依靠锁机制和MVCC(多版本并发控制)实现的，提交读和可重复读可以通过MVCC实现，串行化可以通过锁机制实现。 什么是MVCC参考文章 MVCC(multiple version concurrent control)是一种控制并发的方法，主要用来提高数据库的并发性能。 在了解MVCC时应该先了解当前读和快照读。 当前读：读取的是数据库的最新版本，并且在读取时要保证其他事务不会修该当前记录，所以会对读取的记录加锁。快照读：不加锁读取操作即为快照读，使用MVCC来读取快照中的数据，避免加锁带来的性能损耗。可以看到MVCC的作用就是在不加锁的情况下，解决数据库读写冲突问题，并且解决脏读、幻读、不可重复读等问题，但是不能解决丢失修改问题。 MVCC的实现原理： 版本号 系统版本号：是一个自增的ID，每开启一个事务，系统版本号都会递增。 事务版本号：事务版本号就是事务开始时的系统版本号，可以通过事务版本号的大小判断事务的时间顺序。 行记录隐藏的列 DB_ROW_ID：所需空间6byte，隐含的自增ID，用来生成聚簇索引，如果数据表没有指定聚簇索引，InnoDB会利用这个隐藏ID创建聚簇索引。 DB_TRX_ID：所需空间6byte，最近修改的事务ID，记录创建这条记录或最后一次修改这条记录的事务ID。 DB_ROLL_PTR：所需空间7byte，回滚指针，指向这条记录的上一个版本。 它们大致长这样，省略了具体字段的值 undo日志 MVCC做使用到的快照会存储在Undo日志中，该日志通过回滚指针将一个一个数据行的所有快照连接起来。它们大致长这样。 在重复读的隔离级别下，InnoDB的工作流程： SELECT 作为查询的结果要满足两个条件： 当前事务所要查询的数据行快照的创建版本号必须小于当前事务的版本号，这样做的目的是保证当前事务读取的数据行的快照要么是在当前事务开始前就已经存在的，要么就是当前事务自身插入或者修改过的。当前事务所要读取的数据行快照的删除版本号必须是大于当前事务的版本号，如果是小于等于的话，表示该数据行快照已经被删除，不能读取。 INSERT 将当前系统版本号作为数据行快照的创建版本号。 DELETE 将当前系统版本号作为数据行快照的删除版本号。 UPDATE 保存当前系统版本号为更新前的数据行快照创建行版本号，并保存当前系统版本号为更新后的数据行快照的删除版本号，其实就是，先删除在插入即为更新 drop、delete和truncate","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://lives.xtcgch.ink/tags/MYSQL/"},{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"},{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"网络通信","slug":"网络通信-20210904","date":"2021-08-17T04:48:14.000Z","updated":"2021-09-04T15:31:33.976Z","comments":true,"path":"2021/08/17/网络通信/","link":"","permalink":"https://lives.xtcgch.ink/2021/08/17/网络通信/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 TCP可靠传输的实现以字节为单位的滑动窗口超时重传的时间的选择选择确认sackTCP的流量控制利用滑动窗口TCP的拥塞控制慢开始拥塞避免快重传快恢复Centos7查看网卡流量的6种方法iptraf-ng -h12345678# 查看每一块网卡上的流量sudo iptraf-ng -g# 显示指定网卡上的流量统计，总体流量、流入量、流出量、以及按协议分类的流量统计sudo iptraf-ng -d eth0# 统计各port的流量sudo iptraf-ng -s eth0# 查看远程主机端口及报文（含抓包信息）sudo iptraf-ng -i eth0 nload1sudo nload enp0s3 ifstatsarwatchiftop","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://lives.xtcgch.ink/tags/网络/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"守护进程","slug":"守护进程-20210814","date":"2021-08-14T07:34:26.000Z","updated":"2021-10-02T13:30:55.320Z","comments":true,"path":"2021/08/14/守护进程/","link":"","permalink":"https://lives.xtcgch.ink/2021/08/14/守护进程/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 拓展扩展点一扩展点二1、什么是守护进程 守护进程是运行在后台的一种特殊进程，它独立于控制终端并且周期性地执行某种任务或循环等待处理某些事件的发生； 守护进程一般在系统启动时开始运行，除非强行终止，否则直到系统关机才随之一起停止运行； 守护进程一般都以root用户权限运行，因为要使用某些特殊的端口或者资源； 守护进程的父进程一般都是init进程，因为它真正的父进程在fork出守护进程后就直接退出了，所以守护进程都是孤儿进程，由init接管； 2、有哪些常见的守护进程 日志服务进程 syslogd 数据库守护进程 mysqld 3、创建守护进程的步骤 (1) fork()创建子进程，父进程exit()退出 这是创建守护进程的第一步。由于守护进程是脱离控制终端的，因此，完成第一步后就会在Shell终端里造成程序已经运行完毕的假象。之后的所有工作都在子进程中完成，而用户在Shell终端里则可以执行其他命令，从而在形式上做到了与控制终端的脱离，在后台工作。 (2) 在子进程中调用 setsid() 函数创建新的会话 在调用了fork()函数后，子进程全盘拷贝了父进程的会话期、进程组、控制终端等，虽然父进程退出了，但会话期、进程组、控制终端等并没有改变，因此，这还不是真正意义上的独立开来，而 setsid() 函数能够使进程完全独立出来。 (3) 再次 fork() 一个孙进程并让子进程退出 为什么要再次fork呢，假定有这样一种情况，之前的父进程fork出子进程以后还有别的事情要做，在做事情的过程中因为某种原因阻塞了，而此时的子进程因为某些非正常原因要退出的话，就会形成僵尸进程，所以由子进程fork出一个孙进程以后立即退出，孙进程作为守护进程会被init接管，此时无论父进程想做什么都随它了。 (4) 在孙进程中调用 chdir() 函数，让根目录 ”/” 成为孙进程的工作目录 这一步也是必要的步骤，使用fork创建的子进程继承了父进程的当前工作目录。由于在进程运行中，当前目录所在的文件系统（如“/mnt/usb”）是不能卸载的，这对以后的使用会造成诸多的麻烦（比如系统由于某种原因要进入单用户模式）。因此，通常的做法是让”/“作为守护进程的当前工作目录，这样就可以避免上述的问题，当然，如有特殊需要，也可以把当前工作目录换成其他的路径，如/tmp，改变工作目录的常见函数是chdir。 (5) 在孙进程中调用 umask() 函数，设置进程的文件权限掩码为0 文件权限掩码是指屏蔽掉文件权限中的对应位。比如，有个文件权限掩码是050，它就屏蔽了文件组拥有者的可读与可执行权限。由于使用fork函数新建的子进程继承了父进程的文件权限掩码，这就给该子进程使用文件带来了诸多的麻烦。因此，把文件权限掩码设置为0，可以大大增强该守护进程的灵活性。设置文件权限掩码的函数是umask。在这里，通常的使用方法为umask(0)。 (6) 在孙进程中关闭任何不需要的文件描述符 同文件权限码一样，用fork函数新建的子进程会从父进程那里继承一些已经打开了的文件。这些被打开的文件可能永远不会被守护进程读写，但它们一样消耗系统资源，而且可能导致所在的文件系统无法卸下。 在上面的第2)步之后，守护进程已经与所属的控制终端失去了联系。因此从终端输入的字符不可能达到守护进程，守护进程中用常规方法（如printf）输出的字符也不可能在终端上显示出来。所以，文件描述符为0、1和2 的3个文件（常说的输入、输出和报错）已经失去了存在的价值，也应被关闭。 (7) 守护进程退出处理 当用户需要外部停止守护进程运行时，往往会使用 kill 命令停止该守护进程。所以，守护进程中需要编码来实现 kill 发出的signal信号处理，达到进程的正常退出。 4、守护进程的代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#include &lt;unistd.h&gt;#include &lt;signal.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;time.h&gt;#include &lt;stdio.h&gt; static bool flag = true;void create_daemon();void handler(int); int main()&#123; time_t t; int fd; create_daemon(); struct sigaction act; act.sa_handler = handler; sigemptyset(&amp;act.sa_mask); act.sa_flags = 0; if(sigaction(SIGQUIT, &amp;act, NULL)) &#123; printf(&quot;sigaction error.\\n&quot;); exit(0); &#125; while(flag) &#123; fd = open(&quot;/home/mick/daemon.log&quot;, O_WRONLY | O_CREAT | O_APPEND, 0644); if(fd == -1) &#123; printf(&quot;open error\\n&quot;); &#125; t = time(0); char *buf = asctime(localtime(&amp;t)); write(fd, buf, strlen(buf)); close(fd); sleep(60); &#125; return 0;&#125;void handler(int sig)&#123; printf(&quot;I got a signal %d\\nI&apos;m quitting.\\n&quot;, sig); flag = false;&#125;void create_daemon()&#123; pid_t pid; pid = fork(); if(pid == -1) &#123; printf(&quot;fork error\\n&quot;); exit(1); &#125; else if(pid) &#123; exit(0); &#125; if(-1 == setsid()) &#123; printf(&quot;setsid error\\n&quot;); exit(1); &#125; pid = fork(); if(pid == -1) &#123; printf(&quot;fork error\\n&quot;); exit(1); &#125; else if(pid) &#123; exit(0); &#125; chdir(&quot;/&quot;); int i; for(i = 0; i &lt; 3; ++i) &#123; close(i); &#125; umask(0); return;&#125; 5、用系统函数daemon实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;unistd.h&gt;#include &lt;signal.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;time.h&gt;#include &lt;stdio.h&gt; static bool flag = true;void handler(int); int main()&#123; time_t t; int fd; if(-1 == daemon(0, 0)) &#123; printf(&quot;daemon error\\n&quot;); exit(1); &#125; struct sigaction act; act.sa_handler = handler; sigemptyset(&amp;act.sa_mask); act.sa_flags = 0; if(sigaction(SIGQUIT, &amp;act, NULL)) &#123; printf(&quot;sigaction error.\\n&quot;); exit(0); &#125; while(flag) &#123; fd = open(&quot;/home/mick/daemon.log&quot;, O_WRONLY | O_CREAT | O_APPEND, 0644); if(fd == -1) &#123; printf(&quot;open error\\n&quot;); &#125; t = time(0); char *buf = asctime(localtime(&amp;t)); write(fd, buf, strlen(buf)); close(fd); sleep(60); &#125; return 0;&#125;void handler(int sig)&#123; printf(&quot;I got a signal %d\\nI&apos;m quitting.\\n&quot;, sig); flag = false;&#125;","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"DAEMON","slug":"DAEMON","permalink":"https://lives.xtcgch.ink/tags/DAEMON/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【专项】 编程语言之C++可变参数","slug":"编程语言之C++可变参数-20210813","date":"2021-08-05T22:41:54.000Z","updated":"2021-10-11T13:00:13.623Z","comments":true,"path":"2021/08/06/编程语言之C++可变参数/","link":"","permalink":"https://lives.xtcgch.ink/2021/08/06/编程语言之C++可变参数/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 1. 可变参数宏实现步骤如下： １. 函数原型中使用省略号； ２. 函数定义中创建一个va_list变量； 3. 初始化va_list变量； 4. 访问参数列表； 5. 完成清理工作； 12345678910111213141516/* --sum.cpp-- 可变参数宏实现求任意个整形值得和 */#include &lt;stdarg.h&gt;int sum(int count, ...); //原型中使用省略号int sum(int count, ...)&#123; //count 表示可变参数个数 va_list ap; //声明一个va_list变量 va_start(ap, count); //初始化，第二个参数为最后一个确定的形参 int sum = 0; for(int i = 0; i &lt; count; i++) sum += va_arg(ap, int); //读取可变参数，的二个参数为可变参数的类型 va_end(ap); //清理工作 return sum;&#125; 2. initializer_list标准库类型实现步骤如下： １. 函数原型中使用实例化initializer_list模板代表可变参数列表； ２. 使用迭代器访问initializer_list中的参数； 3. 传入实参写在{}之内。 1234567891011121314/* --sum.cpp-- 利用initializer_list模板实现求人一个整形值得和 */#include &lt;initializer_list&gt;int sum(initializer_list&lt;int&gt; il); //函数原型用int实例化initializer_list作为形参int sum(inttializer_list&lt;int&gt; il)&#123; int sum = 0; for(auto p = il.begin(); p != il.end(); p++) //使用迭代器访问参数 sum += *p; return sum;&#125;sum(&#123;1,2,3&#125;)sum(&#123;2,5,7,8,9,10&#125;) 3. 可变参数模板步骤如下： １. 编写含有模板参数包和函数参数包的模板函数； 2. 函数定义递归调用自己，每一步递归参数包中参数减一； 3. 编写处理边界情况（参数包含有零个参数）的模板。 1234567891011121314int sum()&#123; return 0;&#125;//展开函数template &lt;class T, class ...Args&gt;T sum(T head, Args... rest)&#123; return head + sum(rest...);&#125;sum(1,2,3,4); // head依次是1，2，3，4","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"windows之bat使用","slug":"windows之bat使用-20210805","date":"2021-08-05T10:32:21.000Z","updated":"2021-11-29T11:35:21.725Z","comments":true,"path":"2021/08/05/windows之bat使用/","link":"","permalink":"https://lives.xtcgch.ink/2021/08/05/windows之bat使用/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 知识理解echo 1234echo on #从下一行开始打开回显echo off #从下一行开始关闭回显@echo off #从本行开始关闭回显echo hello world #输出hello world set 显示、设置或删除变量。 显示变量：set 或 set s 前者显示批处理当前已定义的所有变量及其值，后者显示所有以s开头的变量及值。 设置变量：set aa=abcd 此句命令便可向变量aa赋值abcd。如果变量aa已被定义，则aa的值被修改为abcd；若aa尚未定义，则此句命令即可定义新的变量aa，同时为变量aa赋予初始值abcd。 删除变量：set aa= 此句命令即可删除变量aa md/mkdir 创建文件夹 12md C:\\testmkdir C:\\test xcopy 复制文件夹 1xcopy %sourceDir% %targetDir% /s/y/e :: -e 表示递归复制文件夹 input 获取用户输入 12set /p input= if %input%==0 (cd C:\\windows) % 命令行传递给批处理的参数 1234%0 批处理文件本身%1 第一个参数%9 第九个参数%* 从第一个参数开始的所有参数 date 和 time 日期和时间 date #显示当前日期，并提示输入新日期，按”回车”略过输入date/t #只显示当前日期，不提示输入新日期time #显示当前时间，并提示输入新时间，按”回车”略过输入time/t #只显示当前时间，不提示输入新时间 12set curDate=%date:~0,4%%date:~5,2%%date:~8,2% echo %curDate% ::结果 20210806 端口转发 添加端口转发 1netsh interface portproxy add v4tov4 listenport=4000 listenaddress=127.0.0.1 connectport=4000 connectaddress=172.31.217.198 删除端口转发 1netsh interface portproxy del v4tov4 listenport=4000 listenaddress=127.0.0.1 查看已存在的端口映射 1netsh interface portproxy show v4tov4 内外穿透","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"WINDOWS","slug":"WINDOWS","permalink":"https://lives.xtcgch.ink/tags/WINDOWS/"},{"name":"BAT","slug":"BAT","permalink":"https://lives.xtcgch.ink/tags/BAT/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"回调","slug":"回调-20210805","date":"2021-08-05T03:12:25.000Z","updated":"2021-10-10T08:09:39.662Z","comments":true,"path":"2021/08/05/回调/","link":"","permalink":"https://lives.xtcgch.ink/2021/08/05/回调/","excerpt":"","text":"header_include.hpp 12345678910111213#ifndef _HEADER_INCLUDE_HPP#define _HEADER_INCLUDE_HPP#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;mcheck.h&gt;#include &lt;thread&gt;#include &lt;memory&gt;#include &lt;queue&gt;#include &lt;functional&gt;#include &lt;future&gt;#endif CallBack.hpp 123456789101112131415161718192021222324252627282930313233343536#ifndef _CALLBACK_H#define _CALLBACK_H#include&quot;header_include.hpp&quot;using namespace std;enum CallType&#123; NAME, AGE, GRADE,&#125;;struct StCallBackMsg&#123; CallType enCalltype; string _strSeq; string _strData;&#125;; class CallBack&#123;public: CallBack(); ~CallBack(); public: void TestCallBack(StCallBackMsg Msg);public: //PrintName m_PrintName; function&lt;void(string)&gt; m_PrintName; function&lt;void(int)&gt; m_PrintAge; function&lt;void(int)&gt; m_PrintGrade; &#125;;#endif CallBack.cpp 12345678910111213141516171819202122232425262728293031#include &quot;CallBack.hpp&quot;#include &quot;BaseCall.hpp&quot; CallBack::CallBack()&#123;&#125; CallBack::~CallBack()&#123;&#125; void CallBack::TestCallBack(StCallBackMsg msg)&#123; switch (msg.enCalltype) &#123; case NAME: m_PrintName(msg._strData); break; case AGE: m_PrintAge(std::stoi(msg._strData)); break; case GRADE: &#123; m_PrintGrade(std::stoi(msg._strData)); &#125; break; default: break; &#125;&#125; BaseCall.hpp12345678910111213141516171819#ifndef _BASECALL_H#define _BASECALL_H#include&quot;header_include.hpp&quot;#include&quot;CallBack.h&quot; class BaseCall&#123;public: BaseCall(); ~BaseCall(); private: static void onPrintName(string); static void onPrintAge(int); static void onPrintGrade(int);private: std::shared_ptr&lt;CallBack&gt; m_CallBack;&#125;;#endif BaseCall.cpp1234567891011121314151617181920212223242526272829303132333435363738#include&quot;BaseCall.hpp&quot; BaseCall::BaseCall()&#123; m_CallBack = make_shared&lt;CallBack&gt;(); m_CallBack-&gt;m_PrintName = bind(BaseCall::onPrintName, placeholders::_1);; m_CallBack-&gt;m_PrintAge = bind(BaseCall::onPrintAge, placeholders::_1); m_CallBack-&gt;m_PrintGrade = bind(BaseCall::onPrintGrade, placeholders::_1); StCallBackMsg msg1=&#123;CallType::NAME,&quot;00000001&quot;,&quot;My Name is Tom&quot;&#125;; StCallBackMsg msg2=&#123;CallType::AGE,&quot;00000002&quot;,&quot;200&quot;&#125;; StCallBackMsg msg3=&#123;CallType::GRADE,&quot;00000003&quot;,&quot;150&quot;&#125;; m_CallBack-&gt;TestCallBack(msg1); m_CallBack-&gt;TestCallBack(msg2); m_CallBack-&gt;TestCallBack(msg3);&#125; BaseCall::~BaseCall()&#123; &#125; void BaseCall::onPrintName(string strName)&#123; printf(&quot;姓名： %s\\n&quot;, strName.c_str());&#125; void BaseCall::onPrintAge(int nAge)&#123; printf(&quot;年龄： %d\\n&quot;, nAge);&#125; void BaseCall::onPrintGrade(int nGrade)&#123; printf(&quot;班级：%d\\n&quot;, nGrade);&#125; main.cpp123456789#include&quot;header_include.hpp&quot;#include &quot;CallBack.hpp&quot;#include &quot;BaseCall.hpp&quot;int main()&#123; BaseCall bc; return 0;&#125;","categories":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"}],"keywords":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}]},{"title":"内存泄漏检测","slug":"DEBUG之内存泄漏检测-20210510","date":"2021-05-10T09:30:43.000Z","updated":"2021-10-02T13:31:06.022Z","comments":true,"path":"2021/05/10/内存泄漏检测/","link":"","permalink":"https://lives.xtcgch.ink/2021/05/10/内存泄漏检测/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 工具常见的C++内存泄漏检测工具有 mtrace valgrind mtrace原理优缺点优点 工具小，安装和使用方便，快速上手，适用于简单的代码 缺点 功能少，不能检查复杂的逻辑，比如队列，线程，而且分析结果简单 需要修改代码 只能监测单一程序 应用场景安装和使用内存泄漏检测 性能瓶颈检测 日志分析内存泄漏分析 性能瓶颈分析 valgrind原理内存泄漏检测: Memcheck 运行时分析: callgrind 缓存命中分析: Cachegrind 多线程资源竞争分析: Helgrind 堆栈分析器: Massif 优缺点应用场景安装和使用安装 12345678wget https://sourceware.org/pub/valgrind/valgrind-3.17.0.tar.bz2tar xvf valgrind-3.17.0.tar.bz2cd valgrind-3.17.0sudo ./configure --prefix=/usr/local/valgrind #--指定安装目录sudo makesudo make installvalgrind -h #查看帮助valgrind --version #检查版本 内存泄漏检测 12#test是待检测的应用程序valgrind --leak-check=full --show-reachable=yes --trace-children=yes --log-file=test.log --time-stamp=yes ./test 日志分析","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"内存泄漏","slug":"内存泄漏","permalink":"https://lives.xtcgch.ink/tags/内存泄漏/"},{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"数据结构之hashmap","slug":"数据结构之hashmap-20210504","date":"2021-05-04T12:13:17.000Z","updated":"2021-10-10T15:46:23.055Z","comments":true,"path":"2021/05/04/数据结构之hashmap/","link":"","permalink":"https://lives.xtcgch.ink/2021/05/04/数据结构之hashmap/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 知识理解HashMap底层存储结构从整体结构上看HashMap是由数组+链表+红黑树（JDK1.8后增加了红黑树部分）实现的 HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫做一个Entry；这些Entry分散的存储在一个数组当中，该数组就是HashMap的主干 因为数组Table的长度是有限的，使用hash函数计算时可能会出现index冲突的情况，所以我们需要链表来解决冲突；数组Table的每一个元素不单纯只是一个Entry对象，它还是一个链表的头节点，每一个Entry对象通过Next指针指向下一个Entry节点；当新来的Entry映射到冲突数组位置时，只需要插入对应的链表位置即可 查找添加","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"HASHMAP","slug":"HASHMAP","permalink":"https://lives.xtcgch.ink/tags/HASHMAP/"},{"name":"数据结构","slug":"数据结构","permalink":"https://lives.xtcgch.ink/tags/数据结构/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"量化交易相关","slug":"量化交易相关-20210504","date":"2021-05-04T08:36:30.000Z","updated":"2021-08-28T01:43:14.016Z","comments":true,"path":"2021/05/04/量化交易相关/","link":"","permalink":"https://lives.xtcgch.ink/2021/05/04/量化交易相关/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 性能相关 高并发 低延迟 高吞吐量 低延迟 FEC：前向纠错码（Forward Error Correction），是增加数据通讯可信度的方法。 HLS协议：基于HTTP的流媒体网络传输协议（HTTP Live Streaming）。 FPGA： 纯网络方向的优化方案 换专线：这能带来质的飞跃，越贵越快 优化拥塞控制算法：调内核的收发包算法，或者干脆自己实现一套，毕竟发得快，才能收得快。 增加FEC：在掉包率很高的情况下，其实发得快，死得更惨，成本也更高。 从网络链路上考虑：客户服务器 变成 客户 服务器A 服务器B，典型场景就是电信，联通，移动这种跨网通迅，通过在交换服务器（服务器A）上增加多网卡，实现本地交换，以达到降低时延（减少绕路）的目的。 优化点1.限制动态分配内存相关的知识背景glibc默认的malloc背后有复杂的算法，当堆空间不足时会调用sbrk()，当分配内存很大时会调用mmap()，这些都是系统调用，似乎会比较慢，而且新分配的内存被first touch时也要过很久才能准备好。 可取的做法尽量使用vector或者array（初始化时分配足够的空间，之后每次使用都从里面取出来用）。尽量使用内存池。如果需要二叉树或者哈希表，尽量使用侵入式容器（boost::intrusive）。 性能测试我测试的分配尺寸有64和8128两种。首先，我测试了glibc malloc的性能，分配64字节耗时98(sd247)ns，分配8128字节需要耗时1485(sd471)ns。其次，我写了一个多进程安全的内存池，分配64字节需要29(sd15)ns，分配8128字节需要22(sd12)ns。【内存池的细节见注释6】。最后，我单独测试了sbrk()和first touch的性能，但是数据不记得了。 2.使用轮询，尽量避免阻塞相关的知识背景：上下文切换是非常耗时的，其中固定的消耗包括（cpu流水线被冲掉、各种寄存器需要被保存和恢复、内核中的调度算法要被执行），此外，缓存很有可能出现大量miss，这属于不固定的时间消耗。 可取的做法使用带有内核bypass功能的网卡。每个进程或者线程都独占一个cpu核【isolcpus和irqbalance的细节见注释3】，并且不停地轮询，用以保证快速响应。尽量避免任何可能导致阻塞的事件（如mutex），某些注定很慢的活动（比如把log写到磁盘上）应该被独立出来放到别的cpu上，不能影响主线程。 性能测试网上有一篇博客[tsunanet, 2010]测试了mode switch、thread switch、process switch的耗时，但是这篇文章太早了，以后我要用我的新cpu重新测一下。这篇博客里面，系统调用只需要&lt;100ns，线程/进程切换需要&gt;1us（不包括缓存miss的时间）。 3.使用共享内存作为唯一的IPC机制相关的知识背景共享内存只有在初始化的时候有一些系统调用，之后就可以像访问正常内存一样使用了。其他IPC机制（管道、消息队列、套接字）则是每次传输数据时都有系统调用，并且每次传输的数据都经历多次拷贝。因此共享内存是最快的IPC机制。 可取的做法使用共享内存作为唯一的IPC机制。当然，可能需要手动实现一些东西来保证共享的数据在多进程下是安全，我们是自己实现了无锁内存池、无锁队列和顺序锁【关于seqlock的疑点见注释1】。 性能测试我使用了boost中的Interprocess库和Lockfree库，在共享内存上建立了一个spsc队列，然后用这个队列来传送数据，代码参考了stackoverflow上的一个答案[sehe, 2014]。我传送的数据是一个8字节整数，延时是153(sd61)ns。至于其他IPC机制，我在[cambridge, 2016]看到了一些性能测试结果，通常是要几微秒到几十微秒不等。 4.传递消息时使用无锁队列相关的知识背景我只关注基于数组的无锁队列，其中：spsc队列是wait-free的，不论是入队出队都可以在确定的步数之内完成，而且实现时只需要基本的原子操作【为什么这很重要见注释7】；mpmc队列的实现方式则多种多样，但都会稍微慢一点，因为它们需要用一些比较重的原子操作（CAS或者FAA），而且有时它们需要等待一段不确定的时间直到另一个线程完成相应操作；另外，还有一种multi-observer的『广播队列』，多个读者可以收到同一条消息广播，这种队列也有sp和mp类型的，可以检查或者不检查overwrite；最后，还有一种队列允许存储不定长的消息。 可取的做法总的来说，应该避免使用mp类型的队列，举例：如果要用mpsc队列，可以使用多个spsc来达成目的，并不需要mp队列；同理，如果是消息广播，也可以使用多个sp队列来取代一个mp队列；如果广播时observer只想订阅一部分消息，那么可以用多个spsc+有计数功能的内存池【具体做法见注释2】；如果要求多个观察者看到多个生产者的消息，并且顺序一致，那只能用mp队列了。总结一下，mp类型的队列应该尽量避免，因为当多个生产者同时抢占队列的时候，延时会线性增长。 性能测试我写了一个mp类型的广播队列，传输的数据是8字节int，当只有一个生产者时，传输的延时是105(sd26)ns。增加观察者会使延时略微变大，增加生产者会使延时急剧变大（我用rdtsc指令控制不同生产者同时发送消息）。对于这个队列来说，它的延时只略高于跨核可视延时【测试结果见注释8】，所以应该算是不错了。 5.考虑缓存对速度的影响相关的背景知识现在的机器内存是十分充足的，但是缓存还是很小，因此所有节省内存的技巧都还有用武之地。 可取的做法尽量让可能被同时使用的数据挨在一起；减少指针链接（比如用array取代vector，因为链接指向的地方可能不在缓存里）；尽量节省内存（比如用unique_ptr&lt;Data[]&gt;取代vector，比如成员变量按照从大到小排序，比如能用int8的地方就不用int16）；指定cpu affinity时考虑LLC缓存（同核的两个超线程是共享L1，同cpu的两个核是共享L3，不同NUMA核是通过QPI总线）；会被多个核同时读写的数据按照缓存行对齐（避免false sharing）。 【注释1】：有一篇惠普的论文[Hans-J.Boehm, 2012]大致叙述了顺序锁的实现方法，但是那里面有两点让我感到困惑。一是需要用到thread_fence，这在某些cpu上可能会影响性能(x86似乎没影响)；二是被保护的内容也必须是原子变量(可以是多个原子变量，所以被保护的内容可以很长)。但这是我见过的唯一一个符合C++标准的SeqLock的实现。 【注释2】：如果有M个生产者要发消息给N个观察者，可以建M*N个spsc队列和M个内存池，观察者只能读内存池里的数据，只有对应的那一个生产者可以修改内存池。我感觉这样应该会更快，但我没测过。 【注释3】：isolcpus可以隔离出一些cpu，避免其他线程被调度到这些cpu上执行。此外，设置irq affinity可以让一些cpu尽量避免响应中断，但在/proc/interrupts里面仍然有一些项目是避免不了的，而cpu处理中断时，用户程序会有一段时间（有时高达几十微秒）无法响应，我们没法解决这个问题。 【注释4】：在不同的时间点，ping的结果会有很大差异。交易时间段内ping出来的结果是30us，其它时间段ping出来的结果可能是几百微秒。我不知道这是什么原因，可能是期货公司为了省电关掉了某些东西？ 【注释5】：我们要在共享内存上使用内存池，所以不得不自己写一个。我写的内存池只能分配固定尺寸的内存块，但是用户可以建立好几个内存池，用来分配不同的尺寸。实现的过程中有两个要点。一是用无锁链表来保存空闲的内存块；二是每个线程内部有一个缓冲区，所以真正取内存块的时候是没有CAS操作的。 【注释6】：在Intel x86的cpu上，如果C++中的内存顺序只用了acquire和release，那么编译出来的汇编代码里面不会有任何内存栅栏指令；如果同时也没有RMW（读-改-写）指令的话，无锁的代码编译出来就会像是普通的代码一样了。事实上，spsc队列的延时几乎等于跨核可视延时。 【注释7】：跨核可视延时：对于一个共享变量来说，如果有一个核上面的进程或者线程修改了这个变量，另一个核需要过一段时间才能看到这个修改，这段时间被称作跨核可视延时。我不确定在这段时间内，第二个核是会看到旧的数据还是这条指令会执行很久。在我的机器上，对于同一个cpu上的不同核心，这个值是96(sd14)ns。另外，对于同一个核心上的不同超线程，这个值应该会更小；对于同一台机器上的不同cpu，这个值应该会更大。 从战略上来说，避免任何可能的阻塞，以可预测的方式IO，包括但不限于：网络IO，磁盘，内存，甚至CPU的各级缓存。具体展开来讲：网络IO：使用非面向连接的协议，因为面向连接的协议有窗口，有可能引起阻塞。磁盘：使用Write Ahead Log（WAL），避免使用数据库。内存： 避免动态分配内存。（一次随机内存访问花费的时间和顺序访问对于CPU来说花费的时间相差两个数量级） 零内存拷贝，不一定能做到，总之是拷贝的次数越少越好。 数据无需编码解码，可以直接顺序从内存读取，直接可以在网络上收发。CPU：避免false sharing，cache miss等。 相关技术零拷贝零拷贝（zero-copy）： 零拷贝技术是基于 PageCache ,PageCache 会缓存最近访问的数据，提升了访问缓存数据的性能 一般的文件传输过程 开发者需要将静态内容（类似图片、数据表、文件）展示给远程的用户。那么这个情形就意味着开发者需要先将静态内容从磁盘中拷贝出来放到一个内存buf中，然后将这个buf通过socket传输给用户，进而用户或者静态内容的展示。 linux过程如下： 首先，调用read时，数据文件A拷贝到了kernel模式； 之后，CPU控制将kernel模式数据复制到user模式下； 调用write时，先将user模式下的内容复制到到kernel模式下的socket的buffer中； 最后将kernel模式下的socket buffer的数据复制到网卡设备中传送； 发生了 4 次用户态与内核态的上下文切换 使用零拷贝 在 Linux 中，减少拷贝次数的一种方法是调用 mmap() 来代替调用 read,即mmap()+write()代替read()+write() 为SIGBUS信号建立信号处理程序 使用文件租借锁12345678910if(fcntl(diskfd, F_SETSIG, RT_SIGNAL_LEASE) == -1) &#123; perror(&quot;kernel lease set signal&quot;); return -1;&#125;/* l_type can be F_RDLCK F_WRLCK 加锁*//* l_type can be F_UNLCK 解锁*/if(fcntl(diskfd, F_SETLEASE, l_type))&#123; perror(&quot;kernel lease set type&quot;); return -1;&#125; 使用sendfile()代替read()+write() 12#include&lt;sys/sendfile.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 使用splice 123#define _GNU_SOURCE /* See feature_test_macros(7) */#include &lt;fcntl.h&gt;ssize_t splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags); 使用零拷贝技术的项目 Kafka Nginx 注意： 针对大文件的传输的方式,使用零拷贝技术针对大文件的传输的方式,应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术 –&gt; 文章1–&gt; 文章2–&gt; 文章3 写时复制 CopyOnWriteKernel bypasskernel bypass（绕过内核、内核旁路）是解决系统网络栈和存储栈性能瓶颈的另外一种方式，与传统的中断机制不同，kernel bypass的核心思想是：内核只用来处理控制流，所有数据流相关操作都在用户态进行处理，从而规避内核的包拷贝、线程调度、系统调用、中断等性能瓶颈，并辅以各种性能调优手段（如：CPU pin、无锁队列），从而达到更高的性能。 kernel bypass 是一种思想，有几种具体的实施方案 PACKET_MMAP PF_RING Snabbswitch DPDK Netmap Linux内核协议栈性能瓶颈 （1）硬件中断导致的线程、进程切换硬件中断请求会抢占优先级较低的软件中断，频繁到达的硬件中断和软中断意味着频繁的线程切换，随着而来的就是运行模式切换、上下文切换、线程调度器负载、高速缓存缺失（Cache Missing）、多核缓存共享数据同步、竞争锁等一系列的CPU性能损耗。 （2）内存拷贝网卡驱动位于内核态，网络驱动接收到数据包后会经过内核协议栈的处理，然后再拷贝到用户态的应用层缓冲区.从内核态到用户态的数据拷贝是耗时操作，数据拷贝的时间会占数据包处理流程时间的50%以上。 （3）多处理器平台CPU漂移一个数据包可能中断在CPU0，内核态处理在CPU1，用户态处理在 CPU2，跨多个物理核（Core）处理会导致大量的 CPU Cache命中缺失，造成局部性失效。对于NUMA架构，还会出现跨NUMA节点的内存访问，极大地影响CPU性能。 （4）缓存失效传统服务器大多采用页式虚拟存储器，内存页默认为4K的小页，在存储空间较大的处理机上会存在大量的页面映射项。同时由于TLB缓存空间有限，最终导致TLB快表的映射项频繁变更，产生大量的TLB命中缺失。 Kernel Bypass优点 高性能、低延迟 Kernel Bypass缺点 （1）改变了现有操作系统的工作方式，很难与现有操作系统集成。（2）由于网络数据不经过内核网络协议栈，相关网络应用程序需要重新实现由操作系统提供的功能。（3）由于操作系统没有相关网络硬件的控制权，操作系统提供的网络管理部署工具不再可用。（4）破坏了操作系统内核提供的安全性。在容器场景中，资源的抽象和隔离主要由操作系统内核提供。（5）需要消耗1个或者多个CPU核来专门处理网络包。 –&gt; 文章1–&gt; 文章2 DPDK 、SPDK 、RDMA DPDK（Data Plane Development Kit）是由Intel发起，主要基于Linux系统运行，用于快速数据包处理的函数库与驱动集合，可以极大提高数据处理性能和吞吐量，提高数据平面应用程序的工作效率。DPDK使用了轮询(polling)而不是中断来处理数据包。在收到数据包时，经DPDK重载的网卡驱动不会通过中断通知CPU，而是直接将数据包存入内存，交付应用层软件通过DPDK提供的接口来直接处理，这样节省了大量的CPU中断时间和内存拷贝时间。 DPDK特点 （1）轮询：在包处理时避免中断上下文切换的开销，（2）用户态驱动：规避不必要的内存拷贝和系统调用，便于快速迭代优化（3）亲和性与独占：特定任务可以被指定只在某个核上工作，避免线程在不同核间频繁切换，保证更多的cache命中（4）降低访存开销：利用内存大页HUGEPAGE降低TLB miss，利用内存多通道交错访问提高内存访问有效带宽（5）软件调优：cache行对齐，预取数据，多元数据批量操作 SPDK（Storage Performance Development Kit）是由Intel发起，用于加速使用NVMe SSD作为后端存储的应用软件加速库，该软件库的核心是用户态、异步、轮询方式的NVMe驱动。与内核态的NVMe驱动相比，它可以大幅度降低延迟，同时提升单CPU核的IOPS。 RDMA（Remote Direct Memory Access）全称远程直接数据存取，就是为了解决网络传输中服务器端数据处理的延迟而产生的。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理功能。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。 Ceph集群Ceph是一个统一的分布式存储系统，设计初衷是提供较好的性能、可靠性和可扩展性。 Ceph 存储集群至少需要一个 Ceph Monitor 和两个 OSD 守护进程。而运行 Ceph 文件系统客户端时，则必须要有元数据服务器（ Metadata Server ）","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"量化交易","slug":"量化交易","permalink":"https://lives.xtcgch.ink/tags/量化交易/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"生产者和消费者模型","slug":"IPC之生产者和消费者模型-20210426","date":"2021-04-25T23:18:15.000Z","updated":"2021-04-25T23:22:55.002Z","comments":true,"path":"2021/04/26/生产者和消费者模型/","link":"","permalink":"https://lives.xtcgch.ink/2021/04/26/生产者和消费者模型/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 其他模板的标题 知识理解拓展扩展点一123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140#include &lt;unistd.h&gt;#include &lt;cstdlib&gt;#include &lt;condition_variable&gt;#include &lt;iostream&gt;#include &lt;mutex&gt;#include &lt;thread&gt;static const int kItemRepositorySize = 4; // Item buffer size.static const int kItemsToProduce = 10; // How many items we plan to produce.struct ItemRepository &#123; int item_buffer[kItemRepositorySize]; size_t read_position; size_t write_position; size_t produced_item_counter; size_t consumed_item_counter; std::mutex mtx; std::mutex produced_item_counter_mtx; std::mutex consumed_item_counter_mtx; std::condition_variable repo_not_full; std::condition_variable repo_not_empty;&#125; gItemRepository;typedef struct ItemRepository ItemRepository;void ProduceItem(ItemRepository *ir, int item)&#123; std::unique_lock&lt;std::mutex&gt; lock(ir-&gt;mtx); while(((ir-&gt;write_position + 1) % kItemRepositorySize) == ir-&gt;read_position) &#123; // item buffer is full, just wait here. std::cout &lt;&lt; &quot;Producer is waiting for an empty slot...\\n&quot;; (ir-&gt;repo_not_full).wait(lock); &#125; (ir-&gt;item_buffer)[ir-&gt;write_position] = item; (ir-&gt;write_position)++; if (ir-&gt;write_position == kItemRepositorySize) ir-&gt;write_position = 0; (ir-&gt;repo_not_empty).notify_all(); lock.unlock();&#125;int ConsumeItem(ItemRepository *ir)&#123; int data; std::unique_lock&lt;std::mutex&gt; lock(ir-&gt;mtx); // item buffer is empty, just wait here. while(ir-&gt;write_position == ir-&gt;read_position) &#123; std::cout &lt;&lt; &quot;Consumer is waiting for items...\\n&quot;; (ir-&gt;repo_not_empty).wait(lock); &#125; data = (ir-&gt;item_buffer)[ir-&gt;read_position]; (ir-&gt;read_position)++; if (ir-&gt;read_position &gt;= kItemRepositorySize) ir-&gt;read_position = 0; (ir-&gt;repo_not_full).notify_all(); lock.unlock(); return data;&#125;void ProducerTask()&#123; bool ready_to_exit = false; while(1) &#123; sleep(1); std::unique_lock&lt;std::mutex&gt; lock(gItemRepository.produced_item_counter_mtx); if (gItemRepository.produced_item_counter &lt; kItemsToProduce) &#123; ++(gItemRepository.produced_item_counter); ProduceItem(&amp;gItemRepository, gItemRepository.produced_item_counter); std::cout &lt;&lt; &quot;Producer thread &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot; is producing the &quot; &lt;&lt; gItemRepository.produced_item_counter &lt;&lt; &quot;^th item&quot; &lt;&lt; std::endl; &#125; else ready_to_exit = true; lock.unlock(); if (ready_to_exit == true) break; &#125; std::cout &lt;&lt; &quot;Producer thread &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot; is exiting...&quot; &lt;&lt; std::endl;&#125;void ConsumerTask()&#123; bool ready_to_exit = false; while(1) &#123; sleep(1); std::unique_lock&lt;std::mutex&gt; lock(gItemRepository.consumed_item_counter_mtx); if (gItemRepository.consumed_item_counter &lt; kItemsToProduce) &#123; int item = ConsumeItem(&amp;gItemRepository); ++(gItemRepository.consumed_item_counter); std::cout &lt;&lt; &quot;Consumer thread &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot; is consuming the &quot; &lt;&lt; item &lt;&lt; &quot;^th item&quot; &lt;&lt; std::endl; &#125; else ready_to_exit = true; lock.unlock(); if (ready_to_exit == true) break; &#125; std::cout &lt;&lt; &quot;Consumer thread &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot; is exiting...&quot; &lt;&lt; std::endl;&#125;void InitItemRepository(ItemRepository *ir)&#123; ir-&gt;write_position = 0; ir-&gt;read_position = 0; ir-&gt;produced_item_counter = 0; ir-&gt;consumed_item_counter = 0;&#125;int main()&#123; InitItemRepository(&amp;gItemRepository); std::thread producer1(ProducerTask); std::thread producer2(ProducerTask); std::thread producer3(ProducerTask); std::thread producer4(ProducerTask); std::thread consumer1(ConsumerTask); std::thread consumer2(ConsumerTask); std::thread consumer3(ConsumerTask); std::thread consumer4(ConsumerTask); producer1.join(); producer2.join(); producer3.join(); producer4.join(); consumer1.join(); consumer2.join(); consumer3.join(); consumer4.join(); return 0;&#125;","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://lives.xtcgch.ink/tags/线程/"},{"name":"条件变量","slug":"条件变量","permalink":"https://lives.xtcgch.ink/tags/条件变量/"},{"name":"锁","slug":"锁","permalink":"https://lives.xtcgch.ink/tags/锁/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"编译原理之GCC","slug":"编译原理之gcc-20210425","date":"2021-04-25T06:34:26.000Z","updated":"2021-10-10T08:37:02.696Z","comments":true,"path":"2021/04/25/编译原理之GCC/","link":"","permalink":"https://lives.xtcgch.ink/2021/04/25/编译原理之GCC/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 其他模板的标题 知识理解 命名 -o命令： g++ test.cpp -o test功能：生成test.exe的文件。 调试 -g命令： g++ qaq.cpp -o qdq -g功能：生成用于gdb调试的文件qdq.dSYM。 警告 -W -w命令：g++ qaq.cpp -o qaq -W功能：显示所有的警告信息命令：g++ qaq.cpp -o qaq -w功能：禁止显示所有警告信息 优化 -O{num}命令：g++ qaq.cpp -o qaq -O2功能：主要有O1,O2,O3,Os，分别优化大小，功能，功能，大小。 标准 -std={version}命令：g++ qaq.cpp -o qaq -O2 -std=c++11功能：使用标准c++11来编译程序 Win系统栈 -Wl,–stack={size}命令：g++ 1.cpp -o 1 -Wl,–stack=16777216功能：把调用栈的大小指定为16MB。","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"编译器","slug":"编译器","permalink":"https://lives.xtcgch.ink/tags/编译器/"},{"name":"GCC","slug":"GCC","permalink":"https://lives.xtcgch.ink/tags/GCC/"},{"name":"编译原理","slug":"编译原理","permalink":"https://lives.xtcgch.ink/tags/编译原理/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"IPC之线程锁","slug":"IPC之线程锁-20210424","date":"2021-04-23T18:28:52.000Z","updated":"2021-10-10T15:34:35.280Z","comments":true,"path":"2021/04/24/IPC之线程锁/","link":"","permalink":"https://lives.xtcgch.ink/2021/04/24/IPC之线程锁/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 常见的线程锁互斥锁头文件1#include&lt;mutex&gt; 相关变量和函数123std::mutexstd::lock_guard&lt;std::mutex&gt;() ,lock(),unlock()std::unique_lock&lt;std::mutex&gt;() 自旋锁 自旋锁主要适用于被持有时间短，线程不希望在重新调度上花过多时间的情况。 实际上许多其他类型的锁在底层使用了自旋锁实现，例如多数互斥锁在试图获取锁的时候会先自旋一小段时间，然后才会休眠。 C++11之前： 头文件 1#include &lt;pthread.h&gt; 相关变量和函数12345int pthread_spin_init(pthread_spinlock_t *, int); //初始化自旋锁int pthread_spin_lock(pthread_spinlock_t *); //获得一个自旋锁 int pthread_spin_trylock(pthread_spinlock_t *); //尝试获取一个自旋锁int pthread_spin_unlock(pthread_spinlock_t *);//释放（解锁）一个自旋锁 int pthread_spin_destroy(pthread_spinlock_t *); //销毁一个自旋锁 1. 使用C++11的原子操作实现自旋锁 1.1 指定内存序提高性能 12345678910111213141516class spin_mutex &#123; std::atomic&lt;bool&gt; flag = ATOMIC_VAR_INIT(false);public: spin_mutex() = default; spin_mutex(const spin_mutex&amp;) = delete; spin_mutex&amp; operator= (const spin_mutex&amp;) = delete; void lock() &#123; bool expected = false; while(!flag.compare_exchange_strong(expected, true, std::memory_order_acquire)) expected = false; &#125; void unlock() &#123; flag.store(false, std::memory_order_release); &#125;&#125;; 1.2 不使用CAS(compare-and-swap)的实现 1234567891011121314class spin_mutex &#123; std::atomic&lt;bool&gt; flag = ATOMIC_VAR_INIT(false);public: spin_mutex() = default; spin_mutex(const spin_mutex&amp;) = delete; spin_mutex&amp; operator= (const spin_mutex&amp;) = delete; void lock() &#123; while(flag.exchange(true, std::memory_order_acquire)) ; &#125; void unlock() &#123; flag.store(false, std::memory_order_release); &#125;&#125;; 2. 使用std::atomic_flag的实现 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;atomic&gt;#include &lt;thread&gt;#include &lt;mutex&gt;#include &lt;iostream&gt;class spin_mutex &#123; std::atomic_flag flag = ATOMIC_FLAG_INIT;public: spin_mutex() = default; spin_mutex(const spin_mutex&amp;) = delete; spin_mutex&amp; operator= (const spin_mutex&amp;) = delete; void lock() &#123; while(flag.test_and_set(std::memory_order_acquire)) ; &#125; void unlock() &#123; flag.clear(std::memory_order_release); &#125;&#125;;int num = 0;spin_mutex sm;void thread_proc()&#123; for(int i = 0; i &lt; 100000; ++i) &#123; std::lock_guard&lt;spin_mutex&gt; lock(sm); ++num; &#125;&#125;int main()&#123; std::thread td1(thread_proc), td2(thread_proc); td1.join(); td2.join(); std::cout &lt;&lt; num &lt;&lt; std::endl; return 0;&#125; 条件变量std::condition_variable 原子锁std::atomic 读写锁C++17标准以前是boost库，在C++17之后添加到std标准库中 头文件1#include &lt;shared_mutex&gt; 相关变量和函数1234std::shared_mutexlock_shared() unlock_shared() demo: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;thread&gt;#include &lt;shared_mutex&gt;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;unistd.h&gt; // sleep(seconds), usleep(microseconds)using namespace std;class Counter &#123;public: Counter() : value_(0) &#123; &#125; // Multiple threads/readers can read the counter&apos;s value at the same time. std::size_t Get() const &#123; std::shared_lock&lt;std::shared_mutex&gt; lock(mutex_); return value_; &#125; // Only one thread/writer can increment/write the counter&apos;s value. void Increase() &#123; // You can also use lock_guard here. std::unique_lock&lt;std::shared_mutex&gt; lock(mutex_); value_++; &#125; // Only one thread/writer can reset/write the counter&apos;s value. void Reset() &#123; std::unique_lock&lt;std::shared_mutex&gt; lock(mutex_); value_ = 0; &#125;private: mutable std::shared_mutex mutex_; std::size_t value_;&#125;;std::mutex g_io_mutex;void Worker(Counter&amp; counter) &#123; for (int i = 0; i &lt; 3; ++i) &#123; counter.Increase(); std::size_t value = counter.Get(); std::lock_guard&lt;std::mutex&gt; lock(g_io_mutex); std::cout &lt;&lt; std::this_thread::get_id() &lt;&lt; &apos; &apos; &lt;&lt; value &lt;&lt; std::endl; &#125;&#125;int main() &#123; const std::size_t SIZE = 2; Counter counter; std::vector&lt;std::thread&gt; v; v.reserve(SIZE); v.emplace_back(Worker, std::ref(counter)); v.emplace_back(Worker, std::ref(counter)); for (std::thread&amp; t : v) &#123; t.join(); &#125; return 0;&#125; 乐观锁和悲观锁基本概念乐观锁和悲观锁的讨论对象是数据库 乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。 因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。 123update t_goods set status=2,version=version+1 where id=#&#123;id&#125; and version=#&#123;version&#125;; 悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。 因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。 12//悲观锁查询SELECT * FROM account WHERE name = &quot;MAX&quot; for update 实现方式 乐观锁的实现方式主要有两种：CAS机制和版本号机制 优缺点和适用场景乐观锁和悲观锁并没有优劣之分，它们有各自适合的场景；下面从两个方面进行说明。 功能限制 与悲观锁相比，乐观锁适用的场景受到了更多的限制，无论是CAS还是版本号机制。例如，CAS只能保证单个变量操作的原子性，当涉及到多个变量时，CAS是无能为力的，而synchronized则可以通过对整个代码块加锁来处理。 再比如版本号机制，如果query的时候是针对表1，而update的时候是针对表2，也很难通过简单的版本号来实现乐观锁。 竞争激烈程度 如果悲观锁和乐观锁都可以使用，那么选择就要考虑竞争的激烈程度：当竞争不激烈 (出现并发冲突的概率小)时，乐观锁更有优势，因为悲观锁会锁住代码块或数据，其他线程无法同时访问，影响并发，而且加锁和释放锁都需要消耗额外的资源。 当竞争激烈(出现并发冲突的概率大)时，悲观锁更有优势，因为乐观锁在执行更新时频繁失败，需要不断重试，浪费CPU资源。 乐观锁加锁吗 乐观锁本身是不加锁的，只是在更新时判断一下数据是否被其他线程更新了；AtomicInteger便是一个例子。 有时乐观锁可能与加锁操作合作，例如，在前述updateCoins()的例子中，MySQL在执行update时会加排它锁。 但这只是乐观锁与加锁操作合作的例子，不能改变“乐观锁本身不加锁”这一事实。 CAS有哪些缺点","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"IPC","slug":"IPC","permalink":"https://lives.xtcgch.ink/tags/IPC/"},{"name":"线程","slug":"线程","permalink":"https://lives.xtcgch.ink/tags/线程/"},{"name":"锁","slug":"锁","permalink":"https://lives.xtcgch.ink/tags/锁/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"编程语言之C++11特性","slug":"编程语言之C++11特性-20210421","date":"2021-04-20T18:25:12.000Z","updated":"2021-10-10T08:45:25.309Z","comments":true,"path":"2021/04/21/编程语言之C++11特性/","link":"","permalink":"https://lives.xtcgch.ink/2021/04/21/编程语言之C++11特性/","excerpt":"摘要：本文主要介绍C++17特性。","text":"摘要：本文主要介绍C++17特性。 脑图 C++11左值和右值左值和右值的概念主要涉及到模板类，可以通过std::move()和std::static_cast&lt;&gt;()来调整 左值和右值的概念 demo:12int a; // a 为左值a = 3; // 3 为右值 左值是可寻址的变量，有持久性； 右值一般是不可寻址的常量，或在表达式求值过程中创建的无名临时对象，短暂性的,如int &amp;&amp;a = sqrt(4)中sqrt(4)是右值，a则是右值引用 左值和右值主要的区别之一是左值可以被修改，而右值不能。 左值引用和右值引用 左值引用：引用一个对象； 右值引用：就是必须绑定到右值的引用，C++11中右值引用可以实现“移动语义”，通过 &amp;&amp; 获得右值引用。 12345678int x = 6; // x是左值，6是右值int &amp;y = x; // 左值引用，y引用xint &amp;z1 = x * 6; // 错误，x*6是一个右值const int &amp;z2 = x * 6; // 正确，可以将一个const引用绑定到一个右值int &amp;&amp;z3 = x * 6; // 正确，右值引用int &amp;&amp;z4 = x; // 错误，x是一个左值 新规则 规则1（引用折叠规则）：如果间接的创建一个引用的引用，则这些引用就会“折叠”。在所有情况下（除了一个例外），引用折叠成一个普通的左值引用类型。一种特殊情况下，引用会折叠成右值引用，即右值引用的右值引用， T&amp;&amp; &amp;&amp;。即 12X&amp; &amp;、X&amp; &amp;&amp;、X&amp;&amp; &amp;都折叠成X&amp; -&gt; 表示左值引用X&amp;&amp; &amp;&amp;折叠为X&amp;&amp; -&gt; 表示右值引用 规则2（右值引用的特殊类型推断规则）：当将一个左值传递给一个参数是右值引用的函数，且此右值引用指向模板类型参数(T&amp;&amp;)时，编译器推断模板参数类型为实参的左值引用，如12345template&lt;typename T&gt; void f(T&amp;&amp;);int i = 42;f(i) f将被实例化为:void f&lt;int&amp;&gt;(int&amp;) 规则3：虽然不能隐式的将一个左值转换为右值引用，但是可以通过static_cast显示地将一个左值转换为一个右值。【C++11中为static_cast新增的转换功能】 右值能被 const 类型的引用所指向123int x = 5;const int&amp; y = x * 6;std::cout&lt;&lt;&quot;y:&quot;&lt;&lt;y&lt;&lt;std::endl; //y = 30 demo：12345678910void func(int&amp;&amp; a)&#123; cout &lt;&lt; a &lt;&lt; endl;&#125;int a = 6;func(std::move(a));int b = 10;func(static_cast&lt;int&amp;&amp;&gt;(b)); 首先，func函数中的a参数定义为右值引用，那么在使用func函数时，必须保证传入的参数为右值。由int a = 6;可知，a是左值，因此，需要将a转化为右值才能作为func函数的形参，可以使用std::move()或 static_cast&lt;&gt;()进行调整 std::bind1.参数: f：一个可调用对象（可以是函数对象、函数指针、函数引用、成员函数指针、数据成员指针），它的参数将被绑定到args上。args：绑定参数列表，参数会被值或占位符替换，其长度必须与f接收的参数个数一致。 参数可以有2种形式： 明确的值 占位符，下划线+值，如std::placeholders::_1和std::placeholders::_2 2.调用std::bind的一般形式为： auto newCallable = std::bind(callable, arg_list); 3.返回类型: std::bind的返回类型是一个未指定类型T的函数对象，这个类型T满足以下条件: std::is_bind_expression::value == true 4.demo: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 普通函数int add(int a, int b)&#123;return a+b;&#125; ostringstream &amp; printStr(ostringstream &amp;os, const string&amp; s, char c)&#123;os &lt;&lt; s &lt;&lt; c;return os;&#125;// 结构体或类struct Foo &#123; void print_sum(int n1, int n2) &#123; std::cout &lt;&lt; n1+n2 &lt;&lt; &apos;\\n&apos;; &#125; int data = 10;&#125;;struct Foo &#123; int value; void f() &#123; std::cout &lt;&lt; &quot;f(&quot; &lt;&lt; this-&gt;value &lt;&lt; &quot;)\\n&quot;; &#125; void g() &#123; std::cout &lt;&lt; &quot;g(&quot; &lt;&lt; this-&gt;value &lt;&lt; &quot;)\\n&quot;; &#125;&#125;;// 绑定全部参数和调用auto f1 = std::bind(add, 95, 5);f1(); // = 100// 绑定部分参数和调用auto f2 = std::bind(add, 95, _1);f2(5); // = 100auto f3 = std::bind(add, _1, 5);f3(95); // = 100// 绑定一个引用参数ostringstream os1;char c = &apos; &apos;;std::bind(printStr, ref(os1), _1, c);// 绑定成员函数，部分参数和调用Foo foo;auto f4 = std::bind(&amp;Foo::print_sum, &amp;foo, 95, _1);f4(5); // = 100// 指向成员函数的指针void apply(Foo* foo1, Foo* foo2, void (Foo::*fun)()) &#123; (foo1-&gt;*fun)(); // call fun on the object foo1 (foo2-&gt;*fun)(); // call fun on the object foo2&#125;void test() &#123; Foo foo1&#123;1&#125;; Foo foo2&#123;2&#125;; apply(&amp;foo1, &amp;foo2, &amp;Foo::f); apply(&amp;foo1, &amp;foo2, &amp;Foo::g);&#125; std::mem_fnstd::functionstd::mem_fn、std::bind、std::function的区别 std::function是重量级的，功能强大，也复杂，是类模板,比如std::function&lt;int&lt;int&gt;&gt; std::mem_fn、std::bind是具有未指定返回类型的函数模板，即使用auto ret获取返回值 std::movestd::forwardstd::async函数原型 12template&lt;class Fn, class... Args&gt;future&lt;typename result_of&lt;Fn(Args...)&gt;::type&gt; async(launch policy, Fn&amp;&amp; fn, Args&amp;&amp;...args); 参数 launch policy : 表示异步或同步，默认是由系统决定 std::launch::async 传递的可调用对象异步执行； std::launch::deferred 传递的可调用对象同步执行； std::launch::async | std::launch::deferred （默认）可以异步或是同步，取决于操作系统。 Fn&amp;&amp; fn ： 函数 Args&amp;&amp;…args ： 函数参数 std::condition_variable","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"C++11","slug":"C-11","permalink":"https://lives.xtcgch.ink/tags/C-11/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"多线程","slug":"IPC之多线程-20210420","date":"2021-04-18T00:47:05.000Z","updated":"2021-08-27T19:10:20.080Z","comments":true,"path":"2021/04/18/多线程/","link":"","permalink":"https://lives.xtcgch.ink/2021/04/18/多线程/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 知识理解线程池合适的线程数量是多少1.CPU密集型线程数量 大约是 CPU数量的 2 倍。 2.IO密集型第二种任务是耗时 IO 型，比如数据库、文件的读写，网络通信等任务，这种任务的特点是并不会特别消耗 CPU 资源，但是 IO 操作很耗时，总体会占用比较多的时间。对于这种情况任务最大线程数一般会大于 CPU 核心数很多倍，因为 IO 读写速度相比于 CPU 的速度而言是比较慢的，如果我们设置过少的线程数，可能导致 CPU 资源的浪费。而如果我们设置更多的线程数，那么当一部分线程正在等待 IO 的时候，它们此时并不需要 CPU 来计算，那么另外的线程便可以利用 CPU 去执行其他的任务，互不影响，这样的话在任务队列中等待的任务就会减少，可以更好地利用资源。 3.通用公式线程数 = CPU 核心数 * (1+ IO 耗时/CPU 耗时)通过这个公式，我们可以计算出一个合理的线程数量，如果任务的 IO 耗时时间长，线程数就随之增加，而如果CPU 耗时长，也就是对于我们上面的 CPU 密集型任务，线程数就随之减少。 太少的线程数会使得程序整体性能降低，而过多的线程也会消耗内存等其他资源，所以如果想要更准确的话，可以进行压测，监控 JVM 的线程情况以及 CPU 的负载情况，根据实际情况衡量应该创建的线程数，合理并充分利用资源。 4.结论综上所述我们就可以得出以下结论： 线程的 CPU 耗时所占比例越高，就需要越少的线程线程的 IO 耗时所占比例越高，就需要越多的线程针对不同的程序，进行对应的实际测试就可以得到最合适的选择线程数 &gt;= CPU 核心数 编译选项g++ -Wall -std=c++11 -pthread C++11以上：pthreadC++11以下：lpthread","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://lives.xtcgch.ink/tags/线程/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【实战】 网络编程之大小端判断","slug":"网络编程之大小端判断-20210330","date":"2021-03-30T13:30:10.000Z","updated":"2021-10-10T08:39:19.325Z","comments":true,"path":"2021/03/30/网络编程之大小端判断/","link":"","permalink":"https://lives.xtcgch.ink/2021/03/30/网络编程之大小端判断/","excerpt":"摘要：判断网络字节的大小端。","text":"摘要：判断网络字节的大小端。 网络字节序 网络字节序大端和小端1. 概念和区别： 大端字节序（Big Endian）：最高有效位存于最低内存地址处，最低有效位存于最高内存处； 小端字节序（Little Endian）：最高有效位存于最高内存地址，最低有效位存于最低内存处。 2. 网络字节序:大端字节序 网络上传输的数据都是字节流 网络中：UDP/TCP/IP协议规定:把接收到的第一个字节当作高位字节看待,这就要求发送端发送的第一个字节是高位字节;而在发送端发送数据时,发送的第一个字节是该数值在内存中的起始地址处对应的那个字节,也就是说,该数值在内存中的起始地址处对应的那个字节就是要发送的第一个高位字节 主机中：网络字节序就是大端字节序, 有些系统的本机字节序是小端字节序, 有些则是大端字节序, 为了保证传送顺序的一致性, 所以网际协议使用大端字节序来传送数据。 C++实现1234567891011121314151617181920#include&lt;iostrean&gt;bool bLittleEnd(void)&#123; union End &#123; int i; char c; &#125;; End e; e.i = 1; return e.c == 1;&#125;int main()&#123; if(bLittleEnd()) cout&lt;&lt;&quot;小端&quot;&lt;&lt;endl; else cout&lt;&lt;&quot;大端&quot;&lt;&lt;endl; return 0;&#125; 字节序转换函数1234567891011121314#include &lt;arpa/inet.h&gt;//将主机字节序转换为网络字节序 unit32_t htonl (unit32_t hostlong); unit16_t htons (unit16_t hostshort); //将网络字节序转换为主机字节序 unit32_t ntohl (unit32_t netlong); unit16_t ntohs (unit16_t netshort); 说明：h -----host；n----network ；s------short；l----long。htons()--&quot;Host to Network Short&quot;htonl()--&quot;Host to Network Long&quot;ntohs()--&quot;Network to Host Short&quot;ntohl()--&quot;Network to Host Long&quot; 为什么在数据结构 struct sockaddr_in 中， sin_addr 和 sin_port 需要转换为网络字节顺序，而sin_family 需不需要呢? sin_addr 和 sin_port 分别封装在包的 IP 和 UDP 层。因此，它们必须要是网络字节顺序。 sin_family 域只是被内核 (kernel) 使用来决定在数 据结构中包含什么类型的地址，所以它必须是本机字节顺序。同时，sin_family 没有发送到网络上，它们可以是本机字节顺序。","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"网络通信","slug":"网络通信","permalink":"https://lives.xtcgch.ink/tags/网络通信/"},{"name":"网络编程","slug":"网络编程","permalink":"https://lives.xtcgch.ink/tags/网络编程/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"Linux之CentOS7安装python3","slug":"Linux之CentOS7安装python3-20210330","date":"2021-03-30T12:10:55.000Z","updated":"2021-10-10T15:43:06.532Z","comments":true,"path":"2021/03/30/Linux之CentOS7安装python3/","link":"","permalink":"https://lives.xtcgch.ink/2021/03/30/Linux之CentOS7安装python3/","excerpt":"摘要：centos7安装python3！","text":"摘要：centos7安装python3！ 其他模板的标题 思路 安装python3的前置依赖，如zlib 保存旧版本python，安装新版本python 下载python3源代码，编译、安装和配置环境变量 zlib安装1.yum安装1yum install zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl-devel xz xz-devel libffi-devel 或 1yum install -y zlib zlib-devel 2.源码安装 从http://www.zlib.net/下载源码 编译安装12345678910tar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11/su rootmkdir /usr/local/zlib./configure --prefix=/usr/local/zlibmakemake checkmake installecho &quot;/usr/local/zlib/lib&quot; &gt;&gt; /etc/ld.so.conf #环境配置持久化ldconfig -v python3安装 编译安装 123456wget http://npm.taobao.org/mirrors/python/3.8.0/Python-3.8.0.tgz #下载源码tar -xzf Python-3.8.0.tgzsu rootmkdir /usr/local/python3/./configure --prefix=/usr/local/python3make &amp;&amp; make install 创建软连接 在/usr/bin路径下创建python3软链，指向已安装的python3 1ln -s /usr/local/python3/bin/python3 /usr/bin/python3 注意：命令 python 对应的仍是默认2.7版本 命令 python3 则对应新安装的3.8版本 在/usr/bin路径下创建pip3软链，指向已安装的pip31ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 查看版本 12python3 -Vpip3 -V 代码中的问题 python文件中声明时 12#!/usr/bin/python #引用python2.7版本#!/usr/bin/python3 #引用python3.8版本","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"},{"name":"PYTHON","slug":"PYTHON","permalink":"https://lives.xtcgch.ink/tags/PYTHON/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"Linux之CentOS7升级make4.0","slug":"Linux之CentOS7升级make4.0-20210330","date":"2021-03-30T09:14:10.000Z","updated":"2021-10-10T15:43:45.808Z","comments":true,"path":"2021/03/30/Linux之CentOS7升级make4.0/","link":"","permalink":"https://lives.xtcgch.ink/2021/03/30/Linux之CentOS7升级make4.0/","excerpt":"摘要：介绍centos7系统下升级make版本的思路和具体步骤。","text":"摘要：介绍centos7系统下升级make版本的思路和具体步骤。 思路 下载make源代码 编译安装 持久化make环境变量 具体步骤 下载make源码 1234mkdir make4.0wget http://mirrors.ustc.edu.cn/gnu/make/make-4.0.tar.gztar xf make-4.0.tar.gz cd make-4.0/ 配置和安装 123sudo ./configure sudo makesudo make install 持久化环境变量 123456make -v #查看默认引用的make版本/usr/local/bin/make -v #查看安装的make版本whereis make #查询所有的makecd /usr/bin/sudo mv make make.bak #备份旧版本的makeln -sv /usr/local/bin/make /usr/bin/make #建立新版本make的软连接","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"},{"name":"MAKE","slug":"MAKE","permalink":"https://lives.xtcgch.ink/tags/MAKE/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"Linux之CentOS7升级g++","slug":"Linux之CentOS7升级g++-20210330","date":"2021-03-30T06:39:43.000Z","updated":"2021-11-22T00:41:48.862Z","comments":true,"path":"2021/03/30/Linux之CentOS7升级g++/","link":"","permalink":"https://lives.xtcgch.ink/2021/03/30/Linux之CentOS7升级g++/","excerpt":"摘要：整理了一下centos7升级gcc编译器的方法。","text":"摘要：整理了一下centos7升级gcc编译器的方法。 g++版本对应的C++标准传送门 C++17：gcc7完全支持，gcc6和gcc5部分支持，gcc6支持度当然比gcc5高，gcc4及以下版本不支持。 C++14：gcc5就可以完全支持，gcc4部分支持，gcc3及以下版本不支持。 C++11：gcc4.8.1及以上可以完全支持。gcc4.3部分支持，gcc4.3以下版本不支持。 高版本的gcc向下兼容，支持低版本的C++标准。 gcc/g++版本查看12gcc --versiong++ --version 升级说明升级的方法有2个： 不推荐 下载对应版本源代码到本地，手动编译 推荐 安装对应版本的scl源，让yum从源处自动安装 gcc/g++ 7.31.安装SCL源:123sudo yum -y install centos-release-sclsudo yum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutilssudo scl enable devtoolset-7 bash 2.升级gcc/g++:1sudo yum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutils 3.启用软件集(Software Collections):1sudo scl enable devtoolset-7 bash 4.持久化bash引用的环境变量:12su rootecho &quot;source /opt/rh/devtoolset-7/enable&quot; &gt;&gt;/etc/profile 5.将gcc复制到/usr/bin默认目录:12sudo mv /usr/bin/gcc /usr/bin/gcc4.8 sudo cp /opt/rh/devtoolset-7/root/bin/gcc /usr/bin/gcc gcc/g++ 8.31.安装SCL源:123sudo yum -y install centos-release-sclsudo yum -y install devtoolset-8-gcc devtoolset-8-gcc-c++ devtoolset-8-binutilssudo scl enable devtoolset-8 bash 2.升级gcc/g++:1sudo yum -y install devtoolset-8-gcc devtoolset-8-gcc-c++ devtoolset-8-binutils 3.启用软件集(Software Collections):1sudo scl enable devtoolset-8 bash 4.持久化bash引用的环境变量:12sudo rootecho &quot;source /opt/rh/devtoolset-8/enable&quot; &gt;&gt;/etc/profile 5.将gcc复制到/usr/bin默认目录:12sudo mv /usr/bin/gcc /usr/bin/gcc4.8 sudo cp /opt/rh/devtoolset-8/root/bin/gcc /usr/bin/gcc gcc/g++ 9.31.安装SCL源:123sudo yum -y install centos-release-sclsudo yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutilssudo scl enable devtoolset-9 bash 2.升级gcc/g++:1sudo yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils 3.启用软件集(Software Collections):1sudo scl enable devtoolset-9 bash 4.持久化bash引用的环境变量:12su rootecho &quot;source /opt/rh/devtoolset-9/enable&quot; &gt;&gt;/etc/profile 5.将gcc复制到/usr/bin默认目录:12sudo mv /usr/bin/gcc /usr/bin/gcc4.8 sudo cp /opt/rh/devtoolset-9/root/bin/gcc /usr/bin/gcc gcc/g++ 101.安装SCL源:123sudo yum -y install centos-release-sclsudo yum -y install devtoolset-10-gcc devtoolset-10-gcc-c++ devtoolset-10-binutilssudo scl enable devtoolset-10 bash 2.升级gcc/g++:1sudo yum -y install devtoolset-10-gcc devtoolset-10-gcc-c++ devtoolset-10-binutils 3.启用软件集(Software Collections):1sudo scl enable devtoolset-10 bash 4.持久化bash引用的环境变量:12su rootecho &quot;source /opt/rh/devtoolset-10/enable&quot; &gt;&gt;/etc/profile 5.将gcc复制到/usr/bin默认目录:12sudo mv /usr/bin/gcc /usr/bin/gcc4.8 sudo cp /opt/rh/devtoolset-10/root/bin/gcc /usr/bin/gcc","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"DEBUG之GDB的使用","slug":"DEBUG之GDB的使用-20210330","date":"2021-03-30T06:25:22.000Z","updated":"2021-10-10T15:45:18.053Z","comments":true,"path":"2021/03/30/DEBUG之GDB的使用/","link":"","permalink":"https://lives.xtcgch.ink/2021/03/30/DEBUG之GDB的使用/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 mtrace检测内存泄漏内存行为日志 mtrace工具安装1sudo yum install glibc-utils mtrace命令 先运行程序，产生日志文件log.log 使用命令mtrace [exe] [log日志]来查看，如 mtrace list log.log 检测结果： 无内存泄漏： 内存泄漏：","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"GDB","slug":"GDB","permalink":"https://lives.xtcgch.ink/tags/GDB/"},{"name":"编译器","slug":"编译器","permalink":"https://lives.xtcgch.ink/tags/编译器/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"字符串单词逆序输出","slug":"字符串单词逆序输出-20210330","date":"2021-03-30T06:12:38.000Z","updated":"2021-10-10T08:08:45.466Z","comments":true,"path":"2021/03/30/字符串单词逆序输出/","link":"","permalink":"https://lives.xtcgch.ink/2021/03/30/字符串单词逆序输出/","excerpt":"摘要：字符串里面单词逆序输出，如输入：hello world ，输出为：world hello。","text":"摘要：字符串里面单词逆序输出，如输入：hello world ，输出为：world hello。 脑图 C++实现代码1234567891011121314151617181920212223242526272829303132333435363738394041424344#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;string temp;bool SubReverse(string&amp; str,const char ch,int n)&#123; if(n &gt; str.length() -1) &#123; return false; &#125; if(str[n + 1] != &apos;\\0&apos;) &#123; int index = n+1; SubReverse(str,ch,index); &#125; temp = str[n] + temp; if(str[n] == ch || n == 0) &#123; cout &lt;&lt;&quot;&quot;&lt;&lt;temp&lt;&lt;&quot; &quot;; temp = &quot;&quot;; &#125; return true;&#125;void Reverse(string&amp; str,const char ch)&#123; int index = 0; cout &lt;&lt;&quot;before,string:&quot;&lt;&lt;str&lt;&lt;endl; cout &lt;&lt;&quot;after, string:&quot;; SubReverse(str,ch,index);&#125;int main()&#123; string line = &quot;hello world&quot;; Reverse(line,&apos; &apos;); return 0;&#125; 输出","categories":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/tags/算法/"}],"keywords":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}]},{"title":"【实战】链表反转","slug":"链表反转-20210318","date":"2021-03-18T00:49:46.000Z","updated":"2021-10-10T08:08:32.128Z","comments":true,"path":"2021/03/18/链表反转/","link":"","permalink":"https://lives.xtcgch.ink/2021/03/18/链表反转/","excerpt":"摘要：简单实现链表反转","text":"摘要：简单实现链表反转 C++实现代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include&lt;iostream&gt;#include &lt;mcheck.h&gt;#include&lt;stdlib.h&gt;using namespace std;struct STNode&#123; int data; STNode* next;&#125;;STNode* CreateList()&#123; STNode* head = new STNode(); head-&gt;data = -1; head-&gt;next = NULL; STNode* p = head; for(int i=0;i&lt;10;i++) &#123; STNode* node = new STNode(); node-&gt;data = i; node-&gt;next = NULL; p-&gt;next = node; p = node; &#125; return head;&#125;void DestroyList(STNode* head)&#123; STNode* p = head; while(NULL != p) &#123; head = p-&gt;next; delete p; p = head; &#125;&#125;void PrintList(const STNode* head)&#123; const STNode* p = head-&gt;next; while(p != NULL) &#123; cout&lt;&lt;&quot;data:&quot;&lt;&lt;p-&gt;data&lt;&lt;endl; p = p-&gt;next; &#125;&#125;STNode* ReverseList(STNode* head)&#123; STNode* beg = head-&gt;next; STNode* end = head-&gt;next; if(NULL != beg) &#123; end = beg-&gt;next; &#125; while(end != NULL) &#123; beg-&gt;next = end-&gt;next; end-&gt;next = head-&gt;next; head-&gt;next = end; end = beg-&gt;next; &#125; return head;&#125;int main()&#123; setenv(&quot;MALLOC_TRACE&quot;,&quot;mem.log&quot;,1);//设置内存检测行为日志，保存在执行目录下，文件名：mem.log mtrace();//开始检测内存分配和释放行为 STNode* list = CreateList(); cout&lt;&lt;&quot;before reverse:&quot;&lt;&lt;endl; PrintList(list); list = ReverseList(list); cout&lt;&lt;&quot;after reverse:&quot;&lt;&lt;endl; PrintList(list); DestroyList(list); muntrace();//结束内存检测行为 return 0;&#125; 输出 mtrace检测内存泄漏内存行为日志 mtrace工具安装1sudo yum install glibc-utils mtrace命令 先运行程序，产生日志文件log.log 使用命令mtrace [exe] [log日志]来查看，如 mtrace list log.log 检测结果： 无内存泄漏： 内存泄漏：","categories":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"链表","slug":"链表","permalink":"https://lives.xtcgch.ink/tags/链表/"}],"keywords":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}]},{"title":"编译原理之cmake","slug":"编译原理之cmake-20201203","date":"2020-12-03T03:00:30.000Z","updated":"2021-10-10T15:55:43.428Z","comments":true,"path":"2020/12/03/编译原理之cmake/","link":"","permalink":"https://lives.xtcgch.ink/2020/12/03/编译原理之cmake/","excerpt":"摘要：学习cmake语法。","text":"摘要：学习cmake语法。 脑图 前言make、makefile、cmake、nmake的关系 make make工具可以看成是一个智能的批处理工具，它本身并没有编译和链接的功能，而是用类似于批处理的方式—通过调用makefile文件中用户指定的命令来进行编译和链接的 makefile make工具就根据makefile中的命令进行编译和链接的 cmake cmake根据CMakeLists.txt文件生成makefile文件 cmake可以跨平台生成对应平台能用的makefile文件 CMakeList.txt demo： 123456789101112131415161718192021222324252627282930313233#project name PROJECT(test_math) add_definitions(&quot;-Wall -lpthread -g&quot;) #head file path INCLUDE_DIRECTORIES( include ) #source directory AUX_SOURCE_DIRECTORY(src DIR_SRCS) #set environment variable SET(TEST_MATH $&#123;DIR_SRCS&#125; ) #set extern libraries SET(LIBRARIES libm.so ) # set output binary path SET(EXECUTABLE_OUTPUT_PATH $&#123;PROJECT_BINARY_DIR&#125;/bin) SET(FS_BUILD_BINARY_PREFIX &quot;Yfs&quot;) #add executable file ADD_EXECUTABLE($&#123;FS_BUILD_BINARY_PREFIX&#125;sqrt $&#123;TEST_MATH&#125;) #add link library TARGET_LINK_LIBRARIES($&#123;FS_BUILD_BINARY_PREFIX&#125;sqrt $&#123;LIBRARIES&#125;) nmake windows环境下类似于make的工具 make过程1、make会在当前目录下找名字叫“Makefile”或“makefile”的文件。2、如果找到，它会找文件中的第一个目标文件（target），在上面的例子中，他会找到“edit”这个文件，并把这个文件作为最终的目标文件。3、如果edit文件不存在，或是edit所依赖的后面的 .o 文件的文件修改时间要比edit这个文件新，那么，他就会执行后面所定义的命令来生成edit这个文件。4、如果edit所依赖的.o文件也不存在，那么make会在当前文件中找目标为.o文件的依赖性，如果找到则再根据那一个规则生成.o文件。（这有点像一个堆栈的过程）5、当然，你的C文件和H文件是存在的啦，于是make会生成 .o 文件，然后再用 .o 文件生命make的终极任务，也就是执行文件edit了。这就是整个make的依赖性，make会一层又一层地去找文件的依赖关系，直到最终编译出第一个目标文件。 CMakeLists.txt多层CMakeLists.txt使用|—example_person.cpp|—CMakeLists.txt|—proto_pb2 |–Person.pb.cc |–Person.pb.h |–CMakeLists.txt|—proto_buf |—General_buf_read.h |—General_buf_write.h|—protobuf |—bin |—… |—include |—… |—lib |—… 当目录层次结构为上下层关系时，通常的解决方案，就是将下层目录编译成一个静态库文件，让上层目录直接读取和调用，而上层目录就直接生成一个可执行文件。 上层CMakeLists.txt的内容为：123456789101112131415161718192021222324252627cmake_minimum_required(VERSION 3.0)project(example_person)# 如果代码需要支持C++11，就直接加上这句SET(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++0x&quot;)# 如果想要生成的可执行文件拥有符号表，可以gdb调试，就直接加上这句add_definitions(&quot;-Wall -g&quot;)# 设置变量，下面的代码都可以用到set(GOOGLE_PROTOBUF_DIR $&#123;PROJECT_SOURCE_DIR&#125;/protobuf)set(PROTO_PB_DIR $&#123;PROJECT_SOURCE_DIR&#125;/proto_pb2)set(PROTO_BUF_DIR $&#123;PROJECT_SOURCE_DIR&#125;/proto_buf)# 编译子文件夹的CMakeLists.txtadd_subdirectory(proto_pb2)# 规定.h头文件路径include_directories($&#123;PROJECT_SOURCE_DIR&#125; $&#123;PROTO_PB_DIR&#125; $&#123;PROTO_BUF_DIR&#125;)# 生成可执行文件add_executable($&#123;PROJECT_NAME&#125; example_person.cpp )# 链接操作target_link_libraries($&#123;PROJECT_NAME&#125; general_pb2) 下层CMakeLists.txt的内容为： 123456789101112131415project(general_pb2)aux_source_directory($&#123;PROJECT_SOURCE_DIR&#125; PB_FILES)add_library($&#123;PROJECT_NAME&#125; STATIC $&#123;PB_FILES&#125;)include_directories($&#123;PROJECT_SOURCE_DIR&#125; $&#123;GOOGLE_PROTOBUF_DIR&#125;/include)link_directories($&#123;GOOGLE_PROTOBUF_DIR&#125;/lib/)target_link_libraries($&#123;PROJECT_NAME&#125; protobuf) cmake使用思路：在项目顶层目录下,创建build文件夹，在build文件夹中生成中间文件和最终可执行文件、链接库。 1231. mkdir build &amp; cd build 1. cmake .. #在build文件夹中生成Makefile文件1. make #在build文件夹中生成最终可执行文件、链接库 cmake安装或升级删除自带版本本： 1yum remove cmake -y &amp;&amp; rm -f /usr/bin/cmake 下载： 1wget -c https://cmake.org/files/LatestRelease/cmake-3.20.1.tar.gz 解压：1tar xvf cmake-3.20.1.tar.gz &amp;&amp; cd cmake-3.20.1/ 设置openssl的根目录：12CMakeLists.txtset(OPENSSL_ROOT_DIR &quot;/home/xtcgch/Env/openssl/base&quot;) 安装：123sudo ./configure --prefix=/usr/local/cmakesudo make sudo make install 软链：1ln -s /usr/local/bin/cmake /usr/bin/ 配置环境变量123vim /etc/profileexport CMAKE_HOME=/usr/local/cmakeexport PATH=$PATH:$CMAKE_HOME/bin 查看安装后的版本：1cmake --version 常用命令cmake_minimum_required(VERSION 3.4.1)指定需要的最小的cmake版本 project (HELLO) 指定项目名称，生成的VC项目的名称 使用${HELLO_SOURCE_DIR}表示项目根目录 aux_source_directory查找源文件并保存到相应的自定义变量中: 1234#查找当前目录下所有源文件并保存至SRC_LIST变量中aux_source_directory(. SRC_LIST)或aux_source_directory($&#123;PROJECT_SOURCE_DIR&#125; SRC_LIST) # PROJECT_SOURCE_DIR是cmake内置变量 add_library 添加一个库 1add_library(&lt;name&gt; [STATIC | SHARED | MODULE] [EXCLUDE_FROM_ALL] source1 source2 ... sourceN) 添加一个名为的库文件 指定STATIC, SHARED, MODULE参数来指定要创建的库的类型, STATIC对应的静态库(.a),SHARED对应共享动态库(.so) [EXCLUDE_FROM_ALL], 如果指定了这一属性，对应的一些属性会在目标被创建时被设置(指明此目录和子目录中所有的目标，是否应当从默认构建中排除, 子目录的IDE工程文件/Makefile将从顶级IDE工程文件/Makefile中排除) source1 source2 … sourceN用来指定源文件 123456789# Add source filesset(SOURCE_FILES co_epoll.cpp co_hook_sys_call.cpp co_routine.cpp coctx.cpp coctx_swap.S)# Add static and shared library targetadd_library(colib_static STATIC $&#123;SOURCE_FILES&#125;) 导入已有的库 语法:1add_library(&lt;name&gt; [STATIC | SHARED | MODULE | UNKNOWN] IMPORTED) demo: 1234add_library(test SHARED IMPORTED)set_target_properties( test #指定目标库名称 PROPERTIES IMPORTED_LOCATION #指明要设置的参数 libs/src/$&#123;ANDROID_ABI&#125;/libtest.so #设定导入库的路径) set设置CMake变量 1234567891011# 设置可执行文件的输出路径(EXCUTABLE_OUTPUT_PATH是全局变量)set(EXECUTABLE_OUTPUT_PATH [output_path])# 设置库文件的输出路径(LIBRARY_OUTPUT_PATH是全局变量)set(LIBRARY_OUTPUT_PATH [output_path])# 设置C++编译参数(CMAKE_CXX_FLAGS是全局变量)set(CMAKE_CXX_FLAGS &quot;-Wall std=c++11&quot;)# 设置源文件集合(SOURCE_FILES是本地变量即自定义变量)set(SOURCE_FILES main.cpp test.cpp ...) include_directories指定头文件的搜索路径，相当于指定gcc的-I参数 12# 可以用相对或绝对路径，也可以用自定义的变量值include_directories(./include $&#123;MY_INCLUDE&#125;) add_executable添加可执行文件 1add_executable(&lt;name&gt; $&#123;SRC_LIST&#125;) # name 是可执行文件，如./hello ，SRC_LIST是cpp文件，h头文件等源文件 target_link_libraries将若干库链接到目标库文件 1target_link_libraries(&lt;name&gt; lib1 lib2 lib3) add_definitions1add_definitions(-DFOO -DDEBUG ...) add_subdirectory123# sub_dir指定包含CMakeLists.txt和源码文件的子目录位置# binary_dir是输出路径， 一般可以不指定add_subdirectory(sub_dir [binary_dir]) file123456789101112131415161718192021# 将message写入filename文件中,会覆盖文件原有内容file(WRITE filename &quot;message&quot;)# 将message写入filename文件中，会追加在文件末尾file(APPEND filename &quot;message&quot;)# 从filename文件中读取内容并存储到var变量中，如果指定了numBytes和offset，# 则从offset处开始最多读numBytes个字节，另外如果指定了HEX参数，则内容会以十六进制形式存储在var变量中file(READ filename var [LIMIT numBytes] [OFFSET offset] [HEX])# 重命名文件file(RENAME &lt;oldname&gt; &lt;newname&gt;)# 删除文件， 等于rm命令file(REMOVE [file1 ...])# 创建目录file(MAKE_DIRECTORY [dir1 dir2 ...])# 会把path转换为以unix的/开头的cmake风格路径,保存在result中file(TO_CMAKE_PATH path result) set_directory_properties设置某个路径的一种属性 1set_directory_properties(PROPERTIES prop1 value1 prop2 value2) prop1 prop代表属性，取值为： INCLUDE_DIRECTORIES LINK_DIRECTORIES INCLUDE_REGULAR_EXPRESSION ADDITIONAL_MAKE_CLEAN_FILES set_property在给定的作用域内设置一个命名的属性 12345678set_property(&lt;GLOBAL | DIRECTORY [dir] | TARGET [target ...] | SOURCE [src1 ...] | TEST [test1 ...] | CACHE [entry1 ...]&gt; [APPEND] PROPERTY &lt;name&gt; [value ...]) 第一个参数决定了属性可以影响的作用域,必须为以下值： GLOBAL 全局作作用域,不接受名字 DIRECTORY 默认为当前路径，但是同样也可以用[dir]指定路径 TARGET 目标作用，可以是0个或多个已有的目标 SOURCE 源作用域， 可以是0个过多个源文件 TEST 测试作用域, 可以是0个或多个已有的测试 CACHE 必须指定0个或多个cache中已有的条目 demoappstatic libshared lib FAQ 怎样获得一个目录下的所有源文件 aux_source_directory( ) 将dir中所有源文件（不包括头文件）保存到变量variable中，然后可以add_executable (ss7gw ${variable})这样使用。 怎样指定项目编译目标 project命令指定 怎样添加动态库和静态库 target_link_libraries命令添加即可 怎样在执行CMAKE时打印消息 message([SEND_ERROR | STATUS | FATAL_ERROR] “message to display” …) 注意大小写 怎样指定头文件与库文件路径include_directories与link_directories 可以多次调用以设置多个路径 link_directories仅对其后面的targets起作用 怎样区分debug、release版本 建立debug/release两目录，分别在其中执行cmake -DCMAKE_BUILD_TYPE=Debug（或Release），需要编译不同版本时进入不同目录执行make即可； Debug版会使用参数-g；Release版使用-O3 –DNDEBUG 另一种设置方法——例如DEBUG版设置编译参数DDEBUG IF(DEBUG_mode) add_definitions(-DDEBUG) ENDIF() 在执行cmake时增加参数即可，例如cmake -D DEBUG_mode=ON 怎样设置条件编译 例如debug版设置编译选项DEBUG，并且更改不应改变CMakelist.txt 使用option command，eg： option(DEBUG_mode “ON for debug or OFF for release” ON) IF(DEBUG_mode) add_definitions(-DDEBUG) ENDIF() 使其生效的方法：首先cmake生成makefile，然后make edit_cache编辑编译选项；Linux下会打开一个文本框，可以更改，该完后再make生成目标文件——emacs不支持make edit_cache； 局限：这种方法不能直接设置生成的makefile，而是必须使用命令在make前设置参数；对于debug、release版本，相当于需要两个目录，分别先cmake一次，然后分别make edit_cache一次； 期望的效果：在执行cmake时直接通过参数指定一个开关项，生成相应的makefile——可以这样做，例如cmake –DDEBUGVERSION=ON 怎样添加编译宏定义 使用add_definitions命令，见命令部分说明 怎样添加编译依赖项 用于确保编译目标项目前依赖项必须先构建好 add_dependencies 怎样指定目标文件目录 建立一个新的目录，在该目录中执行cmake生成Makefile文件，这样编译结果会保存在该目录——类似 SET_TARGET_PROPERTIES(ss7gw PROPERTIES RUNTIME_OUTPUT_DIRECTORY &quot;${BIN_DIR}&quot;) 很多文件夹，难道需要把每个文件夹编译成一个库文件？ 可以不在子目录中使用CMakeList.txt，直接在上层目录中指定子目录 怎样设定依赖的cmake版本 cmake_minimum_required(VERSION 2.6) 相对路径怎么指定 ${projectname_SOURCE_DIR}表示根源文件目录，${ projectname _BINARY_DIR}表示根二进制文件目录？ 怎样设置编译中间文件的目录 TBD 怎样在IF语句中使用字串或数字比较 数字比较LESS、GREATER、EQUAL，字串比STRLESS、STRGREATER、STREQUAL， Eg： set(CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS ON) set(AAA abc) IF(AAA STREQUAL abc) message(STATUS &quot;true&quot;) #应该打印true ENDIF() 更改h文件时是否只编译必须的cpp文件 是 怎样根据OS指定编译选项 IF( APPLE ); IF( UNIX ); IF( WIN32 ) 能否自动执行某些编译前、后命令？ 可以，TBD 怎样打印make的输出 make VERBOSE=1","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"CMAKE","slug":"CMAKE","permalink":"https://lives.xtcgch.ink/tags/CMAKE/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"协程的学习","slug":"协程的学习-20201203","date":"2020-12-03T01:31:47.000Z","updated":"2021-08-17T17:27:10.184Z","comments":true,"path":"2020/12/03/协程的学习/","link":"","permalink":"https://lives.xtcgch.ink/2020/12/03/协程的学习/","excerpt":"摘要：记录协程的知识点。","text":"摘要：记录协程的知识点。 脑图 简介C++20前的boost::coroutinesboost::coroutines2::coroutine&lt;&gt; 头文件 1#include &lt;boost/coroutine2/coroutine.hpp&gt; 相关函数 123pull_typepush_typesink g++ test_coroutine.cpp -lboost_coroutine -lboost_context -o test C++20下的std::coroutines知识理解 协程是比线程更小的一种执行单元,每个线程分配1M左右的栈空间，而协程可能只有几十或者几百K 线程的调度是在操作系统中进行的,而协程调度则是在用户空间进行的，是开发人员通过调用系统底层的执行上下文相关api来完成的 协成是基于线程实现的，协程的创建、切换、销毁都是在某个线程中来进行的 协程是用户级的线程 协程无法使用CPU的多核 协程要和异步使用才能发挥优势 协程是分时复用，线程是时间片， C++20标准添加了协程的支持，即std::coroutine 协程切换快原理 线程在进行切换的时候，需要将CPU中的寄存器的信息存储起来，然后读入另外一个线程的数据，这个会花费一些时间 CPU的高速缓存中的数据，也可能失效，需要重新加载 线程的切换会涉及到用户模式到内核模式的切换，据说每次模式切换都需要执行上千条指令，很耗时 优势 在切换的时候，寄存器需要保存和加载的数据量比较小。 高速缓存可以有效利用 没有用户模式到内核模式的切换操作。 更有效率的调度，因为协程是非抢占式的，前一个协程执行完毕或者堵塞，才会让出CPU，而线程则一般使用了时间片的算法，会进行很多没有必要的切换（为了尽量让用户感知不到某个线程卡） 推荐项目 腾讯的libco项目 传送门: libco项目github地址 2.","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"协程","slug":"协程","permalink":"https://lives.xtcgch.ink/tags/协程/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"数据库之实战篇","slug":"数据库之实战篇-20201203","date":"2020-12-02T19:00:46.000Z","updated":"2021-10-10T07:45:30.962Z","comments":true,"path":"2020/12/03/数据库之实战篇/","link":"","permalink":"https://lives.xtcgch.ink/2020/12/03/数据库之实战篇/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 其他模板的标题 前言MyISAM和InnoDBMySQL各版本比较MySQL集群 SQL优化-&gt; SQL优化","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"MYSQL","slug":"MYSQL","permalink":"https://lives.xtcgch.ink/tags/MYSQL/"},{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"数据库之理论篇","slug":"数据库之理论篇-20201203","date":"2020-12-02T17:03:11.000Z","updated":"2021-10-10T07:44:13.258Z","comments":true,"path":"2020/12/03/数据库之理论篇/","link":"","permalink":"https://lives.xtcgch.ink/2020/12/03/数据库之理论篇/","excerpt":"摘要：记录数据库的一些知识。","text":"摘要：记录数据库的一些知识。 脑图 关系型数据库原则 数据库最容易也通常是一个系统的瓶颈，因此不要给数据库加压力，能够程序处理就程序处理 一个系统越简单越稳定越不容量出问题， 因此要尽量简单使用数据库， 如SQL简单，事务小 数据库是很难水平扩容的， 要水平扩容动作是很大的， 出了故障影响也是很大的， 不像应用可以很容易水平扩容。因此不要什么都往里面保存， 要预估好数据量 命名规范 所有数据库对象名（库名，表名,字段名等）必须由英文小写字母，下划线及数字组成，不要使用大写字母，更不能使用中文等非英文字符。 所有数据库对象名不能使用mysql本身的关键字 所有数据库对象名控制在32个字符内，名字要见文识义， 如t_merchant与t_merchant_login 临时库表以tmp_为前缀并以日期为后缀，备份表以bak_为前缀并以日期(时间戳)为后缀 分库或者分表以编号为结尾， 如db001, tb_001 日表月表等时间分表以时间为结尾, 如tb20190909 建表设计规范 创建数据库或者表时要显式指定字符集， mysql5.1版本只能指定utf8, mysql5.5及以上版本只能指定为utf8mb4, 不要在字段上指定字符集。如create database db1 default character set utf8mb4 创建表时要显式指定为engine=innodb， 如CREATE TABLE tb (xxx) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=’备份配置表’ 表与每个字段要有COMMENT说明用途， 字段要NOT NULL DEFAULT xx指定默认值，使用NULL值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题 日期默认值或者插入值禁止为’0000-00-00 00:00:00’等无意义非法时间或者日期值 表必须要有主键， 主健只能是单个字段组成， 字段类型只能是unsigned int/bigint， 数据量多的要为unsigned bigint。主健命名为id,最好能程序生成全局唯一顺序增长整数，如不能则使用自增auto_increment。主健在业务上应该无意义，即是程序不应该用到它。业务意义需要id要另起一列， 如user_id。 并不是只能主键才能做到唯一性约束， 唯一索引UNIQUE KEY也可以。不要使用主键来做唯一性约束， 请使用唯一索引 每个表都要有create_time, update_time字段，create_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT ‘创建时间’， update_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT ‘创建时间’。并且update_time要加索引， create_time可以视情况加不加索引 一个表数据量最好不要超过500万行 临时表与中间表要定期清理数据， 清理数据不要直接delete全表，请先找DBA商量 严禁使用存储过程 严禁使用触发器 严禁使用外键 严禁使用event 严禁使用分区表,严禁使用视图view 严禁使用数据库存储图片与文件等二进制数据，禁止使用blob类型字段， 非必要不能使用text类型字段 严禁使用enum, set类型字段， 请使用tinyint, smallint代替 反范式设计：把经常需要join查询的字段，在其他表里冗余一份。如user_name属性在user_account，user_login_log等表里冗余一份，减少join查询 保存相同数据的字段在不同的表，其命名与类型要一致。例如user_id在t_user表为bigint则在t_user_login也要为user_id bigint。严禁使用不同类型， 这在join语句中会引起类型转换，导致使用不了索引 字段类型选择 优先选择符合存储需要的最小的数据类型 能用整形就不要用浮点数或者字符串。合适就好，不要过大，浪费空间；也不要过小， 范围溢出。例如status，user_type此类分类字段， 使用tinyint一般够了。订单表自增主健id那就要使用unsigned bigint。如果范围不够， 那得修改大字段类型， 是要做DDL变更的。 对于整型字段,非负数都加上unsigned, 可存储值大一倍 使用varchar而不是char.对于字符串,由于使用utf8/utf8mb4字符集,char(10)与varchar(10)一样都是需要额外空间来保存实际的长度,是一样的，没什么区别，因此建议都使用varchar(10),省去不够长时的填充空格 禁止使用blob类型字段。 非必须不要使用text字段，如果一定要使用请与表基础字段分离独立另一个表 禁止使用set与enum类型字段 财务相关字段使用decimal类型或者整型，不要使用float或者double 建索引 ID,编号，时间等字段请在建表时加索引，这些一般查询会用到 能建复合索引就建复合索引，例如user_id与user_name都要那索引，那建两个索引(user_id, user_name)与user_name, 而不是user_id与user_name分别一个索引 复合索引包含的字段数不要超过3个, 选择性高的字段放在前面，即是重复值越少排越前面。例如user_name与status, 复合索引应该为(user_name, status)而不是(status, user_name) 索引不要少。我第一次遇到大家担心多了索引影响插入的速度的情况， 这个是不必要的， insert很难成为瓶颈， 基本都是select,update, delete等需要搜索记录的SQL成为瓶颈。也就是搜索永远是数据库的瓶颈， 而使用索引只是为了加快搜索 索引不要过多与冗余。每个索引都是一棵B+树， 每个节点都要存储索引字段与主健值， 别的不说， 会占用不少硬盘空间， 特别是我们公司数据量这么大的情况下。 索引（user_name）与索引(user_name, user_id)就重复了， 需要去掉索引(user_name) 在多表join的SQL里，驱动表的连接列上要有索引。例如t1 inner join t2 on t1.user_id=t2.user_id， 那么t1.user_id与t2.user_id都要有索引。 索引命名， 唯一索引以uidx_为开头如uidx_userid， 普通索引以idx_为开头idx_username SQL规范 连接管理 使用长连接与连接池， 合理设置最大连接数， 最小连接数， 空闲连接回收时间。数据库对空闲连接的回收时间为10分钟， 应用空闲连接回收应该少于10分钟。 连接池一般有重连功能， 没有重连功能的请大家配置上。处理故障时DBA会第一时间切换IP， 没有重连功能的应用需要重启。创建连接或读写timeout时间请合理设置， 例如3秒 使用完连接请主动关闭连接， 释放资源 API支持mysql5.7版本的新功能mysql_reset_connection()的请间隔一段时间reset连接,释放数据库资源。长连接可能存在一个问题,由于连接一直在使用,所消耗的资源不释放,mysql内存会不停增长。有些连接池自行实现了类似的功能,一个连接使用一段时间后就关闭这个连接重建创建一个新的连接,如果有这样的功能也请打开 严禁长事务,有些事务超过了1小时,这是严禁的,请不要在一个事务里面一个SQL执行完成了,去执行其它代码，长时间后再回来执行一个SQL。如果一个事务太多SQL太多步骤,要执行很长时间,请拆分为多个小事务。一个事务保持在10秒内是比较好的。 严禁大事务,一个事务插入几百上千万行， 这也是严禁的。 请将一个事务影响或者涉及的行数控制在200行内5.4 事务内请专注与mysql相关的查询,不要在一个事务内去执行与mysql无关的代码，如查一下mysql然后去读个文件 严禁select *,除了性能问题，更多的是业务兼容性的考虑 严禁一次性大批量插入更新删除数据,必须要小批量变更， 一次不要超过1000行。例如 update tb set col=xx where a=xx and b=xx, 则这样的来小批量更新update tb set col=xx where a=xx and b=xx and id &gt;=yy and id &lt; yy+1000, 循环更新， 最好每个循环加个sleep(1) 禁止limit更新删除,禁用update|delete t1 … where a=XX limit XX; 这种带limit的更新语句。因为会导致主从不一致，导致数据错乱。建议加上order by id 禁止使用子查询，特别是依赖子查询子查询基本都可以使用join来代替。子查询特别是依赖子查询严重影响性能 order by、group by、distinct 尽量少用,没必要的排序就不要排， 像order by order_sn这样的排序没任何意义。如果一定要排序，请确保where条件过滤出来的结果集不过多，例如不要超过5000行 join表不要超过3个，join的字段要有索引 insert into…values(XX),(XX),(XX)…。这里XX的值不要超过200个 in值列表限制在200以内。例如select… where userid in(….200个以内…) 严禁全表无条件更新删除查询，必须要有where条件 where条件里等号左右字段类型必须一致，否则无法利用索引,where user_id=11, 如果user_id为字符串类型， 这样是用不上索引的。 严禁like ‘%xx%’,只能like ‘xx%’ 严禁where条件字段使用函数或表达式，否则无法利用索引,如where date_format(update_time, ‘%Y-%m-%d’)=’2019-09-09’,或where user_id+2=10023 严禁同字段where条件使用or,如 where user_id=1 or user_id=2, 请使用 in, where user_id in (1, 2) 不同字段where条件or尽量用union代替,如 select yy from tb where user_id=1 or user_name=’xx’, 请使用 select yy from tb where user_id=1 union select yy from tb where user_name=’xx’。 禁止使用不含字段列表的INSERT语句,如：insert into values (a,b,c);应使用insert into t(c1,c2,c3) values (a,b,c); 在明显不会有重复值时使用UNION ALL而不是UNION,UNION会把两个结果集的所有数据放到临时表中后再进行去重操作,UNION ALL不会再对结果集进行去重操作 严禁特复杂的SQL,一条SQL几百行,一个SQL里面套了5,6层子查询,一个SQL里面select col1, col2 …, 每个col都是一个子查询,等等,SQL越简单越好 数据库的5种索引类型普通索引唯一索引全文索引（FULLTEXT）单列索引、多列索引 单列索引，如index(id),index(name),可以对id和name单独使用索引 多列索引，如index(id,name)，相当于建立了2个索引，index(id)和index(id,name)，不能单独对name使用索引 组合索引（最左前缀） 非关系型数据库Q &amp; A 哈希(hash)比树(tree)更快，索引结构为什么要设计成树型 单行查询的SQL，hash 比 tree 的效率高，hash时间复杂度都是O(1)，tree平均时间复杂度都是O(lg(n)) 排序查询的SQL，hash 比 tree 的效率低，如 分组：group by，排序：order by，比较：&lt;、&gt;。hash时间复杂度O(n)，tree时间复杂度O(log(n)) 时间复杂度 hash tree 单行sql O(1) O(log(n)) 排序sql O(n) O(log(n)) 总结","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"},{"name":"SQL","slug":"SQL","permalink":"https://lives.xtcgch.ink/tags/SQL/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"GCC和G++的编译","slug":"GCC和G++的编译-20201202","date":"2020-12-02T13:21:04.000Z","updated":"2021-11-01T03:36:31.193Z","comments":true,"path":"2020/12/02/GCC和G++的编译/","link":"","permalink":"https://lives.xtcgch.ink/2020/12/02/GCC和G++的编译/","excerpt":"摘要：本文记录GCC和G++的一些要点。","text":"摘要：本文记录GCC和G++的一些要点。 脑图 前言 GCC部分GCC编译流程 预处理-Pre-Processing // -&gt; .i 文件 读取c源程序，对其中的伪指令（以# 开头的指令）和特殊符号进行处理 伪指令主要包括以下四个方面： 1) 宏定义指令，如# define Name TokenString，# undef等。 对于前一个伪指令，预编译所要做的是将程序中的所有Name用TokenString替换，但作为字符串常量的 Name则不被替换。对于后者，则将取消对某个宏的定义，使以后该串的出现不再被替换。 2) 条件编译指令，如# ifdef，# ifndef，# else，# elif，# endif等。 这些伪指令的引入使得程序员可以通过定义不同的宏来决定编译程序对哪些代码进行处理。预编译程序将根据有关的文件，将那些不必要的代码过滤掉。 3) 头文件包含指令，如# include “FileName” 或者# include &lt; FileName&gt; 等。 在头文件中一般用伪指令# define定义了大量的宏（最常见的是字符常量），同时包含有各种外部符号的声明。 采用头文件的目的主要是为了使某些定义可以供多个不同的C源程序使用。因为在需要用到这些定义的C源程序中，只需加上一条# include语句即可，而不必再在此文件中将这些定义重复一遍。预编译程序将把头文件中的定义统统都加入到它所产生的输出文件中，以供编译程序对之进行处理。 包含到c源程序中的头文件可以是系统提供的，这些头文件一般被放在/ usr/ include目录下。在程序中# include它们要使用尖括号（&lt; &gt;）。另外开发人员也可以定义自己的头文件，这些文件一般与c源程序放在同一目录下，此时在# include中要用双引号（””）。 4) 特殊符号，预编译程序可以识别一些特殊的符号。 例如在源程序中出现的LINE标识将被解释为当前行号（十进制数），FILE则被解释为当前被编译的C源程序的名称。预编译程序对于在源程序中出现的这些串将用合适的值进行替换。 （5）预处理模块 预处理工作由#pragma命令完成，#Pragma命令将设定编译器的状态或者是指示编译器完成一些特定的动作。 #pragma指令对每个编译器给出了一个方法,在保持与C和C++语言完全兼容的情况下,给出主机或操作系统专有的特征。 预编译程序所完成的基本上是对源程序的“替代”工作。经过此种替代，生成一个没有宏定义、没有条件编译指令、没有特殊符号的输出文件。这个文件的含义同没有经过预处理的源文件是相同的，但内容有所不同。下一步，此输出文件将作为编译程序的输入而被翻译成为机器指令。 1gcc -E test.c -o test.i //.i 文件 编译-Compiling // -&gt; .s 文件 经过预编译得到的输出文件中，只有常量；如数字、字符串、变量的定义，以及C语言的关键字，如main, if , else , for , while , { , } , + , - , * , \\ 等等。 编译程序所要作得工作就是通过词法分析和语法分析，在确认所有的指令都符合语法规则之后，将其翻译成等价的中间代码表示或汇编代码。 优化处理是编译系统中一项比较艰深的技术。它涉及到的问题不仅同编译技术本身有关，而且同机器的硬件环境也有很大的关系。优化一部分是对中间代码的优化。这种优化不依赖于具体的计算机。另一种优化则主要针对目标代码的生成而进行的。 对于前一种优化，主要的工作是删除公共表达式、循环优化（代码外提、强度削弱、变换循环控制条件、已知量的合并等）、复写传播，以及无用赋值的删除，等等。 后一种类型的优化同机器的硬件结构密切相关，最主要的是考虑是如何充分利用机器的各个硬件寄存器存放有关变量的值，以减少对于内存的访问次数。另外，如何根据机器硬件执行指令的特点（如流水线、RISC、CISC、VLIW等）而对指令进行一些调整使目标代码比较短，执行的效率比较高，也是一个重要的研究课题。 经过优化得到的汇编代码必须经过汇编程序的汇编转换成相应的机器指令，方可能被机器执行。 1gcc -S test.i -o test.s //.s文件 汇编-Assembling // -&gt; .o文件 汇编过程实际上指把汇编语言代码翻译成目标机器指令的过程。对于被翻译系统处理的每一个C语言源程序，都将最终经过这一处理而得到相应的目标文件。目标文件中所存放的也就是与源程序等效的目标的机器语言代码。 目标文件由段组成。通常一个目标文件中至少有两个段： 1) 代码段：该段中所包含的主要是程序的指令。该段一般是可读和可执行的，但一般却不可写。 2) 数据段：主要存放程序中要用到的各种全局变量或静态的数据。一般数据段都是可读，可写，可执行的。 UNIX环境下主要有三种类型的目标文件： 1) 可重定位文件 其中包含有适合于其它目标文件链接来创建一个可执行的或者共享的目标文件的代码和数据。 2) 共享的目标文件 这种文件存放了适合于在两种上下文里链接的代码和数据。 第一种是链接程序可把它与其它可重定位文件及共享的目标文件一起处理来创建另一个目标文件； 第二种是动态链接程序将它与另一个可执行文件及其它的共享目标文件结合到一起，创建一个进程映象。 3) 可执行文件 它包含了一个可以被操作系统创建一个进程来执行之的文件。 汇编程序生成的实际上是第一种类型的目标文件。对于后两种还需要其他的一些处理方能得到，这个就是链接程序的工作了。 1gcc -c test.s -o test.o 链接-Linking // -&gt; bin文件 由汇编程序生成的目标文件并不能立即就被执行，其中可能还有许多没有解决的问题。 例如，某个源文件中的函数可能引用了另一个源文件中定义的某个符号（如变量或者函数调用等）；在程序中可能调用了某个库文件中的函数，等等。所有的这些问题，都需要经链接程序的处理方能得以解决。 链接程序的主要工作就是将有关的目标文件彼此相连接，也即将在一个文件中引用的符号同该符号在另外一个文件中的定义连接起来，使得所有的这些目标文件成为一个能够被操作系统装入执行的统一整体。 根据开发人员指定的同库函数的链接方式的不同，链接处理可分为两种： 1) 静态链接 在这种链接方式下，函数的代码将从其所在的静态链接库中被拷贝到最终的可执行程序中。这样该程序在被执行时这些代码将被装入到该进程的虚拟地址空间中。静态链接库实际上是一个目标文件的集合，其中的每个文件含有库中的一个或者一组相关函数的代码。 2) 动态链接 在此种方式下，函数的代码被放到称作是动态链接库或共享对象的某个目标文件中。链接程序此时所作的只是在最终的可执行程序中记录下共享对象的名字以及其它少量的登记信息。在此可执行文件被执行时，动态链接库的全部内容将被映射到运行时相应进程的虚地址空间。动态链接程序将根据可执行程序中记录的信息找到相应的函数代码。 对于可执行文件中的函数调用，可分别采用动态链接或静态链接的方法。使用动态链接能够使最终的可执行文件比较短小，并且当共享对象被多个进程使用时能节约一些内存，因为在内存中只需要保存一份此共享对象的代码。但并不是使用动态链接就一定比使用静态链接要优越。在某些情况下动态链接可能带来一些性能上损害。 1gcc test.o -o test 编译参数1）-E参数 -E 选项指示编译器仅对输入文件进行预处理。当这个选项被使用时, 预处理器的输出被送到标准输出而不是储存在文件里. 2）-S参数 -S 编译选项告诉 GCC 在为 C 代码产生了汇编语言文件后停止编译。 GCC 产生的汇编语言文件的缺省扩展名是 .s 。 3）-c参数 -c 选项告诉 GCC 仅把源代码编译为目标代码。缺省时 GCC 建立的目标代码文件有一个 .o 的扩展名。 4）-o参数 -o 编译选项来为将产生的可执行文件用指定的文件名。 5）-O参数 -O 选项告诉 GCC 对源代码进行基本优化。这些优化在大多数情况下都会使程序执行的更快。 -O2 选项告诉 GCC 产生尽可能小和尽可能快的代码。 如-O2，-O3，-On（n 常为0–3）； -O 主要进行跳转和延迟退栈两种优化； -O0 表示不做优化 -O1 为默认优化 -O2 除了完成-O1的优化之外，还进行一些额外的调整工作，如指令调整等。 -O3 则包括循环展开和其他一些与处理特性相关的优化工作。 选项将使编译的速度比使用 -O 时慢， 但通常产生的代码执行速度会更快。 6）调试选项-g和-pg GCC 支持数种调试和剖析选项，常用到的是 -g 和 -pg 。 -g 选项告诉 GCC 产生能被 GNU 调试器使用的调试信息以便调试你的程序。GCC 提供了一个很多其他 C 编译器里没有的特性, 在 GCC 里你能使-g 和 -O(产生优化代码)联用。 -pg 选项告诉 GCC 在编译好的程序里加入额外的代码。运行程序时, 产生 gprof 用的剖析信息以显示你的程序的耗时情况。 7） -l参数和-L参数 -l参数就是用来指定程序要链接的库，-l参数紧接着就是库名， 8） -include和-I参数 -include用来包含头文件，但一般情况下包含头文件都在源码里用＃include xxxxxx实现，-include参数很少用。-I参数是用来指定头文件目录，/usr/include目录一般是不用指定的，gcc知道去那里找，但 是如果头文件不在/usr/icnclude里我们就要用-I参数指定了，比如头文件放在/myinclude目录里，那编译命令行就要加上-I/myinclude 参数了，如果不加你会得到一个”xxxx.h: No such file or directory”的错误。-I参数可以用相对路径，比如头文件在当前 目录，可以用-I.来指定。上面我们提到的–cflags参数就是用来生成-I参数的。 9）-Wall、-w 和 -v参数 几个相关的环境变 PKG_CONFIG_PATH：用来指定pkg-config用到的pc文件的路径，默认是/usr/lib/pkgconfig，pc文件是文本文件，扩展名是.pc，里面定义开发包的安装路径，Libs参数和Cflags参数等等 CC：用来指定c编译器。 CXX：用来指定cxx编译器。 LIBS：跟上面的–libs作用差不多。 CFLAGS:跟上面的–cflags作用差不多。 CC，CXX，LIBS，CFLAGS手动编译时一般用不上，在做configure时有时用到，一般情况下不用管。 环境变量设定方法：export ENV_NAME=xxxxxxxxxxxxxxxxx G++ GDB调试前言: 在编译时需要添加编译参数: -g 进入GDB 1gdb [exe] 查看源码 1(gdb)l 设置断点 1break 6 #第6行打断点 查看断点处情况 1info b 启动程序进行调试 1run 显示变量值 1print var 设置变量值 1set var=&quot;&quot; 观察变量 1watch var 单步运行 12next(进入调用的函数内部)step(不进入调用的函数内部) 程序继续运行 1continue 退出GDB 1quit 调试core文件 用gdb查看core文件 1gdb ./test core 用gdb实时观察某进程crash信息 1gdb -p PID MakeFile的使用-&gt; makefile语法","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"GCC","slug":"GCC","permalink":"https://lives.xtcgch.ink/tags/GCC/"},{"name":"G++","slug":"G","permalink":"https://lives.xtcgch.ink/tags/G/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"架构之RPC篇","slug":"架构之RPC篇-20201202","date":"2020-12-02T03:57:10.000Z","updated":"2021-10-10T15:59:04.435Z","comments":true,"path":"2020/12/02/架构之RPC篇/","link":"","permalink":"https://lives.xtcgch.ink/2020/12/02/架构之RPC篇/","excerpt":"摘要：记录常用的RPC框架原理。","text":"摘要：记录常用的RPC框架原理。 脑图 前言RPC 框架的目标就是让远程服务调用更加简单、透明 RPC 框架负责屏蔽底层的传输方式（TCP 或者 UDP）、序列化方式（XML/Json/ 二进制）和通信细节。 服务调用者可以像调用本地接口一样调用远程的服务提供者，而不需要关心底层通信细节和调用过程 常见RPC框架业界主流的 RPC 框架整体上分为三类： 支持多语言的 RPC 框架，比较成熟的有 Google 的 gRPC、Apache（Facebook）的 Thrift； 只支持特定语言的 RPC 框架，例如新浪微博的 Motan； 支持服务治理等服务化特性的分布式服务框架，其底层内核仍然是 RPC 框架, 例如阿里的 Dubbo gRPC 在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。 与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。 在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。 gRPC 特点 语言中立，支持多种语言 基于 IDL ( 接口定义语言（Interface Define Language）)文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub； 通信协议基于标准的 HTTP/2 设计，支持·双向流、消息头压缩、单 TCP 的多路复用、服务端推送等特性，这些特性使得 gRPC 在移动端设备上更加省电和节省网络流量 序列化支持 PB（Protocol Buffer）和 JSON，PB 是一种语言无关的高性能序列化框架，基于 HTTP/2 + PB, 保障了 RPC 调用的高性能 gRPC 原则 服务而非对象、消息而非引用 促进微服务的系统间粗粒度消息交互设计理念，同时避免分布式对象的陷阱和分布式计算的谬误。 普遍并且简单 该基础框架应该在任何流行的开发平台上适用，并且易于被个人在自己的平台上构建。它在CPU和内存有限的设备上也应该切实可行。 免费并且开源 所有人可免费使用基本特性。以友好的许可协议开源方式发布所有交付件。 互通性 该数据传输协议(Wire Protocol)必须遵循普通互联网基础框架。 通用并且高性能 该框架应该适用于绝大多数用例场景，相比针对特定用例的框架，该框架只会牺牲一点性能。 分层的 该框架的关键是必须能够独立演进。对数据传输格式(Wire Format)的修改不应该影响应用层。 负载无关的 不同的服务需要使用不同的消息类型和编码，例如protocol buffers、JSON、XML和Thrift，协议上和实现上必须满足这样的诉求。类似地，对负载压缩的诉求也因应用场景和负载类型不同而不同，协议上应该支持可插拔的压缩机制。 流 存储系统依赖于流和流控来传递大数据集。像语音转文本或股票代码等其它服务，依靠流表达时间相关的消息序列。 阻塞式和非阻塞式 支持异步和同步处理在客户端和服务端间交互的消息序列。这是在某些平台上缩放和处理流的关键。 取消和超时 有的操作可能会用时很长，客户端运行正常时，可以通过取消操作让服务端回收资源。当任务因果链被追踪时，取消可以级联。客户端可能会被告知调用超时，此时服务就可以根据客户端的需求来调整自己的行为。 Lameducking 服务端必须支持优雅关闭，优雅关闭时拒绝新请求，但继续处理正在运行中的请求。 流控 在客户端和服务端之间，计算能力和网络容量往往是不平衡的。流控可以更好的缓冲管理，以及保护系统免受来自异常活跃对端的拒绝服务(DOS)攻击。 可插拔的 数据传输协议(Wire Protocol)只是功能完备API基础框架的一部分。大型分布式系统需要安全、健康检查、负载均衡和故障恢复、监控、跟踪、日志等。实现上应该提供扩展点，以允许插入这些特性和默认实现。 API扩展 可能的话，在服务间协作的扩展应该最好使用接口扩展，而不是协议扩展。这种类型的扩展可以包括健康检查、服务内省、负载监测和负载均衡分配。 元数据交换 常见的横切关注点，如认证或跟踪，依赖数据交换，但这不是服务公共接口中的一部分。部署依赖于他们将这些特性以不同速度演进到服务暴露的个别API的能力。 标准化状态码 客户端通常以有限的方式响应API调用返回的错误。应该限制状态代码名字空间，使得这些错误处理决定更清晰。如果需要更丰富的特定域的状态，可以使用元数据交换机制来提供。 gRPC 使用","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://lives.xtcgch.ink/tags/RPC/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"开源之protobuf","slug":"开源之protobuf-20201201","date":"2020-12-01T13:08:24.000Z","updated":"2021-10-10T14:48:44.946Z","comments":true,"path":"2020/12/01/开源之protobuf/","link":"","permalink":"https://lives.xtcgch.ink/2020/12/01/开源之protobuf/","excerpt":"摘要：记录protobuf的使用知识。","text":"摘要：记录protobuf的使用知识。 脑图 前言 protobuf安装 protobuf2 protobuf3变化 字段前取消了required和optional两个关键字，目前可用的只有repeated关键字 不可以现设置默认值了 string默认为空串 枚举默认为第一个枚举定义的第一个值。并且必须是0 bytes默认为空bytes bool默认为false 数字类型默认为0 类型对应表 .proto Type C++ Type 描述 double double float float int32 int32 int64 int64 uint32 uint32 uint64 uint64 sint32 int32 可变长度 sint64 int64 可变长度 fixed32 uint32 固定4字节 fixed64 uint64 固定8字节 sfixed32 int32 固定4字节 sfixed64 int64 固定8字节 bool bool string string bytes string 代码编译1protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR path/to/file.proto 解释： proto_path：当proto文件中使用import时指定的导入文件的位置 cpp_out：c++版本的protocol的输出目录 path/to/file.proto：要编译的proto文件 语法 头部 12// 指定使用proto3，如果不指定的话，编译器会使用proto2去编译syntax = &quot;proto3&quot;; //[proto2|proto3] 标准类型定义 1234567message SearchRequests &#123; // 定义SearchRequests的成员变量，需要指定：变量类型、变量名、变量Tag string query = 1; int32 page_number = 2; bool has_key = 3; float money = 4;&#125; message 嵌套 12345678message SearchResponse &#123; message Result &#123; string url = 1; string title = 2; repeated string snippets = 3; &#125; repeated Result results = 1;&#125; 或123456789message Result &#123; string url = 1; string title = 2; repeated string snippets = 3;&#125;message SearchResponse &#123; repeated Result results = 1;&#125; 枚举 123456789101112131415message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3; enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; &#125; Corpus corpus = 4;&#125; 或12345678910111213141516enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6;&#125; message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3; Corpus corpus = 4;&#125; 引用其他 proto 文件 在情景1中， my.proto 不能使用 second.proto 中定义的内容 在情景2中， my.proto 可以使用 second.proto 中定义的内容 情景1和情景2中，my.proto 都可以使用 first.proto 情景1和情景2中，first.proto 都可以使用 second.proto demo: 1234567891011// my.protoimport &quot;first.proto&quot;;FirstProtocol fr = 1;SecondProtocol sp = 2; //情景1:ok 情景2:not okMyProtocol mp = 3;message MyProtocol &#123; string sex = 1; int32 age = 2;&#125; 1234567891011// first.proto//import &quot;second.proto&quot;;import public &quot;second.proto&quot;;FirstProtocol fr = 1;SecondProtocol sp = 2; //情景1:ok 情景2:okmessage FirstProtocol &#123; string idcard = 1; int32 age = 2;&#125; 12345// second.protomessage SecondProtocol &#123; string idcard = 1; int32 age = 2;&#125; proto常用关键字 Any any表示未定义变量类型，由上层决定。 demo:12345import &quot;google/protobuf/any.proto&quot;;message ErrorStatus &#123; string message = 1; repeated google.protobuf.Any details = 2;&#125; Oneof Oneof 类似union demo:12345678message LoginReply &#123; oneof test_oneof &#123; string name = 3; string age = 4; &#125; required string status = 1; required string token = 2;&#125; Mapsmap&lt;key_type, value_type&gt; map_field = N; key_type:必须是string或者int value_type：任意类型 注意： Map 类型不能使 repeated Map 是无序的 以文本格式展示时，Map 以 key 来排序 如果有相同的键会导致解析失败 demo:12// 举例：map&lt;string, Project&gt; projects = 3; Packages 类似于C++的class，主要作用是提供一个作用域。 12package foo.bar;message Open &#123; ... &#125; 123456message Foo &#123; ... // 带上包名 foo.bar.Open open = 1; ...&#125;","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"PROTOBUF","slug":"PROTOBUF","permalink":"https://lives.xtcgch.ink/tags/PROTOBUF/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"编程语言之C++版本变化汇总","slug":"编程语言之C++版本变化汇总-20201130","date":"2020-11-30T08:47:05.000Z","updated":"2021-10-10T15:47:29.582Z","comments":true,"path":"2020/11/30/编程语言之C++版本变化汇总/","link":"","permalink":"https://lives.xtcgch.ink/2020/11/30/编程语言之C++版本变化汇总/","excerpt":"摘要：记录C++各版本之间的演变。","text":"摘要：记录C++各版本之间的演变。 前言 如何定义新增特性和改进特性？ 如果一个特性改变了我们对代码和软件开发的看法，那么我认为它就是一个主要的特性。 C++和G++版本的对应关系C++17： gcc7完全支持，gcc6和gcc5部分支持，gcc6支持度当然比gcc5高，gcc4及以下版本不支持。C++14: gcc5就可以完全支持，gcc4部分支持，gcc3及以下版本不支持。C++11： gcc4.8.1及以上可以完全支持。gcc4.3部分支持，gcc4.3以下版本不支持。 C98 C03 C11关键点 修改 智能指针 新增 lambda 具体介绍 智能指针 weak_ptr 删除了weak_ptr弱指针 shared_ptr 新增了shared_ptr共享指针 lambda表达式 C14 C17 C20关键点 修改 概念：对范式编程中接口的精确规范，旨在提升范式编程的易行性与灵活性 模块：将代码编译速度大为提高（比如说快 5 倍以上） 并发编程 新增 范围 概念与约束 指定初始化 计时 并行算法 具体介绍 每年编程语言排名和趋势 截至2020年09月 排名： 趋势：","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"markdown语法","slug":"markdown语法-20190112","date":"2020-11-30T05:54:45.000Z","updated":"2021-11-01T03:21:22.558Z","comments":true,"path":"2020/11/30/markdown语法/","link":"","permalink":"https://lives.xtcgch.ink/2020/11/30/markdown语法/","excerpt":"摘要：记录下常用的markdown语法。","text":"摘要：记录下常用的markdown语法。 大纲（TOC）说明：使用[toc/TOC]来根据各级标题来生成文本大纲视图。 备注：很多markdown工具对toc支持不友好。github的博客会自动生成文本大纲。 标题在想要设置为标题的文字前面加#来表示 一个#是一级标题，二个#是二级标题，尽量控制在四级标题以内。 注意：在#之后统一使用空格隔开，如# 一级标题 字体（1）加粗 说明：要加粗的文字左右分别用2个 * 号包起来 示例：加粗 用法：**加粗** （2）斜体 说明：要倾斜的文字左右分别用1个 * 号包起来 示例：斜体 用法：*斜体* （3）斜体加粗 说明：要倾斜和加粗的文字左右分别用3个 * 号包起来 示例：斜体加粗 用法：***斜体加粗*** （4）删除线 说明：要加删除线的文字左右分别用2个 ~ 号包起来 示例：删除线 用法：~~删除线~~ 引用（1）单层引用 在引用的文字前加&gt;即可。如： 这是单层引用部分 （2）嵌套引用 使用多个连起来的&gt;，&gt;的个数表示嵌套的层数，如： 第一层引用 第二层引用 第三层引用 分割线使用三个或以上的-（英文中的减号）或 * 号，推荐使用3个-。 图片 语法：![图片alt](图片地址 &quot;图片title&quot;) 示例： 说明： 图片alt：为图片显示失败时的提示信息 图片地址：绝对url或相对url。其中github的博客中，默认从markdown文件对应的文件夹中寻找，因此，一般把图片放入markdown文件夹中后，使用图片名称.格式或./图片名称.格式。推荐使用前者。支持中文。 图片title：鼠标悬停在图片上时的提示语。可有可无 超链接说明：[超链接名](超链接地址 &quot;超链接title&quot;) 解释： 超链接名：可点击进行跳转的文字 超链接地址：为要跳转的url 超链接title：为鼠标悬停在超链接名上空时的提示语 示例：我的博客 用法：[我的博客](https://unistd68.yancoder.com &quot;小小学渣&quot;) 小技巧：可以使用超链接来访问pdf，markdown文件等，前提是有访问这些文件的权限。（github支持）。如果需要新标签页打开，则需要配合ctrl键使用。 无序列表说明：用 - + * 任何一种都可以，和后面的文字之间有一个空格，推荐使用- 示例： 列表1 用法：- 列表1 有序列表说明：数字加点”.”。 备注： 有序列表在列表数量比较大的时候，方便增加或删除列表后的自动排序。因为1,2,3的顺序其实只是表明该行是有序列表。 点号”.”后面有留一个空格。 示例： 列表一 列表二 列表三 用法：1231. 列表一3. 列表二2. 列表三 列表嵌套说明：有序列表和无序列表之间、无序列表之间、有序列表之间的嵌套用法是一样的，只需要在上一级和下一级之间敲三个空格。 示例： （1）demo1：无序列表嵌套有序列表 无序列表一 有序列表一 有序列表二 无序列表二 （2）demo2：有序列表嵌套无序列表 有序列表一 无序列表一 无序列表二 有序列表二 （3）demo3：无序列表嵌套无序列表 无序列表一 无序列表二级标题一 无序列表二级标题二 无序列表二 （4）demo4：有序列表嵌套有序列表 有序列表一 有序列表二级标题一 有序列表二级标题二 有序列表二级标题二 用法：略 表格markdown支持html标签和原生方式 说明： 1234567891011表头|表头|表头---|:--:|--:内容|内容|内容内容|内容|内容第二行分割表头和内容。- 有一个就行，为了对齐，多加了几个文字默认居左-两边加：表示文字居中-右边加：表示文字居右注：原生的语法两边都要用 | 包起来。此处省略 示例： 姓名 技能 排行 刘备 哭 大哥 关羽 打 二哥 张飞 骂 三弟 用法：12345姓名|技能|排行--|:--:|--:刘备|哭|大哥关羽|打|二哥张飞|骂|三弟 流程图说明：github不支持markdown画流程图。 示例：略 用法：略 字体、字号、颜色设置说明：要使用css语法进行设置。 字体：微软雅黑、黑体、宋体 字号：1-10。 颜色：#FF0000（红），推荐使用十六进制颜色值 示例：(有空再把常用的设置都补充完全) 微软雅黑字体黑体3号字4号字红色绿色蓝色 用法：1234567&lt;font face=&quot;微软雅黑&quot; &gt;微软雅黑字体&lt;/font&gt;&lt;font face=&quot;黑体&quot; &gt;黑体&lt;/font&gt;&lt;font size=3 &gt;3号字&lt;/font&gt;&lt;font size=4 &gt;4号字&lt;/font&gt;&lt;font color=#FF0000 &gt;红色&lt;/font&gt;&lt;font color=#008000 &gt;绿色&lt;/font&gt;&lt;font color=#0000FF &gt;蓝色&lt;/font&gt; 背景色设置说明：用到html和css语法。 注意：设置背景色一般要借助table，进行区域染色。 示例： 背景色是 1 orange 背景色2 BlueViolet （1）黑-&gt;灰-&gt;白 #000000#1F1F1F#3B3B3B#575757#7F7F7F#C5C1AA#C7C7C7 （2）蓝 #0000FF#000080#008B8B#00FFFF （3）红-&gt;棕 #EE0000#EE2C2C#DC143C#CD2626#8B0000#B22222 （4）绿 #00FF00#006400#228B22#32CD32#43CD80 （5）黄-&gt;橙 #EEEE00#EE7600#CD6600#FFFF00#EEE685 （6）青-紫 #4B0082#7D26CD#8A2BE2#8968CD#8DEEEE 用法：12&lt;table&gt;&lt;tr&gt;&lt;td bgcolor=orange&gt; 背景色是 1 orange&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;table&gt;&lt;tr&gt;&lt;td bgcolor=BlueViolet &gt; 背景色2 BlueViolet &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 数学公式备注：github不支持数学公式 第一个公式： $\\sum_{i=0}^N\\int_{a}^{b}g(t,i)\\text{d}t$ 第二个公式： $$\\sum_{i=0}N\\int_{a}{b}g(t,i)\\text{d}t$$ 换行如果另起一行，只需在当前行结尾加 2 个空格 如果是要起一个新段落，只需要空出一行即可。 复选框在无序列表符号后面加上[]或者[x]代表选中或者未选中情况 12- [x] Markdown - [ ] JavaScript 或者 12+ [x] Markdown + [ ] JavaScript 或者 12* [x] Markdown * [ ] JavaScript 效果： Markdown JavaScript","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"MARKDOWN","slug":"MARKDOWN","permalink":"https://lives.xtcgch.ink/tags/MARKDOWN/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"Linux结构思维导图","slug":"linux结构思维导图-20201130","date":"2020-11-30T00:22:12.000Z","updated":"2021-10-02T13:33:14.470Z","comments":true,"path":"2020/11/30/Linux结构思维导图/","link":"","permalink":"https://lives.xtcgch.ink/2020/11/30/Linux结构思维导图/","excerpt":"摘要：这是linux知识结构的大纲收录。","text":"摘要：这是linux知识结构的大纲收录。 其他模板的标题 知识理解 文件目录管理 目录系统 文件系统 根目录 /bin /boot /dev /etc /home /media /opt /proc /root /sbin /srv /sys /tmp /usr /var 文件查找命令 文件内容查看 设备管理 系统管理 用户和组管理 进程和作业管理 网络管理 编程 SHELL 管理 文档编辑器","categories":[{"name":"知识导图","slug":"知识导图","permalink":"https://lives.xtcgch.ink/categories/知识导图/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"}],"keywords":[{"name":"知识导图","slug":"知识导图","permalink":"https://lives.xtcgch.ink/categories/知识导图/"}]},{"title":"【原理】 IPC之管道通信","slug":"IPC之管道通信-20181122","date":"2020-11-23T08:00:00.000Z","updated":"2021-10-10T08:20:40.553Z","comments":true,"path":"2020/11/23/IPC之管道通信/","link":"","permalink":"https://lives.xtcgch.ink/2020/11/23/IPC之管道通信/","excerpt":"摘要：管道通信是进程间通信的一种方式。学习管道通信对于linux下C++多进程编程有很大的帮助。","text":"摘要：管道通信是进程间通信的一种方式。学习管道通信对于linux下C++多进程编程有很大的帮助。 管道的介绍管道其实是内核内存中维护的一个缓冲器 匿名管道（PIPE）A.管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道 B.只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程); C.单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。 D.数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。 命名管道（FIFO）FIFO不同于无名管道之处在于它提供了一个路径名与之关联，以FIFO的文件形式存在于文件系统中。 这样，即使与FIFO的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过FIFO相互通信。 因此，通过FIFO不相关的进程也能交换数据。 值的注意的是，FIFO严格遵循先进先出(first in first out),对管道及FIFO的读总是从开始处返回数据，对它们的写则把数据添加到末尾。 它们不支持诸如lseek()等文件定位操作。 注意：有名管道的名字存在于文件系统中，内容存放在内存中。 管道的使用匿名管道 函数 int pipe（int filedis[2]） 命名管道 函数 int mkfifo(const char *pathname,mode_t mode) 管道使用例子 信号Linux常见信号","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"IPC","slug":"IPC","permalink":"https://lives.xtcgch.ink/tags/IPC/"},{"name":"POSIX","slug":"POSIX","permalink":"https://lives.xtcgch.ink/tags/POSIX/"},{"name":"管道","slug":"管道","permalink":"https://lives.xtcgch.ink/tags/管道/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"网络编程之IO模型","slug":"网络编程之IO模型-20201103","date":"2020-11-22T14:13:36.000Z","updated":"2021-10-10T14:50:09.001Z","comments":true,"path":"2020/11/22/网络编程之IO模型/","link":"","permalink":"https://lives.xtcgch.ink/2020/11/22/网络编程之IO模型/","excerpt":"摘要：记录IO模型的相关知识。","text":"摘要：记录IO模型的相关知识。 脑图 date: 2020-11-03 18:13:36IO模型 阻塞式IO 非阻塞式IO IO复用 select poll epoll 信号驱动式IO SIGIO 异步IO POSIX的aio_系列函数 阻塞式IO 函数：recv()。调用者所在的线程会被recv函数所阻塞，知道recv函数返回结果，而recv函数直到接收到对端发来数据后才会返回。 非阻塞式IO 函数：recvfrom()。recvfrom函数在被调用后,无论是否接收到数据,都会立刻返回,没有接收到数据时返回值：EWOULDBLOCK。 IO复用在调用recv前先调用select或者poll,这2个系统调用都可以在内核准备好数据(网络数据到达内核)时告知用户进程，这个时候再调用recv一定是有数据的。因此这一过程中它是阻塞于select或poll，而没有阻塞于recv。 信号驱动式IO通过调用sigaction注册信号函数，等内核数据准备好的时候系统中断当前程序，执行信号函数(在这里面调用recv) 异步IO调用aio_read，让内核等数据准备好，并且复制到用户进程空间后执行事先指定好的函数。 benchmark 比较IO模型比较同步和异步IO比较 select select的优缺点优点：（1）select的可移植性好，在某些unix下不支持poll.（2）select对超时值提供了很好的精度，精确到微秒，而poll式毫秒。缺点：（1）单个进程可监视的fd数量被限制，默认是1024。（2）需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。（3）对fd进行扫描时是线性扫描，fd剧增后，IO效率降低，每次调用都对fd进行线性扫描遍历，随着fd的增加会造成遍历速度慢的问题。（4）select函数超时参数在返回时也是未定义的，考虑到可移植性，每次超时之后进入下一个select之前都要重新设置超时参数 select函数介绍 int select(int maxfdp,fd_set *readfds,fd_set *writefds,fd_set *errorfds,struct timeval *timeout); 参数介绍 maxfdp : 需要监视的最大文件描述符加1 readfds、writefds、errorfds：分别对应于需要检测的可读文件描述符的集合，可写文件描述符的集 合及异常文件描述符的集合。 timeout：等待时间，这个时间内，需要监视的描述符没有事件发⽣生则函数返回，返回值为0。设为NULL 表示阻塞式等待，一直等到有事件就绪，函数才会返回，0表示非阻塞式等待，没有事件就立即返回，大于0表示等待的时间 返回值 大于0：表示就绪时间的个数 等于0：表示timeout等待时间到了 小于0：表示调用失 demo 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#include&lt;stdio.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;unistd.h&gt;#include&lt;netinet/in.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;sys/time.h&gt;static void Usage(const char* proc)&#123; printf(&quot;%s [local_ip] [local_port]\\n&quot;,proc);&#125;int array[4096];static int start_up(const char* _ip,int _port)&#123; int sock = socket(AF_INET,SOCK_STREAM,0); if(sock &lt; 0) &#123; perror(&quot;socket&quot;); exit(1); &#125; struct sockaddr_in local; local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = inet_addr(_ip); if(bind(sock,(struct sockaddr*)&amp;local,sizeof(local)) &lt; 0) &#123; perror(&quot;bind&quot;); exit(2); &#125; if(listen(sock,10) &lt; 0) &#123; perror(&quot;listen&quot;); exit(3); &#125; return sock;&#125;int main(int argc,char* argv[])&#123; if(argc != 3) &#123; Usage(argv[0]); return -1; &#125; int listensock = start_up(argv[1],atoi(argv[2])); int maxfd = 0; fd_set rfds; fd_set wfds; array[0] = listensock; int i = 1; int array_size = sizeof(array)/sizeof(array[0]); for(; i &lt; array_size;i++) &#123; array[i] = -1; &#125; while(1) &#123; FD_ZERO(&amp;rfds); FD_ZERO(&amp;wfds); for(i = 0;i &lt; array_size;++i) &#123; if(array[i] &gt; 0) &#123; FD_SET(array[i],&amp;rfds); FD_SET(array[i],&amp;wfds); if(array[i] &gt; maxfd) &#123; maxfd = array[i]; &#125; &#125; &#125; switch(select(maxfd + 1,&amp;rfds,&amp;wfds,NULL,NULL)) &#123; case 0: &#123; printf(&quot;timeout\\n&quot;); break; &#125; case -1: &#123; perror(&quot;select&quot;); break; &#125; default: &#123; int j = 0; for(; j &lt; array_size; ++j) &#123; if(j == 0 &amp;&amp; FD_ISSET(array[j],&amp;rfds)) &#123; //listensock happened read events struct sockaddr_in client; socklen_t len = sizeof(client); int new_sock = accept(listensock,(struct sockaddr*)&amp;client,&amp;len); if(new_sock &lt; 0)//accept failed &#123; perror(&quot;accept&quot;); continue; &#125; else//accept success &#123; printf(&quot;get a new client%s\\n&quot;,inet_ntoa(client.sin_addr)); fflush(stdout); int k = 1; for(; k &lt; array_size;++k) &#123; if(array[k] &lt; 0) &#123; array[k] = new_sock; if(new_sock &gt; maxfd) maxfd = new_sock; break; &#125; &#125; if(k == array_size) &#123; close(new_sock); &#125; &#125; &#125;//j == 0 else if(j != 0 &amp;&amp; FD_ISSET(array[j], &amp;rfds)) &#123; //new_sock happend read events char buf[1024]; ssize_t s = read(array[j],buf,sizeof(buf) - 1); if(s &gt; 0)//read success &#123; buf[s] = 0; printf(&quot;clientsay#%s\\n&quot;,buf); if(FD_ISSET(array[j],&amp;wfds)) &#123; const char *msg = &quot;HTTP/1.0 200 OK &lt;\\r\\n\\r\\n&lt;html&gt;&lt;h1&gt;yingying beautiful&lt;/h1&gt;&lt;/html&gt;\\r\\n&quot;; write(array[j],msg,strlen(msg)); &#125; &#125; else if(0 == s) &#123; printf(&quot;client quit!\\n&quot;); close(array[j]); array[j] = -1; &#125; else &#123; perror(&quot;read&quot;); close(array[j]); array[j] = -1; &#125; &#125;//else j != 0 &#125; break; &#125; &#125; &#125; return 0;&#125; poll poll函数的优缺点优点：（1）不要求计算最大文件描述符+1的大小。（2）应付大数量的文件描述符时比select要快。（3）没有最大连接数的限制是基于链表存储的。缺点：（1）大量的fd数组被整体复制于内核态和用户态之间，而不管这样的复制是不是有意义。（2）同select相同的是调用结束后需要轮询来获取就绪描述符 poll函数介绍 int poll ( struct pollfd * fds, unsigned int nfds, int timeout); 参数介绍 fds : 对应上述介绍的结构体指针 nfds : 标记数组中结构体元素的总个数。 timeout : 超时时间 ，等于0表示非阻塞式等待，小于0表示阻塞式等待，大于0表示等待的时间。 返回值： 成功时返回fds数组中事件就绪的文件描述符的个数 0：表示超时时间到了。 -1：表示调用失败，对应的错误码会被设置。 demo： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#include&lt;stdio.h&gt;#include &lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;netinet/in.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;poll.h&gt;static void usage(const char *proc)&#123; printf(&quot;%s [local_ip] [local_port]\\n&quot;,proc);&#125;int start_up(const char*_ip,int _port)&#123; int sock = socket(AF_INET,SOCK_STREAM,0); if(sock &lt; 0) &#123; perror(&quot;socket&quot;); return 2; &#125; int opt = 1; setsockopt(sock,SOL_SOCKET,SO_REUSEADDR,&amp;opt,sizeof(opt)); struct sockaddr_in local; local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = inet_addr(_ip); if(bind(sock,(struct sockaddr*)&amp;local,sizeof(local)) &lt; 0) &#123; perror(&quot;bind&quot;); return 3; &#125; if(listen(sock,10) &lt; 0) &#123; perror(&quot;listen&quot;); return 4; &#125; return sock;&#125;int main(int argc, char*argv[])&#123; if(argc != 3) &#123; usage(argv[0]); return 1; &#125; int sock = start_up(argv[1],atoi(argv[2])); struct pollfd peerfd[1024]; peerfd[0].fd = sock; peerfd[0].events = POLLIN; int nfds = 1; int ret; int maxsize = sizeof(peerfd)/sizeof(peerfd[0]); int i = 1; int timeout = -1; for(; i &lt; maxsize; ++i) &#123; peerfd[i].fd = -1; &#125; while(1) &#123; switch(ret = poll(peerfd,nfds,timeout)) &#123; case 0: printf(&quot;timeout...\\n&quot;); break; case -1: perror(&quot;poll&quot;); break; default: &#123; if(peerfd[0].revents &amp; POLLIN) &#123; struct sockaddr_in client; socklen_t len = sizeof(client); int new_sock = accept(sock,\\ (struct sockaddr*)&amp;client,&amp;len); printf(&quot;accept finish %d\\n&quot;,new_sock); if(new_sock &lt; 0) &#123; perror(&quot;accept&quot;); continue; &#125; printf(&quot;get a new client\\n&quot;); int j = 1; for(; j &lt; maxsize; ++j) &#123; if(peerfd[j].fd &lt; 0) &#123; peerfd[j].fd = new_sock; break; &#125; &#125; if(j == maxsize) &#123; printf(&quot;to many clients...\\n&quot;); close(new_sock); &#125; peerfd[j].events = POLLIN; if(j + 1 &gt; nfds) nfds = j + 1; &#125; for(i = 1;i &lt; nfds;++i) &#123; if(peerfd[i].revents &amp; POLLIN) &#123; printf(&quot;read ready\\n&quot;); char buf[1024]; ssize_t s = read(peerfd[i].fd,buf, \\ sizeof(buf) - 1); if(s &gt; 0) &#123; buf[s] = 0; printf(&quot;client say#%s&quot;,buf); fflush(stdout); peerfd[i].events = POLLOUT; &#125; else if(s &lt;= 0) &#123; close(peerfd[i].fd); peerfd[i].fd = -1; &#125; else &#123; &#125; &#125;//i != 0 else if(peerfd[i].revents &amp; POLLOUT) &#123; const char *msg = &quot;HTTP/1.0 200 OK \\ &lt;\\r\\n\\r\\n&lt;html&gt;&lt;h1&gt; \\ yingying beautiful \\ &lt;/h1&gt;&lt;/html&gt;\\r\\n&quot;; write(peerfd[i].fd,msg,strlen(msg)); close(peerfd[i].fd); peerfd[i].fd = -1; &#125; else &#123; &#125; &#125;//for &#125;//default break; &#125; &#125; return 0;&#125; epoll epoll函数的优缺点优点：（1）支持一个进程打开大数目的socket描述符(FD)select 最不能忍受的是一个进程所打开的FD是有一定限制的，由FD_SETSIZE设置，默认值是2048。对于那些需要支持的上万连接数目的IM服务器来说显 然太少了。这时候你一是可以选择修改这个宏然后重新编译内核，不过资料也同时指出这样会带来网络效率的下降，二是可以选择多进程的解决方案(传统的 Apache方案)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完 美的方案。不过 epoll则没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。（2）IO效率不随FD数目增加而线性下降传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是”活跃”的， 但是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对”活跃”的socket进行 操作—这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有”活跃”的socket才会主动的去调用 callback函数，其他idle状态socket则不会，在这点上，epoll实现了一个”伪”AIO，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上都是活跃的—比如一个高速LAN环境，epoll并不比select/poll有什么效率，相 反，如果过多使用epoll_ctl,效率相比还有稍微的下降。但是一旦使用idle connections模拟WAN环境,epoll的效率就远在select/poll之上了。（3）使用mmap加速内核与用户空间的消息传递。这点实际上涉及到epoll的具体实现了。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就 很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。而如果你想我一样从2.5内核就关注epoll的话，一定不会忘记手工 mmap这一步的。（4）内核微调这一点其实不算epoll的优点了，而是整个linux平台的优点。也许你可以怀疑linux平台，但是你无法回避linux平台赋予你微调内核的能力。 比如，内核TCP/IP协议栈使用内存池管理sk_buff结构，那么可以在运行时期动态调整这个内存pool(skb_head_pool)的大小 — 通过echo XXXX&gt;/proc/sys/net/core/hot_list_length完成。再比如listen函数的第2个参数(TCP完成3次握手 的数据包队列长度)，也可以根据你平台内存大小动态调整。更甚至在一个数据包面数目巨大但同时每个数据包本身大小却很小的特殊系统上尝试最新的NAPI网 卡驱动架构 epoll函数相关系统调用 int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event ); epfd : epoll的专用描述符。 op : 相关操作，通常用以下宏来表示 event ： 通知内核需要监听的事件 EPOLL_CTL_ADD：注册新的fd到epfd中 EPOLL_CTL_MOD：修改已经注册的fd的监听事件 EPOLL_CTL_DEL：从epfd中删除⼀一个fd fd : 需要监听的事件 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout) demo: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142#include&lt;stdio.h&gt;#include &lt;unistd.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;netinet/in.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;sys/epoll.h&gt;static void usage_info(const char* proc)&#123; printf(&quot;%s [local_ip] [local_port]\\n&quot;,proc);&#125;int start_up(const char*_ip,int _port)&#123; int sock = socket(AF_INET,SOCK_STREAM,0); if(sock &lt; 0) &#123; perror(&quot;socket&quot;); exit(2); &#125; struct sockaddr_in local; local.sin_family = AF_INET; local.sin_port = htons(_port); local.sin_addr.s_addr = inet_addr(_ip); if(bind(sock,(struct sockaddr*)&amp;local,sizeof(local)) &lt; 0) &#123; perror(&quot;bind&quot;); exit(3); &#125; if(listen(sock,10)&lt; 0) &#123; perror(&quot;listen&quot;); exit(4); &#125; return sock;&#125;int main(int argc, char*argv[])&#123; if(argc != 3) &#123; usage_info(argv[0]); return 1; &#125; int sock = start_up(argv[1],atoi(argv[2])); int epollfd = epoll_create(256); if(epollfd &lt; 0) &#123; perror(&quot;epoll_create&quot;); return 5; &#125; struct epoll_event ev; ev.events = EPOLLIN; ev.data.fd = sock; if(epoll_ctl(epollfd,EPOLL_CTL_ADD,sock,&amp;ev) &lt; 0) &#123; perror(&quot;epoll_ctl&quot;); return 6; &#125; int evnums = 0;//epoll_wait return val struct epoll_event evs[64]; int timeout = -1; while(1) &#123; switch(evnums = epoll_wait(epollfd,evs,64,timeout)) &#123; case 0: printf(&quot;timeout...\\n&quot;); break; case -1: perror(&quot;epoll_wait&quot;); break;default: &#123; int i = 0; for(; i &lt; evnums; ++i) &#123; struct sockaddr_in client; socklen_t len = sizeof(client); if(evs[i].data.fd == sock \\ &amp;&amp; evs[i].events &amp; EPOLLIN) &#123; int new_sock = accept(sock, \\ (struct sockaddr*)&amp;client,&amp;len); if(new_sock &lt; 0) &#123; perror(&quot;accept&quot;); continue; &#125;//if accept failed else &#123; printf(&quot;Get a new client[%s]\\n&quot;, \\ inet_ntoa(client.sin_addr)); ev.data.fd = new_sock; ev.events = EPOLLIN; epoll_ctl(epollfd,EPOLL_CTL_ADD,\\ new_sock,&amp;ev); &#125;//accept success &#125;//if fd == sock else if(evs[i].data.fd != sock &amp;&amp; \\ evs[i].events &amp; EPOLLIN) &#123; char buf[1024]; ssize_t s = read(evs[i].data.fd,buf,sizeof(buf) - 1); if(s &gt; 0) &#123; buf[s] = 0; printf(&quot;client say#%s\\n&quot;,buf); ev.data.fd = evs[i].data.fd; ev.events = EPOLLOUT; epoll_ctl(epollfd,EPOLL_CTL_MOD, \\ evs[i].data.fd,&amp;ev); &#125;//s &gt; 0 else &#123; close(evs[i].data.fd); epoll_ctl(epollfd,EPOLL_CTL_DEL, \\ evs[i].data.fd,NULL); &#125; //printf(&quot;get a new message\\n&quot;); &#125;//fd != sock else if(evs[i].data.fd != sock \\ &amp;&amp; evs[i].events &amp; EPOLLOUT) &#123; printf(&quot;one client logout\\n&quot;); const char *msg = &quot;HTTP/1.0 200 OK &lt;\\r\\n\\r\\n&lt;html&gt;&lt;h1&gt;yingying beautiful &lt;/h1&gt;&lt;/html&gt;\\r\\n&quot;; write(evs[i].data.fd,msg,strlen(msg)); close(evs[i].data.fd); epoll_ctl(epollfd,EPOLL_CTL_DEL, \\ evs[i].data.fd,NULL); &#125;//EPOLLOUT else &#123; &#125; &#125;//for &#125;//default break; &#125;//switch &#125;//while return 0;&#125; EPOLL事件有两种模型： Level Triggered (LT) 水平触发.socket接收缓冲区不为空 有数据可读 读事件一直触发.socket发送缓冲区不满 可以继续写入数据 写事件一直触发符合思维习惯，epoll_wait返回的事件就是socket的状态 Edge Triggered (ET) 边沿触发.socket的接收缓冲区状态变化时触发读事件，即空的接收缓冲区刚接收到数据时触发读事件.socket的发送缓冲区状态变化时触发写事件，即满的缓冲区刚空出空间时触发读事件仅在状态变化时触发事件 换种思路理解： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 ET还是LT? LT的处理过程：. accept一个连接，添加到epoll中监听EPOLLIN事件. 当EPOLLIN事件到达时，read fd中的数据并处理. 当需要写出数据时，把数据write到fd中；如果数据较大，无法一次性写出，那么在epoll中监听EPOLLOUT事件. 当EPOLLOUT事件到达时，继续把数据write到fd中；如果数据写出完毕，那么在epoll中关闭EPOLLOUT事件 ET的处理过程：. accept一个一个连接，添加到epoll中监听EPOLLIN|EPOLLOUT事件. 当EPOLLIN事件到达时，read fd中的数据并处理，read需要一直读，直到返回EAGAIN为止. 当需要写出数据时，把数据write到fd中，直到数据全部写完，或者write返回EAGAIN. 当EPOLLOUT事件到达时，继续把数据write到fd中，直到数据全部写完，或者write返回EAGAIN 注意事项： ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 场景应用 总结 参考文章–&gt; 文章1–&gt; 文章1–&gt; 文章1","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"IO","slug":"IO","permalink":"https://lives.xtcgch.ink/tags/IO/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"设计模式","slug":"设计模式-20201122","date":"2020-11-22T03:07:09.000Z","updated":"2020-11-30T03:47:53.654Z","comments":true,"path":"2020/11/22/设计模式/","link":"","permalink":"https://lives.xtcgch.ink/2020/11/22/设计模式/","excerpt":"摘要：本文记录一下常用的设计模式。","text":"摘要：本文记录一下常用的设计模式。 脑图 单例模式工厂模式抽象工厂模式桥接模式组合模式迭代器模式解释器模式观察者模式模板模式工厂模式扩展点一 总结 推荐书籍","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://lives.xtcgch.ink/tags/设计模式/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"求职之综合篇","slug":"求职之综合篇-20200902","date":"2020-09-02T02:03:55.000Z","updated":"2021-11-22T00:38:36.776Z","comments":true,"path":"2020/09/02/求职之综合篇/","link":"","permalink":"https://lives.xtcgch.ink/2020/09/02/求职之综合篇/","excerpt":"摘要：记录一下面试要点。","text":"摘要：记录一下面试要点。 脑图 目录★★★ 一、基础篇 ★★★ 1.基础原理类 1.1 map和set有什么区别，分别又是怎么实现的 1.2 STL中MAP数据存放形式 1.3 epoll原理 1.4 malloc的原理，另外brk系统调用和mmap系统调用的作用分别是什么 1.5 C++的内存管理 1.6 C++的内存泄漏 1.7 什么时候会发生段错误 1.8 什么是memory leak，也就是内存泄漏 1.9 C++11有哪些新特性 1.10 并发(concurrency)和并行(parallelism) 1.11 单核机器上写多线程程序，是否需要考虑加锁 1.12 死锁发生的条件以及如何解决死锁 1.13 操作系统中的结构体对齐，字节对齐 1.14 虚函数的实现的基本原理 [static关键字的作用] [软硬链接] [函数指针] [设计模式] [数据结构] [各种排序算法] [二叉树定理] [互斥锁] [STL] [为什么析构函数要是虚函数] [构造函数可以是虚函数吗] [new和malloc的原理和区别] [手动实现strcpy] [C++对象内存布局] [虚函数多态机制] [线程和进程的区别] [僵尸进程] [重载与多态的区别] [内存管理] [RAII 机制] [Sizeof 考察] [union的内存分配] [进程之间调度] [进程间通信] [线程间通信] 2.计算机网络类 2.1 TCP怎么保证可靠性，并且简述一下TCP建立连接和断开连接的过程 2.2 TCP的模型，状态转移 2.3 操作系统中的中断 2.4 TCP拥塞控制 2.5 阻塞，非阻塞，同步，异步 2.6 ET和LT的区别 [io多路复用] [大小端转换] [IP分片与重组] [网络粘包] 3.数据库类 3.1 数据库事物的一致性 3.2 redis和memcache [数据库索引] [事务] [MySQL两种引擎的区别] [隔离的级别] [回表] [log分类] [覆盖索引] [为什么说B+树比B树更适合数据库索引] 4.linux强相关类 4.1 select，epoll的区别 4.2 Linux虚拟地址空间 4.3 fork和vfork的区别 4.3 虚函数的实现的基本原理 4.4 如何判断一个程序是死锁还是死循环 [gdb调试命令] [gdb step和next的区别] [gdb查看内存] [gdb多线程调试] [gdb查看调用堆栈] [gdb 带参数调试] [gdb list命令] [用户态到内核态的转化原理] [系统调用] [6种微服务RPC框架]★★★ 二、进阶篇 ★★★ [git你使用的是哪种工作流？git有哪些协作流了解过吗？] [大数据处理了解过吗？一致性哈希解决什么问题的？] [存储引擎了解过吗？不是MySQL，大数据这块的存储引擎？] [说说对zookeeper的了解] [Zookeeper的选主机制] [优雅关闭服务和进程] ★★★ 一、基础篇 ★★★1.基础原理类1.1 map和set有什么区别，分别又是怎么实现的 共同点map和set都是C++的关联容器，其底层实现都是红黑树（RB-Tree）。由于 map 和set所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 map 和set的操作行为，都只是转调 RB-tree 的操作行为。 区别 map中的元素是key-value（关键字—值）对：关键字起到索引的作用，值则表示与索引相关联的数据；Set与之相对就是关键字的简单集合，set中每个元素只包含一个关键字。 set的迭代器是const的，不允许修改元素的值；map允许修改value，但不允许修改key。其原因是因为map和set是根据关键字排序来保证其有序性的，如果允许修改key的话，那么首先需要删除该键，然后调节平衡，再插入修改后的键值，调节平衡，如此一来，严重破坏了map和set的结构，导致iterator失效，不知道应该指向改变前的位置，还是指向改变后的位置。所以STL中将set的迭代器设置成const，不允许修改迭代器的值；而map的迭代器则不允许修改key值，允许修改value值。 map支持下标操作，set不支持下标操作。map可以用key做下标，map的下标运算符[ ]将关键码作为下标去执行查找，如果关键码不存在，则插入一个具有该关键码和mapped_type类型默认值的元素至map中，因此下标运算符[ ]在map应用中需要慎用，const_map不能用，只希望确定某一个关键值是否存在而不希望插入元素时也不应该使用，mapped_type类型没有默认值也不应该使用。如果find能解决需要，尽可能用find。 1.2 STL中MAP数据存放形式 有序的MAP是红黑树，unordered map底层结构是哈希表 Map映射，map 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。不允许键值重复。 底层实现：红黑树 适用场景：有序键值对不重复映射 Multimap多重映射。multimap 的所有元素都是 pair，同时拥有实值（value）和键值（key）。pair 的第一元素被视为键值，第二元素被视为实值。所有元素都会根据元素的键值自动被排序。允许键值重复。 底层实现：红黑树 适用场景：有序键值对可重复映射 1.3 epoll原理调用顺序：123int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout); 首先创建一个epoll对象 使用epoll_ctl对这个对象进行操作，把需要监控的描述添加进去，这些描述如将会以epoll_event结构体的形式组成一颗红黑树 阻塞在epoll_wait，进入大循环，当某个fd上有事件发生时，内核将会把其对应的结构体放入到一个链表中，返回有事件发生的链表 1.4 malloc的原理，另外brk系统调用和mmap系统调用的作用分别是什么Malloc函数用于动态分配内存。为了减少内存碎片和系统调用的开销，malloc其采用内存池的方式，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。当用户申请内存时，直接从堆区分配一块合适的空闲块。Malloc采用隐式链表结构将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时malloc采用显示链表结构来管理所有的空闲块，即使用一个双向链表将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。当进行内存分配时，Malloc会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配；当进行内存合并时，malloc采用边界标记法，根据每个块的前后块是否已经分配来决定是否进行块合并。 Malloc在申请内存时，一般会通过brk或者mmap系统调用进行申请。其中当申请内存小于128K时，会使用系统函数brk在堆区中分配；而当申请内存大于128K时，会使用系统函数mmap在映射区分配。 1.5 C++的内存管理在C++中，虚拟内存分为代码段、数据段、BSS段、堆区、文件映射区以及栈区六部分。代码段:包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码。 数据段：存储程序中已初始化的全局变量和静态变量 bss 段：存储未初始化的全局变量和静态变量（局部+全局），以及所有被初始化为0的全局变量和静态变量。 堆区：调用new/malloc函数时在堆区动态分配内存，同时需要调用delete/free来手动释放申请的内存。 映射区:存储动态链接库以及调用mmap函数进行的文件映射 栈：使用栈空间存储函数的返回地址、参数、局部变量、返回值 1.6 C++的内存泄漏/font&gt;内存泄漏通常是由于调用了malloc/new等内存申请的操作，但是缺少了对应的free/delete。 linux环境下的内存泄漏检查工具Valgrind 在写代码时可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致 1.7 什么时候会发生段错误 使用野指针 试图修改字符串常量的内 1.8 什么是memory leak，也就是内存泄漏内存泄漏(memory leak)是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。内存泄漏的分类： 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak. 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。 1.9 C++11有哪些新特性1.10 并发(concurrency)和并行(parallelism)并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。 1.11 单核机器上写多线程程序，是否需要考虑加锁在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。 例如变量自增操作，++i，并非原子操作，汇编层面分为3步：获取变量值，变量值+1，保存。 1.12 死锁发生的条件以及如何解决死锁死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的相互等待的现象。死锁发生的四个必要条件如下： 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源； 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链 解决死锁的方法即破坏上述四个条件之一，主要方法如下： 资源一次性分配，从而剥夺请求和保持条件 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 1.13 操作系统中的结构体对齐，字节对齐1、原因：1）平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。 2）性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。 2、规则 1）数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员的对齐按照#pragma pack指定的数值和这个数据成员自身长度中，比较小的那个进行。 2）结构(或联合)的整体对齐规则：在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行。 3）结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。 3、定义结构体对齐 可以通过预编译命令#pragma pack(n)，n=1,2,4,8,16来改变这一系数，其中的n就是指定的“对齐系数”。 4、举例123456789101112131415#pragma pack(2)struct AA &#123;int a; //长度4 &gt; 2 按2对齐；偏移量为0；存放位置区间[0,3]char b; //长度1 &lt; 2 按1对齐；偏移量为4；存放位置区间[4]short c; //长度2 = 2 按2对齐；偏移量要提升到2的倍数6；存放位置区间[6,7]char d; //长度1 &lt; 2 按1对齐；偏移量为7；存放位置区间[8]；共九个字节&#125;;#pragma pack() 1.14 虚函数的实现的基本原理 单继承 虚函数表构造过程 虚函数调用过程 多重继承 1.14 Sizeof 考察在c99没有出现之前，sizeof是由编译时确定的，sizeof对一个类型求出的值可以当一个常量来用。但C99中引入了动态数组（定义一个数组，其大小由运行时确定）导致sizeof作用于动态数组时的值不再是常量。 demo 1234567891011#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(int argc, char *argv[]) &#123; int n; scanf(&quot;%d&quot;,&amp;n); int arr[n]; printf(&quot;%d\\n&quot;,sizeof(n++)); printf(&quot;%d\\n&quot;,sizeof(arr)); printf(&quot;%d&quot;,n); return 0;&#125; 输入：3输出： 4 12 3 sizeof(n++)中的++未执行。 结论 sizeof是一种运算符不是函数，所得出的值在编译期确定，可以求出静态分配内存的数组的长度，但不能求出动态分配的内存的大小。 1.14 union的内存分配1.空间大小 各成员共享一段内存空间，一个联合变量的长度等于各成员中最长的长度 要大于等于最长的一个结构变量的空间 并且要能够整除其他结构变量的数据长度，即联合体空间对其他成员的元类型要能够整除（int a[5]，其元类型为int，元类型长度为4），实际上就是要取一个元类型的最小公倍数。 123456union &#123; float fuel_load; //4 Bytes char a[5]; // 1 * 5 = 5 Bytes int pallets; // 4 Bytes&#125;fighter; fighter的空间大小为：8。float：4 Bytes，char：1 Bytes，int：4 Bytes 。8可以整除1和4，并且8&gt;5。 2.内存分布 1234567891011union &#123; int i; char x[2];&#125;a;int main(void)&#123; a.x[0] = 10; a.x[1] = 1; printf(&quot;%d\\n&quot;,a.i); return 0;&#125; 高地址-&gt;低地址|::|::|::|::||字节0|字节1|字节2|字节3||0000 0000|0000 0000|0000 0001|0000 1010| 应用：判断大小端 1.14 进程的状态，以及进程生命周期流程 创建状态：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态 就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行 执行状态：进程处于就绪状态被调度后，进程进入执行状态 阻塞状态：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用 终止状态：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 1.14 进程之间调度方式分类 系统进程：操作系统用来管理资源的进程，当系统进程处于运行态时，CPU处于管态，系统之间的关系由操作系统负责 用户进程：操作系统可以独立执行的的用户程序段，当用户进程处于运行态时，CPU处于目态，用户进程之间的关系由用户负责 调度方法 先来先服务调度算法 短作业（进程） 优先调度算法 优先权调度算法 高响应比优先调度算法 基于时间片的轮转调度算法 多级反馈队列调度算法 1.14 进程间通信 共享内存 消息队列 信号 信号量 套接字 管道 1.14 线程通信 锁机制 信号量机制 信号机制 2.计算机网络类2.1 TCP怎么保证可靠性，并且简述一下TCP建立连接和断开连接的过程TCP保证可靠性：（1）序列号、确认应答、超时重传 数据到达接收方，接收方需要发出一个确认应答，表示已经收到该数据段，并且确认序号会说明了它下一次需要接收的数据序列号。如果发送发迟迟未收到确认应答，那么可能是发送的数据丢失，也可能是确认应答丢失，这时发送方在等待一定时间后会进行重传。这个时间一般是2*RTT(报文段往返时间）+一个偏差值。 （2）窗口控制与高速重发控制/快速重传（重复确认应答） TCP会利用窗口控制来提高传输速度，意思是在一个窗口大小内，不用一定要等到应答才能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。 使用窗口控制，如果数据段1001-2000丢失，后面数据每次传输，确认应答都会不停地发送序号为1001的应答，表示我要接收1001开始的数据，发送端如果收到3次相同应答，就会立刻进行重发；但还有种情况有可能是数据都收到了，但是有的应答丢失了，这种情况不会进行重发，因为发送端知道，如果是数据段丢失，接收端不会放过它的，会疯狂向它提醒…… （3）拥塞控制 如果把窗口定的很大，发送端连续发送大量的数据，可能会造成网络的拥堵（大家都在用网，你在这狂发，吞吐量就那么大，当然会堵），甚至造成网络的瘫痪。所以TCP在为了防止这种情况而进行了拥塞控制。 慢启动：定义拥塞窗口，一开始将该窗口大小设为1，之后每次收到确认应答（经过一个rtt），将拥塞窗口大小*2。 拥塞避免：设置慢启动阈值，一般开始都设为65536。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小+1），以此来避免拥塞。 将报文段的超时重传看做拥塞，则一旦发生超时重传，我们需要先将阈值设为当前窗口大小的一半，并且将窗口大小设为初值1，然后重新进入慢启动过程。 快速重传：在遇到3次重复确认应答（高速重发控制）时，代表收到了3个报文段，但是这之前的1个段丢失了，便对它进行立即重传。 然后，先将阈值设为当前窗口大小的一半，然后将拥塞窗口大小设为慢启动阈值+3的大小。 这样可以达到：在TCP通信时，网络吞吐量呈现逐渐的上升，并且随着拥堵来降低吞吐量，再进入慢慢上升的过程，网络不会轻易的发生瘫痪。 三次握手： Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 四次挥手： 由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。 1.数据传输结束后，客户端的应用进程发出连接释放报文段，并停止发送数据，客户端进入FIN_WAIT_1状态，此时客户端依然可以接收服务器发送来的数据。 2.服务器接收到FIN后，发送一个ACK给客户端，确认序号为收到的序号+1，服务器进入CLOSE_WAIT状态。客户端收到后进入FIN_WAIT_2状态。 3.当服务器没有数据要发送时，服务器发送一个FIN报文，此时服务器进入LAST_ACK状态，等待客户端的确认 4.客户端收到服务器的FIN报文后，给服务器发送一个ACK报文，确认序列号为收到的序号+1。此时客户端进入TIME_WAIT状态，等待2MSL（MSL：报文段最大生存时间），然后关闭连接 2.2 TCP的模型，状态转移2.3 操作系统中的中断中断是指CPU对系统发生的某个事件做出的一种反应，CPU暂停正在执行的程序，保存现场后自动去执行相应的处理程序，处理完该事件后再返回中断处继续执行原来的程序。 由CPU外部引起的，如I/O中断、时钟中断 来自CPU内部事件或程序执行中引起的中断，例如程序非法操作，地址越界、浮点溢出） 在程序中使用了系统调用引起的。而中断处理一般分为中断响应和中断处理两个步骤，中断响应由硬件实施，中断处理主要由软件实施。 2.4 TCP拥塞控制拥塞控制是防止过多的数据注入网络，使得网络中的路由器或者链路过载。流量控制是点对点的通信量控制，而拥塞控制是全局的网络流量整体性的控制。发送双方都有一个拥塞窗口——cwnd。1、慢开始 最开始发送方的拥塞窗口为1，由小到大逐渐增大发送窗口和拥塞窗口。每经过一个传输轮次，拥塞窗口cwnd加倍。当cwnd超过慢开始门限，则使用拥塞避免算法，避免cwnd增长过大。 2、拥塞避免 每经过一个往返时间RTT，cwnd就增长1。 在慢开始和拥塞避免的过程中，一旦发现网络拥塞，就把慢开始门限设为当前值的一半，并且重新设置cwnd为1，重新慢启动。（乘法减小，加法增大） 3、快重传 接收方每次收到一个失序的报文段后就立即发出重复确认，发送方只要连续收到三个重复确认就立即重传（尽早重传未被确认的报文段）。 4、快恢复 当发送方连续收到了三个重复确认，就乘法减半（慢开始门限减半），将当前的cwnd设置为慢开始门限，并且采用拥塞避免算法（连续收到了三个重复请求，说明当前网络可能没有拥塞）。 采用快恢复算法时，慢开始只在建立连接和网络超时才使用。 达到什么情况的时候开始减慢增长的速度？ 采用慢开始和拥塞避免算法的时候 一旦cwnd&gt;慢开始门限，就采用拥塞避免算法，减慢增长速度 一旦出现丢包的情况，就重新进行慢开始，减慢增长速度 采用快恢复和快重传算法的时候 一旦cwnd&gt;慢开始门限，就采用拥塞避免算法，减慢增长速度 一旦发送方连续收到了三个重复确认，就采用拥塞避免算法，减慢增长速度 2.5 阻塞，非阻塞，同步，异步阻塞和非阻塞：调用者在事件没有发生的时候，一直在等待事件发生，不能去处理别的任务这是阻塞。调用者在事件没有发生的时候，可以去处理别的任务这是非阻塞。 同步和异步：调用者必须循环自去查看事件有没有发生，这种情况是同步。调用者不用自己去查看事件有没有发生，而是等待着注册在事件上的回调函数通知自己，这种情况是异步 3.数据库类3.1 数据库事物的一致性事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元。事务是DBMS中最基础的单位，事务不可分割。事务具有4个基本特征，分别是：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Duration），简称ACID。 1）原子性（Atomicity） 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，[删删删]因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。 2）一致性（Consistency） 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。 3）隔离性（Isolation） 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。 多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。这指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。 不同的隔离级别： Read Uncommitted（读取未提交[添加中文释义]内容）：最低的隔离级别，什么都不需要做，一个事务可以读到另一个事务未提交的结果。所有的并发事务问题都会发生。 Read Committed（读取提交内容）：只有在事务提交后，其更新结果才会被其他事务看见。可以解决脏读问题。 Repeated Read（可重复读）：在一个事务中，对于同一份数据的读取结果总是相同的，无论是否有其他事务对这份数据进行操作，以及这个事务是否提交。可以解决脏读、不可重复读。 Serialization（可串行化）：事务串行化执行，隔离级别最高，牺牲了系统的并发性。可以解决并发事务的所有问题。 4）持久性（Durability） 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误 redis和memcache1）数据类型 ：redis数据类型丰富，支持set liset等类型；memcache支持简单数据类型，需要客户端自己处理复杂对象2）持久性：redis支持数据落地持久化存储；memcache不支持数据持久存储。) 3）分布式存储：redis支持master-slave复制模式；memcache可以使用一致性hash做分布式。 4）value大小不同：memcache是一个内存缓存，key的长度小于250字符，单个item存储要小于1M，不适合虚拟机使用 5）数据一致性不同：redis使用的是单线程模型，保证了数据按顺序提交；memcache需要使用cas保证数据一致性。CAS（Check and Set）是一个确保并发一致性的机制，属于“乐观锁”范畴；原理很简单：拿版本号，操作，对比版本号，如果一致就操作，不一致就放弃任何操作 6）cpu利用：redis单线程模型只能使用一个cpu，可以开启多个redis进程 覆盖索引覆盖索引是select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖。 注意：覆盖索引必须要存储索引列的值，而哈希索引、空间索引和全文索引不存储索引列的值，所以mysql只能用B-tree索引做覆盖索引。 为什么说B+树比B树更适合数据库索引 B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。 B+树的查询效率更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。 B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低 4.linux强相关类4.1 select，epoll的区别4.2 Linux虚拟地址空间为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。 虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。 还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。 请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 虚拟内存的好处： 1.扩大地址空间； 2.内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。 3.公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。 4.当进程通信时，可采用虚存共享的方式实现。 5.当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存 6.虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高 7.在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片 虚拟内存的代价： 1.虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存 2.虚拟地址到物理地址的转换，增加了指令的执行时间。 3.页面的换入换出需要磁盘I/O，这是很耗时的 4.如果一页中只有一部分数据，会浪费内存。 4.3 fork和vfork的区别fork的基础知识：fork:创建一个和当前进程映像一样的进程可以通过fork( )系统调用： 12345#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;pid_t fork(void); 成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。 最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。 在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。 vfork的基础知识： 在实现写时复制之前，Unix的设计者们就一直很关注在fork后立刻执行exec所造成的地址空间的浪费。BSD的开发者们在3.0的BSD系统中引入了vfork( )系统调用。12345#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;pid_t vfork(void); 除了子进程必须要立刻执行一次对exec的系统调用，或者调用_exit( )退出，对vfork( )的成功调用所产生的结果和fork( )是一样的。vfork( )会挂起父进程直到子进程终止或者运行了一个新的可执行文件的映像。通过这样的方式，vfork( )避免了地址空间的按页复制。在这个过程中，父进程和子进程共享相同的地址空间和页表项。实际上vfork( )只完成了一件事：复制内部的内核数据结构。因此，子进程也就不能修改地址空间中的任何内存。 vfork( )是一个历史遗留产物，Linux本不应该实现它。需要注意的是，即使增加了写时复制，vfork( )也要比fork( )快，因为它没有进行页表项的复制。然而，写时复制的出现减少了对于替换fork( )争论。实际上，直到2.2.0内核，vfork( )只是一个封装过的fork( )。因为对vfork( )的需求要小于fork( )，所以vfork( )的这种实现方式是可行的。 补充知识点：写时复制 Linux采用了写时复制的方法，以减少fork时对父进程空间进程整体复制带来的开销。 写时复制是一种采取了惰性优化方法来避免复制时的系统开销。它的前提很简单：如果有多个进程要读取它们自己的那部门资源的副本，那么复制是不必要的。每个进程只要保存一个指向这个资源的指针就可以了。只要没有进程要去修改自己的“副本”，就存在着这样的幻觉：每个进程好像独占那个资源。从而就避免了复制带来的负担。如果一个进程要修改自己的那份资源“副本”，那么就会复制那份资源，并把复制的那份提供给进程。不过其中的复制对进程来说是透明的。这个进程就可以修改复制后的资源了，同时其他的进程仍然共享那份没有修改过的资源。所以这就是名称的由来：在写入时进行复制。 写时复制的主要好处在于：如果进程从来就不需要修改资源，则不需要进行复制。惰性算法的好处就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。 在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享。 现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。 在调用fork( )时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。 fork和vfork的区别： fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段 fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。 vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。 当需要改变共享数据段中变量的值，则拷贝父进程。 4.4 如何判断一个程序是死锁还是死循环1. 定位 死循环 线程： 活跃中 死锁 线程： 挂起中 命令： top 、 ps 4.4 用户态到内核态的转化原理用户态切换到内核态的3种方式 系统调用 这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。 异常 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。 外围设备的中断 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 切换操作 从出发方式看，可以在认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一样的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断处理机制基本上是一样的，用户态切换到内核态的步骤主要包括： 从当前进程的描述符中提取其内核栈的ss0及esp0信息。 使用ss0和esp0指向的内核栈将当前进程的cs,eip，eflags，ss,esp信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。 将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。 6种微服务RPC框架 Dubbo Motan Tars Spring Cloud Thrift gRPC","categories":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"}],"keywords":[{"name":"求职","slug":"求职","permalink":"https://lives.xtcgch.ink/categories/求职/"}]},{"title":"jenkins的配置和使用","slug":"Linux之jenkins的配置和使用-20200819","date":"2020-08-19T09:58:39.000Z","updated":"2021-10-02T13:33:56.678Z","comments":true,"path":"2020/08/19/jenkins/","link":"","permalink":"https://lives.xtcgch.ink/2020/08/19/jenkins/","excerpt":"摘要：本文记录一下jenkins的配置和使用。","text":"摘要：本文记录一下jenkins的配置和使用。 先占个坑 脑图 简介 配置","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"JENKINS","slug":"JENKINS","permalink":"https://lives.xtcgch.ink/tags/JENKINS/"},{"name":"运维","slug":"运维","permalink":"https://lives.xtcgch.ink/tags/运维/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"Linux之ubuntu篇","slug":"Linux之ubuntu篇-20200819","date":"2020-08-19T08:02:06.000Z","updated":"2021-10-10T08:34:20.584Z","comments":true,"path":"2020/08/19/Linux之ubuntu篇/","link":"","permalink":"https://lives.xtcgch.ink/2020/08/19/Linux之ubuntu篇/","excerpt":"摘要：本文记录了ubuntu18.04和20.04版本设置静态IP的方法。","text":"摘要：本文记录了ubuntu18.04和20.04版本设置静态IP的方法。 脑图yaml那么简单，应该不需要脑图!? 前言 不同配置文本的格式都不尽相同，都是坑，希望早日能够财务自由！珍爱生命，远离编程！ ubuntu18.04 和 ubuntu20.04两个版本的配置方法是一样的!ubuntu18.04 和 ubuntu20.04两个版本的配置方法是一样的!ubuntu18.04 和 ubuntu20.04两个版本的配置方法是一样的! 配置方法 备份原始配置文件 1sudo cp /etc/netplan/01-network-manager-all.yaml /etc/netplan/01-network-manager-all.yaml.bak 原始配置文件内容 1234# Let NetworkManager manage all devices on this systemnetwork: version: 2 renderer: NetworkManager 新配置文件内容 1234567891011# Let NetworkManager manage all devices on this systemnetwork: version: 2 renderer: NetworkManager ethernets: enp0s8: dhcp4: no addresses: [192.168.1.112/24] gateway4: 192.168.1.1 nameservers: addresses: [8.8.8.8,114.114.114.114] 注意： yaml文件的格式：冒号”:”后必须有个空格(欸，这就是猿们喜欢自己造轮子的原因) 应用配置 1sudo netplan apply yaml语法To be continue","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"UBUNTU","slug":"UBUNTU","permalink":"https://lives.xtcgch.ink/tags/UBUNTU/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"Linux之shell","slug":"Linux之shell-20200811","date":"2020-08-11T06:19:37.000Z","updated":"2021-10-10T16:03:36.419Z","comments":true,"path":"2020/08/11/Linux之shell/","link":"","permalink":"https://lives.xtcgch.ink/2020/08/11/Linux之shell/","excerpt":"摘要：记录shell的学习过程！","text":"摘要：记录shell的学习过程！ 脑图 简述 语法查找替换源文件内容替换1sed -i &apos;s/abcd/efghk/g&apos; data.txt 截取1awk -F&apos;|&apos; &apos;&#123;&#125;BEGIN&#123;&#125;END&#123;&#125;&apos; data.txt 常用功能后台执行python12nohup sh shell.sh &gt; temp_log.txt 2&gt;&amp;1 &amp;(nohup sh shell.sh ) 统计文本中某一列的和文本：data.txt123banana 1.5apple 6.0peach 3.2 脚本：1cat data.txt|awk -F&apos; &apos; -v sum=0 &apos;&#123;sum += $2&#125; END&#123;print sum&#125;&apos; 输出：110.7 统计某列值得类型文本：123452020-08-11 5002020-08-09 62020-08-10 152020-08-11 292020-08-12 6 脚本：1awk &apos;&#123;count[$1]++;count2[$2]++&#125;END&#123;print length(count),length(count2)&#125;&apos; data.txt 输出：14 4 多文本处理文本：a.txt123banana 1.5apple 6.0peach 3.2 b.txt1234banana 1.5car 20000house 5000000horse 2000 脚本：1awk -F&apos;|&apos; &apos;ARGIND==1&#123;data[$1]=0;&#125;ARGIND==2&#123;if($1 in data)&#123;printf(&quot;%s|%s\\n&quot;,$1,$2);&#125;&#125;END&#123;&#125;&apos; a.txt b.txt 输出：1banana 1.5 批量发送http请求1awk &apos;&#123; system( &quot;curl -d \\&quot;data=&quot; $0 &quot;\\&quot; http://127.0.0.1/cgi-bin/cgi.cgi&quot; ) &#125;&apos; files.txt shell会建立子shell的场景 进程替换既然是新进程了，当然进入子shell执行 12345[root@xuexi ~]# echo $BASHPID65230[root@xuexi ~]# cat &lt;(echo $BASHPID) # 进程替换&quot;&lt;()&quot;进入子shell65616 放入后台运行的任务它不仅是一个独立的子进程，还是在子shell环境中运行的 1234567[root@xuexi ~]# echo $BASHPID65230[root@xuexi ~]# echo $BASHPID &amp; # 放入后台运行的任务进入子shell[1] 65614[root@xuexi ~]# 65614[1]+ Done echo $BASHPID 使用括号()组合一系列命令例如(ls;date;echo haha)，独立的括号将会开启一个子shell来执行括号内的命令 1234[root@xuexi ~]# echo $BASHPID65230[root@xuexi ~]# (echo $BASHPID) # 使用括号()的命令组合进入子shell65613 命令替换当命令行中包含了命令替换部分时，将开启一个子shell先执行这部分内容，再将执行结果返回给当前命令。因为这次的子shell不是通过bash命令进入的子shell，所以它会继承父shell的所有变量内容。这也就解释了”echo $(echo $$)”中”$$”的结果是当前bash的pid号，而不是子shell的pid号，但”echo $(echo $BASHPID)”却和父bash进程的pid不同，因为它不是使用bash命令进入的子shell 1234[root@xuexi ~]# echo $BASHPID65230[root@xuexi ~]# echo $(echo $BASHPID) # 使用命令替换$()进入子shell65612 执行非bash内置命令时例如执行cp命令、grep命令等，它们直接fork一份bash进程，然后使用exec加载程序替代该子bash。此类子进程会继承所有父bash的环境。但严格地说，这已经不是子shell，因为exec加载的程序已经把子bash进程替换掉了，这意味着丢失了很多bash环境。在bash文档中，直接称呼这种环境为”单独的环境”，和子shell的概念类似 12345[root@xuexi ~]# let a=$BASHPID # let是内置命令[root@xuexi ~]# echo $a65230[root@xuexi ~]# echo $BASHPID # echo是非内置命令，结果是不进入子shell65230 执行shell函数时其实shell函数就是命令，它和bash内置命令的情况一样。直接执行时不会进入子shell，但放在管道后会进入子shell 1234567[root@xuexi ~]# fun_test ()&#123; echo $BASHPID; &#125; # 定义一个函数，输出BASHPID变量的值[root@xuexi ~]# echo $BASHPID 65230[root@xuexi ~]# fun_test # 说明执行函数不会进入子shell65230[root@xuexi ~]# cd | fun_test # 但放在管道后会进入子shell65605 执行shell脚本时脚本中第一行总是”#!/bin/bash”或者直接”bash xyz.sh”，这和上面的执行bash进入子shell其实是一回事，都是使用bash命令进入子shell。只不过此时的bash命令和情况②中直接执行bash命令所隐含的选项不一样，所以继承和加载的shell环境也不一样。事实也确实如此，它仅只继承父shell的某些环境变量，其余环境一概初始化。另外，执行shell脚本相比于直接执行bash命令，还多了一个动作：脚本执行完毕后自动退出子shell 12345678[root@xuexi ~]# cat b.sh #!/bin/bashecho $BASHPID[root@xuexi ~]# echo $BASHPID65534[root@xuexi ~]# ./b.sh 65570 执行bash命令本身时显然它会进入子shell环境，它的绝大多数环境都是新配置的，因为会加载一些环境配置文件。事实上fork出来的bash子进程内容完全继承父shell，但因重新加载了环境配置项，所以子shell没有继承普通变量，更准确的说是覆盖了从父shell中继承的变量。不妨试试在/etc/bashrc文件中定义一个变量，再在父shell中export名称相同值却不同的环境变量，然后到子shell中看看该变量的值为何 12345[root@xuexi ~]# echo &quot;var=55&quot; &gt;&gt;/etc/bashrc[root@xuexi ~]# export var=66[root@xuexi ~]# bash[root@xuexi ~]# echo $var55 执行bash内置命令时bash内置命令是非常特殊的，父进程不会创建子进程来执行这些命令，而是直接在当前bash环境中执行。但如果将内置命令放在管道后，则此内置命令将和管道左边的进程同属于一个进程组，所以仍然会创建子shell 同一个shell内执行：12345[root@xuexi ~]# echo $BASHPID # 当前BASHPID65230[root@xuexi ~]# let a=$BASHPID # bash内置命令，不进入子shell[root@xuexi ~]# echo $a65230 创建子shell执行：1234[root@xuexi ~]# echo $BASHPID65230[root@xuexi ~]# cd | expr $BASHPID # 管道使得任何命令都进入进程组，会进入子shell 65603 环境变量export和source用户登录到Linux系统后，系统将启动一个用户shell。在这个shell中，可以使用shell命令或声明变量，也可以创建并运行shell脚本程序。运行shell脚本程序时，系统将创建一个子shell。此时，系统中将有两个shell，一个是登录时系统启动的shell，另一个是系统为运行脚本程序创建的shell。当一个脚本程序运行完毕，它的脚本shell将终止，可以返回到执行该脚本之前的shell。 1.export 在子 shell中定义的变量只在该子shell内有效。如果在一个shell脚本程序中定义了一个变量，当该脚本程序运行时，这个定义的变量只是该脚本程序内的一个局部变量，其他的shell不能引用它，要使某个变量的值可以在其他shell中被改变，可以使用export命令对已定义的变量进行输出。 export命令将使系统在创建每一个新的shell时定义这个变量的一个拷贝。这个过程称之为变量输出。 用法： 12myfile=”List”export myfile 说明： 在子shell中定义变量myfile时，myfile的作用域只在该shell，生命周期也只在该shell中，其他shell是无法访问myfile的值。 export myfile能够将myfile的作用域改变为所有的shell，但是需要重新登录系统才能生效。而source /etc/profile则能够立即刷新，使得myfile立即生效。 2.source source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录。 用法： 121. source filename 2. . filename 3. source filename 与 sh filename 及./filename执行脚本的区别 当shell脚本具有可执行权限时，用sh filename与./filename执行脚本是没有区别得。./filename是因为当前目录没有在PATH中，所有”.”是用来表示当前目录的。 sh filename 重新建立一个子shell，在子shell中执行脚本里面的语句，该子shell继承父shell的环境变量，但子shell新建的、改变的变量不会被带回父shell，除非使用export。 source filename：这个命令其实只是简单地读取脚本里面的语句依次在当前shell里面执行，没有建立新的子shell。那么脚本里面所有新建、改变变量的语句都会保存在当前shell里面。 应用场景 总结","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"SHELL","slug":"SHELL","permalink":"https://lives.xtcgch.ink/tags/SHELL/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"编程语言之go","slug":"编程语言之go-20200127","date":"2020-01-27T15:58:12.000Z","updated":"2021-11-22T12:10:50.227Z","comments":true,"path":"2020/01/27/编程语言之go/","link":"","permalink":"https://lives.xtcgch.ink/2020/01/27/编程语言之go/","excerpt":"摘要：这是摘要！","text":"摘要：这是摘要！ 脑图 环境配置 下载google国内镜像 环境配置解压缩到/usr/local,并且配置环境变量123tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gzexport PATH=$PATH:/usr/local/go/binsource /etc/profile 测试查看版本 1go version 输出1go version go1.14.7 linux/amd64 测试脚本12345678#test.gopackage mainimport &quot;fmt&quot;func main() &#123; fmt.Printf(&quot;hello, world\\n&quot;)&#125; 运行 1go run hello.go 输出：1hello, world 配置国内镜像1export GOPROXY=https://mirrors.aliyun.com/goproxy/ gin框架下载下载地址 安装1go get -u github.com/gin-gonic/gin 安装1import &quot;github.com/gin-gonic/gin&quot; 总结无","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"GO","slug":"GO","permalink":"https://lives.xtcgch.ink/tags/GO/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"编程语言之python","slug":"编程语言之python-20200127","date":"2020-01-27T15:47:02.000Z","updated":"2021-11-08T05:37:13.773Z","comments":true,"path":"2020/01/27/编程语言之python/","link":"","permalink":"https://lives.xtcgch.ink/2020/01/27/编程语言之python/","excerpt":"摘要：记录python的学习过程！","text":"摘要：记录python的学习过程！ 脑图 定义引用的python处理器1#!/usr/bin/python Python2.x 与 3​​.x 版本区别 print 函数 Unicode 除法运算 异常 xrange 八进制字面量表示 不等运算符 去掉了repr表达式`` 多个模块被改名 数据类型 Py3.X去除了long类型，现在只有一种整型——int，但它的行为就像2.X版本的long 新增了bytes类型，对应于2.X版本的八位串 dict的.keys()、.items 和.values()方法返回迭代器，而之前的iterkeys()等函数都被废弃。同时去掉的还有 dict.has_key()，用 in替代它 定义一个bytes字面量的方法如下: 123&gt;&gt;&gt; b = b&apos;china&apos; &gt;&gt;&gt; type(b) &lt;type &apos;bytes&apos;&gt; 引用包和模块12345678import sysimport commandsimport MySQLdbimport csvimport datetimeimport timeimport os 行和缩进 Python 的代码块不使用大括号 {} 来控制类，函数以及其他逻辑判断 python 最具特色的就是用缩进来写模块 缩进的空白数量是可变的，但是所有代码块语句必须包含相同的缩进空白数量，这个必须严格执行 1234if True: print &quot;True&quot;else: print &quot;False&quot; 函数12345def get_refund_bills_with_mid(nums): data= 12345 + nums return numsretval = get_refund_bills_with_mid(5) 不定长参数123456789101112131415#!/usr/bin/python# -*- coding: UTF-8 -*- # 可写函数说明def printinfo( arg1, *vartuple ): &quot;打印任何传入的参数&quot; print &quot;输出: &quot; print arg1 for var in vartuple: print var return # 调用printinfo 函数printinfo( 10 )printinfo( 70, 60, 50 ) 匿名函数python 使用 lambda 来创建匿名函数。 lambda只是一个表达式，函数体比def简单很多 lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去 lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数 虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率 return语句Python 标识符 Python 中的标识符是区分大小写的 以下划线开头的标识符是有特殊意义的 以单下划线开头 _foo 的代表不能直接访问的类属性,需通过类提供的接口进行访问 以双下划线开头的 __foo 代表类的私有成员 以双下划线开头和结尾的 foo 代表 Python 里特殊方法专用的标识 Python 可以同一行显示多条语句，方法是用分号 ; 分开1print &apos;hello&apos;;print &apos;runoob&apos;; 多行语句 Python语句中一般以新行作为语句的结束符 可以使用斜杠（ \\）将一行的语句分为多行显示 123total = item_one + \\ item_two + \\ item_three 语句中包含 [], {} 或 () 括号就不需要使用多行连接符 12days = [&apos;Monday&apos;, &apos;Tuesday&apos;, &apos;Wednesday&apos;, &apos;Thursday&apos;, &apos;Friday&apos;] Python 引号 Python 可以使用引号( ‘ )、双引号( “ )、三引号( ‘’’ 或 “”” ) 来表示字符串 三引号(“””)可以由多行组成，编写多行文本的快捷语法，常用于文档字符串，在文件的特定地点，被当做注释 1234word = &apos;word&apos;sentence = &quot;这是一个句子。&quot;paragraph = &quot;&quot;&quot;这是一个段落。包含了多个语句&quot;&quot;&quot; Python注释 单行注释：# 注意：第一行的#! /bin/bash不是表示注释，而是指明了执行该脚本的bash解释器的位置 python 中多行注释使用三个单引号(‘’’)或三个双引号(“””) 1234567891011&apos;&apos;&apos;这是多行注释，使用单引号。这是多行注释，使用单引号。这是多行注释，使用单引号。&apos;&apos;&apos;&quot;&quot;&quot;这是多行注释，使用双引号。这是多行注释，使用双引号。这是多行注释，使用双引号。&quot;&quot;&quot; 空行 函数之间或类的方法之间用空行分隔，表示一段新的代码的开始 空行的作用在于分隔两段不同功能或含义的代码，便于日后代码的维护或重构 空行也是程序代码的一部分 同一行显示多条语句Python可以在同一行中使用多条语句，语句之间使用分号(;)分割 123#!/usr/bin/pythonimport sys; x = &apos;runoob&apos;; sys.stdout.write(x + &apos;\\n&apos;) 输出 屏幕输出1print (&quot;%s , %d&quot;%(str,intval)) print 默认输出是换行的，如果要实现不换行需要在变量末尾加上逗号 , 12345678910111213141516#!/usr/bin/python# -*- coding: UTF-8 -*-x=&quot;a&quot;y=&quot;b&quot;# 换行输出print xprint yprint &apos;---------&apos;# 不换行输出print x,print y,# 不换行输出print x,y 文件输出123fo = open(&quot;text.txt&quot;,&quot;w&quot;)fo.write(&quot;%s , %d&quot;%(str,intval))fo.close() MYSQL数据库连接 引入mysql模块 1import MySQLdb 链接mysql数据库 1234posbill_read = MySQLdb.connect(host=&quot;&quot;,user = &quot;&quot;,passwd = &quot;&quot;,use_unicode=True,charset=&apos;utf8&apos;)cursor_read = posbill_read.cursor()cursor_read.close()posbill_read.close() 事务的提交和回滚 12posbill_read.commit()posbill_read.rollback() 获取数据 1234results = cursor_read.execute(sql)for one in results: data0 = one[0] data1 = one[1] 设置全局编码123import sysreload(sys)sys.setdefaultencoding(&apos;utf8&apos;) # 设置默认编码格式为&apos;utf-8&apos; map的使用 定义 1map_data = &#123;&#125; 赋值 1234if key not in map_data: map_data[key] = valueelse: map_data[key] = value2 遍历 123for key in map_data.keys(): print key print map_data[key] 读取配置文件 引用包 1import ConfigParser 加载配置文件 12cf = ConfigParser.ConfigParser()cf.read(&quot;/home/data/config.properties&quot;) 读取配置节点 12ip= cf.get(&quot;node1&quot;, &quot;IP&quot;)port = cf.get(&quot;node1&quot;, &quot;PORT&quot;) 配置文件 123[node1]IP = 127.0.0.1PORT = 3306 demo 配置文件: 12345678[posbill_pos]IP = 127.0.0.1User = rootPassword = adminCharsetName = utf8ClientIP = 127.0.0.1Port = 3308Database = test 读取方法:12345678910111213141516171819202122232425262728293031323334353637383940414243import ConfigParserimport MySQLdbconfig_path = &quot;/home/root/tools/config_tools.properties&quot;#map_keydb_alias_IP = &quot;IP&quot;db_alias_Port = &quot;Port&quot;db_alias_User = &quot;User&quot;db_alias_Password = &quot;Password&quot;db_alias_CharsetName = &quot;CharsetName&quot;db_info = &#123;&#125;def close_db_conn(cursor_obj,posbill_obj): cursor_obj.close() posbill_obj.close()def get_config_info(file_path,db_alias): cf = ConfigParser.ConfigParser() cf.read(file_path) #写入key和value db_info[db_alias_IP] = cf.get(db_alias, db_alias_IP) db_info[db_alias_Port] = cf.get(db_alias, db_alias_Port) db_info[db_alias_User] = cf.get(db_alias, db_alias_User) db_info[db_alias_Password] = cf.get(db_alias, db_alias_Password) db_info[db_alias_CharsetName] = cf.get(db_alias, db_alias_CharsetName) print &quot;########################################################&quot; print &quot;配置文件数据&quot; print (&quot;db_alias:%s&quot;%(db_alias)) print (&quot;db_info[db_alias_IP]:%s&quot;%(db_info[db_alias_IP])) print (&quot;db_info[db_alias_Port]:%s&quot;%(db_info[db_alias_Port])) print (&quot;db_info[db_alias_User]:%s&quot;%(db_info[db_alias_User])) print (&quot;db_info[db_alias_Password]:%s&quot;%(db_info[db_alias_Password])) print (&quot;db_info[db_alias_CharsetName]:%s&quot;%(db_info[db_alias_CharsetName])) print &quot;########################################################&quot;if __name__ == &apos;__main__&apos;: get_config_info(config_path,&quot;config.properties&quot;) posbill_pos = MySQLdb.connect(host = db_info[db_alias_IP], port = int(db_info[db_alias_Port]), user = db_info[db_alias_User], passwd = db_info[db_alias_Password], use_unicode = True, charset = db_info[db_alias_CharsetName]) cursor_posbill_pos = posbill_pos.cursor() close_db_conn(cursor_posbill_pos,posbill_pos) close_db_conn(cursor_posbill_scan,posbill_scan) 获取命令行参数获取参数个数1count = sys.argc 获取某个参数1param = sys.argv[1] IF语句 多条件判断123456if key1 ==1 and key2 != 2: print &quot;if 1&quot;elif key1 !=2 or key2 ==2 : print &quot;if 2&quot;else: print &quot;if 3&quot; while语句while语句分为2类：while和while else 语句 常用到的关键词有：continue、break while语句 12345678#!/usr/bin/python count = 0while (count &lt; 9): print &apos;The count is:&apos;, count count = count + 1 print &quot;Good bye!&quot; while else 语句 12345678#!/usr/bin/python count = 0while count &lt; 5: print count, &quot; is less than 5&quot; count = count + 1else: print count, &quot; is not less than 5&quot; 常用运算布尔运算字符串运算关系运算算术运算网络编程 服务器端 1234567891011121314#!/usr/bin/python # -*- coding: UTF-8 -*- # 文件名：server.py import socket # 导入 socket 模块 s = socket.socket() # 创建 socket 对象 host = socket.gethostname() # 获取本地主机名 port = 12345 # 设置端口 s.bind((host, port)) # 绑定端口 s.listen(5) # 等待客户端连接 while True: c,addr = s.accept() # 建立客户端连接 print &apos;连接地址：&apos;, addr c.send(&apos;欢迎访问菜鸟教程！&apos;) c.close() # 关闭连接 客户端 12345678910#!/usr/bin/python # -*- coding: UTF-8 -*- # 文件名：client.py import socket # 导入 socket 模块 s = socket.socket() # 创建 socket 对象 host = socket.gethostname() # 获取本地主机名 port = 12345 # 设置端口号 s.connect((host, port)) print s.recv(1024) s.close() 多线程 函数式：调用thread模块中的start_new_thread()函数来产生新线程。 12345678910111213141516171819#!/usr/bin/python # -*- coding: UTF-8 -*- import thread import time #为线程定义一个函数 def print_time( threadName, delay): count = 0 while count &lt; 5: time.sleep(delay) count += 1 print &quot;%s: %s&quot; % ( threadName, time.ctime(time.time()) ) # 创建两个线程 try: thread.start_new_thread( print_time, (&quot;Thread-1&quot;, 2, ) ) thread.start_new_thread( print_time, (&quot;Thread-2&quot;, 4, ) ) except: print &quot;Error: unable to start thread&quot; while 1: pass 使用Threading模块创建线程使用Threading模块创建线程，直接从threading.Thread继承，然后重写init方法和run方法： 12345678910111213141516171819202122232425262728293031#!/usr/bin/python # -*- coding: UTF-8 -*- import threading import time exitFlag = 0 class myThread (threading.Thread): #继承父类threading.Thread def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): #把要执行的代码写到run函数里面 线程在创建后会直接运行run函数 print &quot;Starting &quot; + self.name print_time(self.name, self.counter, 5) print &quot;Exiting &quot; + self.name def print_time(threadName, delay, counter): while counter: if exitFlag: (threading.Thread).exit() time.sleep(delay) print &quot;%s: %s&quot; % (threadName, time.ctime(time.time())) counter -= 1 # 创建新线程 thread1 = myThread(1, &quot;Thread-1&quot;, 1) thread2 = myThread(2, &quot;Thread-2&quot;, 2) # 开启线程 thread1.start() thread2.start() print &quot;Exiting Main Thread&quot; 线程同步 123456789101112131415161718192021222324252627282930313233343536373839#!/usr/bin/python # -*- coding: UTF-8 -*- import threading import time class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print &quot;Starting &quot; + self.name # 获得锁，成功获得锁定后返回True # 可选的timeout参数不填时将一直阻塞直到获得锁定 # 否则超时后将返回False hreadLock.acquire() print_time(self.name, self.counter, 3) # 释放锁 threadLock.release() def print_time(threadName, delay, counter): while counter: time.sleep(delay) print &quot;%s: %s&quot; % (threadName, time.ctime(time.time())) counter -= 1 hreadLock = threading.Lock() threads = [] # 创建新线程 thread1 = myThread(1, &quot;Thread-1&quot;, 1) thread2 = myThread(2, &quot;Thread-2&quot;, 2) # 开启新线程 thread1.start() thread2.start() # 添加线程到线程列表 threads.append(thread1) threads.append(thread2) # 等待所有线程完成 for t in threads: t.join() print &quot;Exiting Main Thread&quot; 线程优先队列123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#!/usr/bin/python # -*- coding: UTF-8 -*- import Queue import threading import time exitFlag = 0 class myThread (threading.Thread): def __init__(self, threadID, name, q): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.q = q def run(self): print &quot;Starting &quot; + self.name process_data(self.name, self.q) print &quot;Exiting &quot; + self.name def process_data(threadName, q): while not exitFlag: queueLock.acquire() if not workQueue.empty(): data = q.get() queueLock.release() print &quot;%s processing %s&quot; % (threadName, data) else: queueLock.release() time.sleep(1) threadList = [&quot;Thread-1&quot;, &quot;Thread-2&quot;, &quot;Thread-3&quot;] nameList = [&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;, &quot;Four&quot;, &quot;Five&quot;] queueLock = threading.Lock() workQueue = Queue.Queue(10) threads = [] threadID = 1 # 创建新线程 for tName in threadList: thread = myThread(threadID, tName, workQueue) thread.start() threads.append(thread) threadID += 1 # 填充队列 queueLock.acquire() for word in nameList: workQueue.put(word) queueLock.release() # 等待队列清空 while not workQueue.empty(): pass # 通知线程是时候退出 exitFlag = 1 # 等待所有线程完成 for t in threads: t.join() print &quot;Exiting Main Thread&quot; json json函数 12345678910import json函数描述json.dumps将 Python 对象编码成 JSON 字符串json.loads将已编码的 JSON 字符串解码为 Python 对象 json.dumps 123456789#!/usr/bin/pythonimport jsondata = [ &#123; &apos;a&apos; : 1, &apos;b&apos; : 2, &apos;c&apos; : 3, &apos;d&apos; : 4, &apos;e&apos; : 5 &#125; ]json = json.dumps(data)print json json.loads 123456789#!/usr/bin/pythonimport jsonjsonData = &#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;;text = json.loads(jsonData)print text XML 解析movies.xml:123456789101112131415161718192021222324252627282930313233&lt;collection shelf=&quot;New Arrivals&quot;&gt;&lt;movie title=&quot;Enemy Behind&quot;&gt; &lt;type&gt;War, Thriller&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;2003&lt;/year&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Talk about a US-Japan war&lt;/description&gt;&lt;/movie&gt;&lt;movie title=&quot;Transformers&quot;&gt; &lt;type&gt;Anime, Science Fiction&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;year&gt;1989&lt;/year&gt; &lt;rating&gt;R&lt;/rating&gt; &lt;stars&gt;8&lt;/stars&gt; &lt;description&gt;A schientific fiction&lt;/description&gt;&lt;/movie&gt; &lt;movie title=&quot;Trigun&quot;&gt; &lt;type&gt;Anime, Action&lt;/type&gt; &lt;format&gt;DVD&lt;/format&gt; &lt;episodes&gt;4&lt;/episodes&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;10&lt;/stars&gt; &lt;description&gt;Vash the Stampede!&lt;/description&gt;&lt;/movie&gt;&lt;movie title=&quot;Ishtar&quot;&gt; &lt;type&gt;Comedy&lt;/type&gt; &lt;format&gt;VHS&lt;/format&gt; &lt;rating&gt;PG&lt;/rating&gt; &lt;stars&gt;2&lt;/stars&gt; &lt;description&gt;Viewable boredom&lt;/description&gt;&lt;/movie&gt;&lt;/collection&gt; 使用sax解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#!/usr/bin/python# -*- coding: UTF-8 -*- import xml.sax class MovieHandler( xml.sax.ContentHandler ): def __init__(self): self.CurrentData = &quot;&quot; self.type = &quot;&quot; self.format = &quot;&quot; self.year = &quot;&quot; self.rating = &quot;&quot; self.stars = &quot;&quot; self.description = &quot;&quot; # 元素开始事件处理 def startElement(self, tag, attributes): self.CurrentData = tag if tag == &quot;movie&quot;: print &quot;*****Movie*****&quot; title = attributes[&quot;title&quot;] print &quot;Title:&quot;, title # 元素结束事件处理 def endElement(self, tag): if self.CurrentData == &quot;type&quot;: print &quot;Type:&quot;, self.type elif self.CurrentData == &quot;format&quot;: print &quot;Format:&quot;, self.format elif self.CurrentData == &quot;year&quot;: print &quot;Year:&quot;, self.year elif self.CurrentData == &quot;rating&quot;: print &quot;Rating:&quot;, self.rating elif self.CurrentData == &quot;stars&quot;: print &quot;Stars:&quot;, self.stars elif self.CurrentData == &quot;description&quot;: print &quot;Description:&quot;, self.description self.CurrentData = &quot;&quot; # 内容事件处理 def characters(self, content): if self.CurrentData == &quot;type&quot;: self.type = content elif self.CurrentData == &quot;format&quot;: self.format = content elif self.CurrentData == &quot;year&quot;: self.year = content elif self.CurrentData == &quot;rating&quot;: self.rating = content elif self.CurrentData == &quot;stars&quot;: self.stars = content elif self.CurrentData == &quot;description&quot;: self.description = content if ( __name__ == &quot;__main__&quot;): # 创建一个 XMLReader parser = xml.sax.make_parser() # turn off namepsaces parser.setFeature(xml.sax.handler.feature_namespaces, 0) # 重写 ContextHandler Handler = MovieHandler() parser.setContentHandler( Handler ) parser.parse(&quot;movies.xml&quot;) 使用xml.dom1234567891011121314151617181920212223242526272829#!/usr/bin/python# -*- coding: UTF-8 -*- from xml.dom.minidom import parseimport xml.dom.minidom # 使用minidom解析器打开 XML 文档DOMTree = xml.dom.minidom.parse(&quot;movies.xml&quot;)collection = DOMTree.documentElementif collection.hasAttribute(&quot;shelf&quot;): print &quot;Root element : %s&quot; % collection.getAttribute(&quot;shelf&quot;) # 在集合中获取所有电影movies = collection.getElementsByTagName(&quot;movie&quot;) # 打印每部电影的详细信息for movie in movies: print &quot;*****Movie*****&quot; if movie.hasAttribute(&quot;title&quot;): print &quot;Title: %s&quot; % movie.getAttribute(&quot;title&quot;) type = movie.getElementsByTagName(&apos;type&apos;)[0] print &quot;Type: %s&quot; % type.childNodes[0].data format = movie.getElementsByTagName(&apos;format&apos;)[0] print &quot;Format: %s&quot; % format.childNodes[0].data rating = movie.getElementsByTagName(&apos;rating&apos;)[0] print &quot;Rating: %s&quot; % rating.childNodes[0].data description = movie.getElementsByTagName(&apos;description&apos;)[0] print &quot;Description: %s&quot; % description.childNodes[0].data 操作excel 安装和引入openpyxl模块 12pip install openpyxlimport openpyxl 加载excel 123path = &apos;/home/lucas/test/python_excel/test.xlsx&apos;# 加载工作本workbook = openpyxl.load_workbook(path) 获取工作表 1sheet = workbook[&apos;Sheet1&apos;] 获取单元格的值 根据row和col的索引来遍历 123456data=&#123;&#125;for x in range(1,8): for y in range(1,3): cell = sheet.cell(row=x, column=y) if y != 1: data[x] = cell.value 根据起始单元格遍历 12345cells = sheet[&apos;A1&apos;:&apos;C1&apos;]for row in cells: for col in row: # 获取属性值 print(col.value) 写入和保存excel 12345678910# -*- coding: utf-8 -*-import openpyxlpath = &apos;/home/lucas/test/python_excel/test.xlsx&apos;wb = openpyxl.Workbook()# 创建一个 sheetsheet = wb.create_sheet(&apos;sheet1&apos;)# 写入文本形式sheet[&apos;A1&apos;] = &apos;12345&apos;wb.save(path) lxml版本升级 1pip install lxml --upgrade 操作csv 引入csv模块 1import csv 异常处理python提供了两个非常重要的功能来处理python程序在运行中出现的异常和错误: 异常处理 断言(Assertions) 捕获标准异常1234567891011#!/usr/bin/python# -*- coding: UTF-8 -*-try: fh = open(&quot;testfile&quot;, &quot;w&quot;) fh.write(&quot;这是一个测试文件，用于测试异常!!&quot;)except IOError: print &quot;Error: 没有找到文件或读取文件失败&quot;else: print &quot;内容写入文件成功&quot; fh.close() 自定义异常定义： 123class Networkerror(RuntimeError): def __init__(self, arg): self.args = arg 捕获： 1234try: raise Networkerror(&quot;Bad hostname&quot;)except Networkerror,e: print e.args 总结无","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"PYTHON","slug":"PYTHON","permalink":"https://lives.xtcgch.ink/tags/PYTHON/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【专项】 数据库之SQL优化","slug":"数据库之SQL优化-20200127","date":"2020-01-27T12:55:14.000Z","updated":"2021-10-10T14:43:55.096Z","comments":true,"path":"2020/01/27/数据库之SQL优化/","link":"","permalink":"https://lives.xtcgch.ink/2020/01/27/数据库之SQL优化/","excerpt":"摘要：SQL语句作为数据库和程序的交互语言，优秀的sql语句是理所当然的，但是很多人却不是很重视SQL语句，本文就是针对SQL的病句进行问题剖析，然后给出优化方案，以此来端正对SQL语句的态度。","text":"摘要：SQL语句作为数据库和程序的交互语言，优秀的sql语句是理所当然的，但是很多人却不是很重视SQL语句，本文就是针对SQL的病句进行问题剖析，然后给出优化方案，以此来端正对SQL语句的态度。 脑图暂无 一、常见案例1. 查询列发生隐式或显示的类型转换(1)描述 where 条件中的字符串没有使用引号 1不用引号的条件不会使用索引 (2)优化建议 查询列是什么字段类型，列的值就应该用什么字段类型，否则会导致发生类型转换而使用不到索引 对有索引的查询列不要使用函数或运算的操作，例如to_char(列)，列%10，列+10等 2. 对于查询频繁的列，并且列的选择性比较高，应当建立索引(1)描述 无 (2)优化建议 查询列建立索引 建索引原则，这个列的无重复值的数量和表的记录数越接近，说明选择性好，建的索引查询就越高效，比如主键，时间，身份证，手机号等 的重复值很高，根据值的分布，某个值的重复值却很少，而查询只查询这个值，这时候该字段就适合创建索引 3. 存在索引，实际执行的时候并未使用到(1)描述 如问题1 对于组合索引，where中并未按顺序进行查询 单表多条件查询时使用or，或者联表查询时的不合理使用 (2)优化建议 虽然查询的字段有索引，但是查询范围过大，导致使用不到索引，应该将范围拆分为更小的几段，然后再进行汇总 or条件改为in,否则用不到索引 模糊查询时，尽量使用后置%，否则使用不到索引 4. 表关联的字段需要有索引，尽量少用子查询(1)描述 (2)优化建议 关联的字段创建索引，并且将子查询改为表关联 另一个字段F_remark虽然重复值比较多，但是这个值的数量却很少，建索引对该查询有效 5. 索引字段进行模糊查询时，like ‘%%’会导致使用不到索引(1)描述 无 (2)优化建议 将模糊查询like %xxx% 语句改为 xxx% 6. 存在多个索引时，mysql错误的选择了索引(1)描述 (2)优化建议 改写原查询sql，加上force index(idx_agent_id) 强制使用F_agent_id索引 一般不推荐使用force index固定执行计划，因为数据是变化的，数据库内部会收集各种统计信息给出最优的执行计划，但是5.1版本做的不够好，在5.7版本得到了增强 7. 对于联合索引来说，要遵守最左前缀法则(1)描述 (2)优化建议 对于 index(a,b,c)复合索引，根据最左前缀规则，a,(a,b),(a,b,c)都可以使用到索引，而(b,c)不能使用到 为使用到索引，加上f_status条件，并将该列的所有值查出来 8.SQL语句中IN包含的值不应过多二、常见案例 单表查询时：联合索引中范围之后的索引将 会失效 单表查询时：联合索引中范围之后的索引将 会失效 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num is null可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：select id from t where num=0 应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 in 和 not in 也要慎用，否则会导致全表扫描，如：select id from t where num in(1,2,3)对于连续的数值，能用 between 就不要用 in 了：select id from t where num between 1 and 3 很多时候用 exists 代替 in 是一个好的选择：select num from a where num in(select num from b)用下面的语句替换：select num from a where exists(select 1 from b where num=a.num) 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效 尽量避免大事务操作，提高系统并发能力 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理 三、总结暂无","categories":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"},{"name":"SQL","slug":"SQL","permalink":"https://lives.xtcgch.ink/tags/SQL/"}],"keywords":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}]},{"title":"leetcode的经典题目","slug":"leetcode的经典题目-20190407","date":"2019-04-07T07:51:08.000Z","updated":"2021-10-02T13:34:55.249Z","comments":true,"path":"2019/04/07/leetcode的经典题目/","link":"","permalink":"https://lives.xtcgch.ink/2019/04/07/leetcode的经典题目/","excerpt":"摘要：本页主要摘录leetcode上面一些经典的题目！","text":"摘要：本页主要摘录leetcode上面一些经典的题目！ 基础知识类编程语言类网络相关数据库相关操作系统相关扩展点一扩展点二算法类","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"LEETCODE","slug":"LEETCODE","permalink":"https://lives.xtcgch.ink/tags/LEETCODE/"},{"name":"面试","slug":"面试","permalink":"https://lives.xtcgch.ink/tags/面试/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"画流程图","slug":"画流程图-20190407","date":"2019-04-07T04:30:06.000Z","updated":"2021-10-02T13:34:46.919Z","comments":true,"path":"2019/04/07/画流程图/","link":"","permalink":"https://lives.xtcgch.ink/2019/04/07/画流程图/","excerpt":"摘要：介绍流程图的一些知识！","text":"摘要：介绍流程图的一些知识！ 先从软件工程开始–&gt; 参考文档 目录 为何需要软件工程 过程模块与生命周期 项目计划与管理 需求分析 系统设计 关于对象 编写代码 程序测试 系统测试 系统提交 系统维护 产品，过程，资源评估 预测，处理和资源的改进 软件工程的前景 常用工具 drawio","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://lives.xtcgch.ink/tags/软件工程/"},{"name":"流程图","slug":"流程图","permalink":"https://lives.xtcgch.ink/tags/流程图/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"协程的介绍","slug":"协程的介绍-20190405","date":"2019-04-05T12:27:04.000Z","updated":"2021-11-01T06:10:51.632Z","comments":true,"path":"2019/04/05/协程的介绍/","link":"","permalink":"https://lives.xtcgch.ink/2019/04/05/协程的介绍/","excerpt":"摘要：非正式的协程学习笔记！","text":"摘要：非正式的协程学习笔记！ 简单介绍 协程，又称微线程，纤程。英文名Coroutine。 协程属于线程内的概念，脱离了线程就毫无意义。 一个线程可以有很多个协程，协程数受到文件描述符的限制。 协程是原子性的。 协程的切换属于用户态，即只有显示使用协程，cpu才会使用协程的方式来处理代码。 一个线程里的协程共享所有线程内的变量，且是独享，即每个协程获取到的线程变量值都是即时的数据，和线程使用进程内的公共变量不同，也即不需要加锁。 协程的切换是由IO事件来操控，只有当协程发生IO操作，或者协程处理完事件，才会发生协程的切换。 协程占有的资源量比线程小，且通常情况下协程间的切换对资源的消耗是比较小的，主要是因为协程切换时不会发生上下文的切换，cpu会根据偏移量来找到协程对应的栈位置，所以协程间的切换只是偏移量发生了改变，因此对资源的消耗量很小。 和线程比，在IO任务不处理具体事情时，线程会被挂起，但是协程会一直切换，会消耗一定的cpu资源，目前可测出的消耗率约为1%-2%。 语言层面 目前支持协程的编程语言主要有python，lua，C/C++ 应用场景 协程的特性是由IO事件来进行切换，因此在一些IO事件比较频繁的场景下运用，能够产生比较巨大的正面效果，如http/https请求，udp/tcp请求，数据库IO，文件IO，日志IO 一些协程库 libco 坑 1、锁在一个函数fun1()中有一个IO操作，如写日志（设定为一直阻塞），并且在写日志前进行加锁，这时可能会发生如下情况： 协程A获取锁，进行写日志IO操作 cpu切换协程B来运行 协程B视图获取锁，但是协程A未释放，因此协程B一直等待 由于协程A一直阻塞在写日志操作，因此协程B也一直阻塞，也不能被切换出去，造成了死锁 即使协程A未被阻塞，而是耗时比较长，那么协程B也只能等待，这种情况也会比较坑 2、socket 一些使用建议 在使用IO函数之前要先释放锁 使用最小粒度的锁","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"协程","slug":"协程","permalink":"https://lives.xtcgch.ink/tags/协程/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"使用hexo搭建github博客","slug":"使用hexo搭建github博客-20190402","date":"2019-03-31T09:24:36.000Z","updated":"2021-10-02T13:35:11.445Z","comments":true,"path":"2019/03/31/使用hexo搭建github博客/","link":"","permalink":"https://lives.xtcgch.ink/2019/03/31/使用hexo搭建github博客/","excerpt":"摘要：主要介绍利用hexo搭建个人的github博客！","text":"摘要：主要介绍利用hexo搭建个人的github博客！ 总体思路介绍1、创建和配置github仓库 这一步主要有2个作用 存放博客相关文件 能够建立本地git仓库和远程github仓库的连接，便于远程管理。这个功能还需要配置本地git和其他依赖环境 2、配置本地环境 这一步主要是配置git工具和hexo博客的环境 配置git和依赖的工具，主要是nodejs 搭建hexo博客环境 3、配置博客主题 hexo支持很多博客主题，这些主题可以从github上面去clone和update，对于假装很喜欢写博客的我来说，用得爽才是最好的 4、进行一些个性化的改造 就像对待自己女朋友一样，要把她变成私有的，烙上自己独特的印记，最常用的有配置域名啦，对主题进行配置啦，模板配置啦，一键部署啦，等等 各个步骤说明创建github仓库1、创建一个public的repos 2、设置启用https 部署本地环境1、安装git git可以把本地的博客文件commit到远程仓库，即对博客进行更新 2、创建ssh的rsa公钥和密钥，配置连接远程仓库的参数 本地git和远程仓库进行连接时，首先需要进行安全验证，目前使用ssh的rsa key来保证，远程仓库使用public key，本地使用private key 其次需要配置连接到哪个用户，哪个仓库，这就需要显示地指定目标地址 一般有2中配置方式：直接配置用户环境、配置文件信息 其中配置用户环境比较简单，但是可配置性也比较差 配置文件信息稍微复杂点，但是可配置性比较高，适合个性化配置，见后面说明 3、安装nodejs nodejs是管理hexo博客的主要工具，主要用到nodejs里面的npm，nodejs支持把markdown文件转为静态网页 同时npm也可以安装一些主题需要的模块 配置博客主题hexo的默认主题是landscape，我用的是snippet 在根目录的_config.yml文件里面可以指定要使用的主题，然后在generate阶段会去themes目录下寻找对应的主题 配置博客主题主要有2方面： 在根目录的配置文件中指定主题 在主题目录里面进行个性化配置 第二点的坑比较多，在配置snippet时，我遇到的坑有： 要安装ejs 模版引擎 、 Less CSS预编译语言，安装项目的依赖 要对根目录的_config.yml结构进行更改，还要拷贝package.json到根目录等等 修改url地址，这点无疑是最坑的，无论修改成github仓库地址还是域名 配置域名1、阿里云/腾讯/万网进行解析，添加CNAME记录即可 2、github仓库设置好域名，添加CNAME文件 常见问题1、hexo d 时出现错误 Error: ERROR: Permission to 原因：登录账号和push到仓库的账号不一致，要么配置错误，要么是存在多账号的问题 解决方法：使用配置文件的方式来进行登录和push 2、hexo d后 ERROR Deployer not found: git 原因：未指定hexo的发布工具 解决方法:1npm install --save hexo-deployer-git 具体步骤参考文章： 综合配置 snippet主题 账号的配置 1、创建和配置仓库略 2、安装和配置git安装：略 创建SSH KEY 12cd ~/.ssh/ssh-keygen -t rsa -f ~/.ssh/abc_rsa -C &quot;yourmail@xxx.com&quot; //abc为自定义名，常用github登录名 配置git连接到github仓库 配置文件 - 配置多个账号时要根据邮箱创建不同的SSH KEY1234567cd ~/.ssh/touch config# 账号名 abcHost abc.github.com # abc为github的登录账号名 HostName github.com User git IdentityFile ~/.ssh/abc_rsa 原理分析: ssh 客户端是通过类似 git@abc.github.com:abc/blog.git 的地址来识别使用本地的哪个私钥的，(abc是github登录名，blog是仓库名) 如果所有账号的 User 和 Host 都为 git 和 github.com，那么就只能使用一个私钥。所以要对User 和 Host 进行配置，让每个账号使用自己的 Host，每个 Host 的域名做 CNAME 解析到 github.com，如上面配置中的Host abc.github.com。 配置了别名之后，新的地址就是git@abc.github.com:abc/blog.git。这样 ssh 在连接时就可以区别不同的账号了。 github仓库添加SSH KEY 打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key： title： 内容：填abc_rsa.pub里面的公钥 在.ssh根目录下, 清空本地的 SSH 缓存，添加新的 SSH 密钥 到 SSH agent中 添加： 123cd ~/.sshssh-add -Dssh-add abc_rsa 验证新秘钥已经添加成功： 1ssh-add -l 使用环境变量配置时，输入指令, 验证配置是否成功: 1ssh -T git@github.com 使用配置文件时，输入指令, 验证配置是否成功: 1ssh -T git@abc.github.com 进入各自项目文件夹，单独设置用户名/邮箱 注意：如果有多个账号，建议使用局部的。 1234567# 取消全局 用户名/邮箱 配置git config –global –unset user.namegit config –global –unset user.email# 单独设置每个repo 用户名/邮箱git config user.name &quot;用户名&quot; //在config后加上--global即全局git config user.email &quot;邮箱&quot; 查看设置是否成功 1git config --list 在 hexo 配置文件_config.yml修改git地址 1234deploy: type: git repository: git@abc.github.com:abc/blog.github.io.git branch: master 3、安装和配置git 前提条件：安装nodejs 配置淘宝镜像：pm install -g cnpm –registry=https://registry.npm.taobao.org 安装:npm install -g hexo-cli 查看：hexo -version 初始化hexo框架 进入文件夹：hexo init 启动Hexo服务：hexo s 查看效果：localhost:4000 设置bat快捷命令文件 新建：123456@echo offecho Wait a minute ...D: &amp;&amp; cd D:\\github_workplace\\blog &amp;&amp; hexo n newecho Finished !start D:\\github_workplace\\blog\\source\\_postspause 发布：12345@echo offecho Wait a minute ...D: &amp;&amp; cd D:\\github_workplace\\blog &amp;&amp; hexo clean &amp;&amp; hexo g &amp;&amp; hexo decho Finished !pause 4、域名 在本地根目录的source文件夹下创建CNAME文件，输入域名，如：blog.abc.com github仓库的setting/GitHub Pages/Custom domain一栏输入域名 在阿里云/腾讯/万网添加域名解析记录CNAME，主机记录为blog，记录值是abc.github.io 温馨提示：配置域名后，几乎可以立即使用http的方式进行访问，但如果要启用https，则可以泡一杯咖啡，耐心等待5分钟，等待https证书的传输等过程完成，然后就可以进行访问了 snippet主题设置唉，坑 扩展：个性化的设置1、迁移到另一台电脑或重装系统后的配置","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"https://lives.xtcgch.ink/tags/HEXO/"},{"name":"GITHUB","slug":"GITHUB","permalink":"https://lives.xtcgch.ink/tags/GITHUB/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"Linux下的一些小知识","slug":"Linux下的一些小知识-20190319","date":"2019-03-19T15:54:45.000Z","updated":"2021-10-02T13:35:20.475Z","comments":true,"path":"2019/03/19/Linux下的一些小知识/","link":"","permalink":"https://lives.xtcgch.ink/2019/03/19/Linux下的一些小知识/","excerpt":"摘要：专治各种水土不服","text":"摘要：专治各种水土不服 linu系统介绍1、内核 2、Linux文件结构 /bin：bin 是 Binaries (二进制文件) 的缩写, 这个目录存放着最经常使用的命令。 /boot：这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ：dev 是 Device(设备) 的缩写, 该目录下存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。 /etc：etc 是 Etcetera(等等) 的缩写,这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home：用户的主目录，在 Linux 中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的，如上图中的 alice、bob 和 eve。 /lib：lib 是 Library(库) 的缩写这个目录里存放着系统最基本的动态连接共享库，其作用类似于 Windows 里的 DLL 文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media：linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。 /mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在 /mnt/ 上，然后进入该目录就可以查看光驱里的内容了。 /opt：opt 是 optional(可选) 的缩写，这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc：proc 是 Processes(进程) 的缩写，/proc 是一种伪文件系统（也即虚拟文件系统），存储的是当前内核运行状态的一系列特殊文件，这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，使别人无法ping你的机器： /root：该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin：s 就是 Super User 的意思，是 Superuser Binaries (超级用户的二进制文件) 的缩写，这里存放的是系统管理员使用的系统管理程序。 /selinux： 这个目录是 Redhat/CentOS 所特有的目录，Selinux 是一个安全机制，类似于 windows 的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv： 该目录存放一些服务启动之后需要提取的数据。 /sys：这是 Linux2.6 内核的一个很大的变化。该目录下安装了 2.6 内核中新出现的一个文件系统 sysfs 。 sysfs 文件系统集成了下面3种文件系统的信息：针对进程信息的 proc 文件系统、针对设备的 devfs 文件系统以及针对伪终端的 devpts 文件系统。 该文件系统是内核设备树的一个直观反映。 当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。 /tmp： tmp 是 temporary(临时) 的缩写这个目录是用来存放一些临时文件的。 /usr： usr 是 unix shared resources(共享资源) 的缩写，这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于 windows 下的 program files 目录。 /usr/bin：系统用户使用的应用程序。 /usr/sbin：超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src：内核源代码默认的放置目录。 /var：var 是 variable(变量) 的缩写，这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 /run：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。 文件编码问题在windows系统中生成的文件，在Linux系统中会出现各种格式方面的问题，比如cpp文件的编译错误 查看文件编码格式：set fileencoding设置文件编码格式：set fileencoding = utf8","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"Nginx中FastCGI的解读","slug":"Nginx中FastCGI的解读-20190309","date":"2019-03-09T15:19:37.000Z","updated":"2021-10-02T13:35:29.520Z","comments":true,"path":"2019/03/09/Ngix中FastCGI的解读/","link":"","permalink":"https://lives.xtcgch.ink/2019/03/09/Ngix中FastCGI的解读/","excerpt":"摘要：本文主要是阅读ngix中fastcgi的源码来了解c++对http请求体的解析，以及对回复包的封装过程。","text":"摘要：本文主要是阅读ngix中fastcgi的源码来了解c++对http请求体的解析，以及对回复包的封装过程。 1.初识FastCGI协议 1.1消息头 FastCGI定义了多种类型的消息；nginx对FastCGI消息类型定义如下： 12345678#define NGX_HTTP_FASTCGI_BEGIN_REQUEST 1#define NGX_HTTP_FASTCGI_ABORT_REQUEST 2#define NGX_HTTP_FASTCGI_END_REQUEST 3#define NGX_HTTP_FASTCGI_PARAMS 4#define NGX_HTTP_FASTCGI_STDIN 5#define NGX_HTTP_FASTCGI_STDOUT 6#define NGX_HTTP_FASTCGI_STDERR 7#define NGX_HTTP_FASTCGI_DATA 8 一般情况下，最先发送的是BEGIN_REQUEST类型的消息，然后是PARAMS和STDIN类型的消息； 当FastCGI响应处理完后，将发送STDOUT和STDERR类型的消息，最后以END_REQUEST表示请求的结束。 FastCGI定义了一个统一结构的8个字节消息头，用来标识每个消息的消息体，以及实现消息数据的分割。结构体定义如下： 12345678910typedef struct &#123; u_char version; //FastCGI协议版本 u_char type; //消息类型 u_char request_id_hi; //请求ID u_char request_id_lo; u_char content_length_hi; //内容 u_char content_length_lo; u_char padding_length; //内容填充长度 u_char reserved; //保留&#125; ngx_http_fastcgi_header_t; 我们看到请求ID与内容长度分别用两个u_char存储，实际结果的计算方法如下：12requestId = (request_id_hi &lt;&lt; 8) + request_id_lo;contentLength = (content_length_hi &lt;&lt; 8) + content_length_lo; 消息体的长度始终是8字节的整数倍，当实际内容长度不足时，需要填充若干字节；填充代码如下所示： 12padding = 8 - len % 8;padding = (padding == 8) ? 0 : padding; 1.2消息体举例 BEGIN_REQUEST类型的消息标识FastCGI请求的开始，结构固定，定义如下：123456typedef struct &#123; u_char role_hi; //标记FastCGI应用应该扮演的角色 u_char role_lo; u_char flags; u_char reserved[5];&#125; ngx_http_fastcgi_begin_request_t; 角色同样使用两个u_char存储，计算方法为：1role = (role_hi &lt;&lt; 8) + role_lo; 最常用的是响应器(Responder)角色，FastCGI应用接收所有与HTTP请求相关的信息，并产生一个HTTP响应。 nginx配置文件中，fastcgi_param指令配置的若干参数，以及HTTP请求的消息头，都是通过FCGI_PARAMS类型的消息传递的，此消息就是若干个名—值对（此名—值对在php中可以通过$_SERVER[ ]获取）； 传输格式为nameLength+valueLength+name+value。 为了节省空间，对于0~127长度的值，Length使用了一个char来表示，第一位为0，对于大于127的长度的值，Length使用了4个char来表示，第一位为1； Length字段编码的逻辑如下：123456789if (val_len &gt; 127) &#123; *b-&gt;last++ = (u_char) (((val_len &gt;&gt; 24) &amp; 0x7f) | 0x80); *b-&gt;last++ = (u_char) ((val_len &gt;&gt; 16) &amp; 0xff); *b-&gt;last++ = (u_char) ((val_len &gt;&gt; 8) &amp; 0xff); *b-&gt;last++ = (u_char) (val_len &amp; 0xff); &#125; else &#123; *b-&gt;last++ = (u_char) val_len;&#125; 2.基础知识 2.1 FastCGI配置 代码中搜索ngx_http_fastcgi_commands，查看fastcgi模块提供的配置指令； 12345678910111213141516static ngx_command_t ngx_http_fastcgi_commands[] = &#123; &#123; ngx_string(&quot;fastcgi_pass&quot;), NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1, //只能出现在location块中 ngx_http_fastcgi_pass, NGX_HTTP_LOC_CONF_OFFSET, 0, NULL &#125;, &#123; ngx_string(&quot;fastcgi_param&quot;), NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE23, //可以出现在http配置块、server配置块、location配置块中 ngx_http_upstream_param_set_slot, NGX_HTTP_LOC_CONF_OFFSET, offsetof(ngx_http_fastcgi_loc_conf_t, params_source), //ngx_http_fastcgi_loc_conf_t结构的params_source字段是存储配置参数的array， NULL &#125;, …………&#125; fastcgi_pass指令用于配置上游FastCGI应用的ip:port，ngx_http_fastcgi_pass方法解析此指令（设置handler为ngx_http_fastcgi_handler方法，命中当前location规则的HTTP请求，请求处理的内容产生阶段会调用此handler）； fastcgi_param用于配置nginx向FastCGI应用传递的参数，在php中，我们可以通过$_SERVER[&quot; &quot;]获取这些参数； 解析fastcgi_param配置的代码实现如下： 123456789101112131415161718char * ngx_http_upstream_param_set_slot(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)&#123; a = (ngx_array_t **) (p + cmd-&gt;offset); //ngx_http_fastcgi_loc_conf_t结构首地址加params_source字段的偏移 param = ngx_array_push(*a); value = cf-&gt;args-&gt;elts; param-&gt;key = value[1]; param-&gt;value = value[2]; param-&gt;skip_empty = 0; if (cf-&gt;args-&gt;nelts == 4) &#123; //if_not_empty用于配置参数是否必传（如果配置，当值为空时不会传向FastCGI应用传递此参数） if (ngx_strcmp(value[3].data, &quot;if_not_empty&quot;) != 0) &#123; return NGX_CONF_ERROR; &#125; param-&gt;skip_empty = 1; &#125; return NGX_CONF_OK;&#125; 2.2FastCGI配置预处理 fastcgi_param配置的所有参数会会存储在ngx_http_fastcgi_loc_conf_t结构体的params_source字段； nginx为了方便生成fastcgi请求数据，会提前对params_source做一些预处理，预先初始化号每个名—值对的长度以及数据拷贝方法等； 2.1节查看fastcgi模块提供的配置指令时发现，某些配置指令出现在location配置块，有些配置却可以出现http配置块、server配置块和location配置块；即可能出现同一个指令同时出现在好几个配置块中，此时如何解析配置？ 对于这些配置指令，nginx最终会执行一个merge操作，合并多个配置为一个；观察nginx的HTTP模块，大多模块都会存在一个merge_loc_conf字段（函数指针），用于merge配置； fastcgi模块的merge操作由ngx_http_fastcgi_merge_loc_conf完成，其同时对params_source进行了一些预处理；代码如下： 123456789101112131415static char * ngx_http_fastcgi_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child)&#123; ngx_conf_merge_msec_value(conf-&gt;upstream.connect_timeout, prev-&gt;upstream.connect_timeout, 60000); ngx_conf_merge_value(conf-&gt;upstream.pass_request_headers, prev-&gt;upstream.pass_request_headers, 1); //配置HTTP头部是否传递给FastCGI应用，默认为1 ngx_conf_merge_value(conf-&gt;upstream.pass_request_body, prev-&gt;upstream.pass_request_body, 1); //配置HTTP body是否传递给FastCGI应用，默认为1 ………… if (ngx_http_fastcgi_merge_params(cf, conf, prev) != NGX_OK) &#123; //重点，merger并预处理传递给FastCGI应用的参数 return NGX_CONF_ERROR; &#125;&#125; ngx_http_fastcgi_merge_params方法主要params_source做了一些预处理，主要处理逻辑如下： 注意：配置参数的名称以HTTP_开始时，此参数可能还是HTTP请求头，需要记录这些参数，以便传递HTTP请求头时排除掉。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758static ngx_int_t ngx_http_fastcgi_merge_params(ngx_conf_t *cf, ngx_http_fastcgi_loc_conf_t *conf, ngx_http_fastcgi_loc_conf_t *prev)&#123; if (conf-&gt;params_source) &#123; src = conf-&gt;params_source-&gt;elts; nsrc = conf-&gt;params_source-&gt;nelts; &#125; conf-&gt;params_len = ngx_array_create(cf-&gt;pool, 64, 1); //params_len用于计算参数名—值的长度 conf-&gt;params = ngx_array_create(cf-&gt;pool, 512, 1); //params用于名—值对数据内容的处理（拷贝） if (ngx_array_init(&amp;headers_names, cf-&gt;temp_pool, 4, sizeof(ngx_hash_key_t)) != NGX_OK)&#123; //存储以HTTP_开始的配置参数，hash表 return NGX_ERROR; &#125; for (i = 0; i &lt; nsrc; i++) &#123; //以HTTP_开始，存储在headers_names hash表 if (src[i].key.len &gt; sizeof(&quot;HTTP_&quot;) - 1 &amp;&amp; ngx_strncmp(src[i].key.data, &quot;HTTP_&quot;, sizeof(&quot;HTTP_&quot;) - 1) == 0)&#123; hk = ngx_array_push(&amp;headers_names); hk-&gt;key.len = src[i].key.len - 5; hk-&gt;key.data = src[i].key.data + 5; hk-&gt;key_hash = ngx_hash_key_lc(hk-&gt;key.data, hk-&gt;key.len); hk-&gt;value = (void *) 1; &#125; //ngx_http_script_copy_code_t结构体包含两个字段：code函数指针，用于计算参数名称的长度（方法内部直接返回了了len字段）；len是参数名称的长度 copy = ngx_array_push_n(conf-&gt;params_len, sizeof(ngx_http_script_copy_code_t)); copy-&gt;code = (ngx_http_script_code_pt) ngx_http_script_copy_len_code; copy-&gt;len = src[i].key.len; //这里的len表示参数是否必传；对于非必传参数，当此参数的值为空时，可以不传递此参数；（ngx_http_script_copy_len_code方法内部直接返回了了len字段，即skip_empty） copy = ngx_array_push_n(conf-&gt;params_len, sizeof(ngx_http_script_copy_code_t)); copy-&gt;code = (ngx_http_script_code_pt) ngx_http_script_copy_len_code; copy-&gt;len = src[i].skip_empty; //ngx_http_script_copy_code_t结构体包含两个字段：code函数指针，实现参数名称内容的拷贝；len数参数名称的长度 //空间大小为ngx_http_script_copy_code_t结构体长度，加参数名称的长度；最后再8字节对齐 size = (sizeof(ngx_http_script_copy_code_t) + src[i].key.len + sizeof(uintptr_t) - 1) &amp; ~(sizeof(uintptr_t) - 1); copy = ngx_array_push_n(conf-&gt;params, size); copy-&gt;code = ngx_http_script_copy_code; copy-&gt;len = src[i].key.len; //拷贝数据 p = (u_char *) copy + sizeof(ngx_http_script_copy_code_t); ngx_memcpy(p, src[i].key.data, src[i].key.len); //params_len与params分别存储NULL，以实现存储空间的分隔；及参数与参数之间使用NULL进行隔离； code = ngx_array_push_n(conf-&gt;params_len, sizeof(uintptr_t)); *code = (uintptr_t) NULL; code = ngx_array_push_n(conf-&gt;params, sizeof(uintptr_t)); *code = (uintptr_t) NULL; &#125; conf-&gt;header_params = headers_names.nelts; //以HTTP_开始的参数存储在conf的header_params与headers_hash字段 hash.hash = &amp;conf-&gt;headers_hash; …… return ngx_hash_init(&amp;hash, headers_names.elts, headers_names.nelts); &#125; 根据上面的代码逻辑，很容易画出params_len与params的内部存储结构： 问题：参数是名—值对，这里的代码只对参数名称进行了预处理，参数的值呢？参数的值应该与请求相对应的，在解析配置文件时，并没有请求对应的信息，如何预处理参数的值呢？ 一般fastcgi的参数是以下这些配置：12345fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_method;fastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length 参数的值其实就是nginx提供的一系列可以直接使用变量（在ngx_http_variable.c文件中查找ngx_http_core_variables数组，即nginx提供的变量），每个变量都有一个索引值； 预处理fastcgi的配置参数时，其实只需要初始化参数值对应的变量索引即可；（注意参数的值可能是由多个nginx变量组合而成） 注意到ngx_http_fastcgi_merge_params方法中还有以下一段代码： 1234567891011for (i = 0; i &lt; nsrc; i++) &#123; sc.cf = cf; sc.source = &amp;src[i].value; sc.flushes = &amp;conf-&gt;flushes; sc.lengths = &amp;conf-&gt;params_len; sc.values = &amp;conf-&gt;params; if (ngx_http_script_compile(&amp;sc) != NGX_OK) &#123; return NGX_ERROR; &#125;&#125; 我们看到sc的这些字段values（params）、lengths（params_len）、source（src[i].value，即参数的值）；ngx_http_script_compile可以对params和params_len字段进行修改；其实现如下： 12345678910111213141516171819202122232425262728293031ngx_int_t ngx_http_script_compile(ngx_http_script_compile_t *sc)&#123; for (i = 0; i &lt; sc-&gt;source-&gt;len; /* void */ ) &#123; //针对$document_root$fastcgi_script_name这种配置，会执行两次 if (sc-&gt;source-&gt;data[i] == &apos;$&apos;) &#123; if (ngx_http_script_add_var_code(sc, &amp;name) != NGX_OK) &#123; //name是变量名称 return NGX_ERROR; &#125; &#125; &#125;&#125; //同一个参数，值可能由多个变量组合而成，同一个参数可能会调用此方法多次static ngx_int_t ngx_http_script_add_var_code(ngx_http_script_compile_t *sc, ngx_str_t *name)&#123; index = ngx_http_get_variable_index(sc-&gt;cf, name); //获取变量的索引 //ngx_http_script_var_code_t结构体包含两个字段：code函数指针，计算为变量长度（方法内部查找索引为index的变量，返回其长度）；index为变量索引 code = ngx_http_script_add_code(*sc-&gt;lengths, sizeof(ngx_http_script_var_code_t), NULL); //存储到lengths，即params_len code-&gt;code = (ngx_http_script_code_pt) ngx_http_script_copy_var_len_code; code-&gt;index = (uintptr_t) index; //ngx_http_script_var_code_t结构体包含两个字段：code函数指针，拷贝变量内容（方法内部查找索引为index的变量，拷贝变量内容）；index为变量索引 code = ngx_http_script_add_code(*sc-&gt;values, sizeof(ngx_http_script_var_code_t), &amp;sc-&gt;main); //存储到values，即params code-&gt;code = ngx_http_script_copy_var_code; code-&gt;index = (uintptr_t) index; return NGX_OK;&#125; 最终params_len与params的内部存储结构入下图： 3.构造FastCGI请求方法ngx_http_fastcgi_create_request创建FastCGI请求，初始化请求内容（包括BEGIN_REQUEST、PARAMS和STDIN类型的请求消息）； 3.1FastCGI请求结构FastCGI应用即为nginx的upstream，输出缓冲区的类型为ngx_chain_t，是由多个buf组成的链表 1234struct ngx_chain_s &#123; ngx_buf_t *buf; ngx_chain_t *next;&#125;; nginx将FastCGI请求分为三个部分，由三个buf链成一个ngx_chain_s；nginx构造的FastCGI请求结构如下图所示； 其中第一部分主要包括fastcgi_param配置的参数以及HTTP请求的header，其他内容固定不变；第二部分是HTTP请求的body，其buf在解析HTTP请求时已经初始化好了，此处只需要将此buf添加到ngx_chain_s链中即可；第三部分内容固定； 3.2 计算请求第一部分长度为第一部分分配buf时，首先需要计算buf所需空间的大小；第一部分空间分为fastcgi_param参数与HTTP请求header；计算方法见下文： 1）计算fastcgi_param参数所需空间大小：1234567891011121314151617181920212223242526272829if (flcf-&gt;params_len) &#123; ngx_memzero(&amp;le, sizeof(ngx_http_script_engine_t)); ngx_http_script_flush_no_cacheable_variables(r, flcf-&gt;flushes); le.flushed = 1; le.ip = flcf-&gt;params_len-&gt;elts; //le.ip即为params_len存储的元素 le.request = r; while (*(uintptr_t *) le.ip) &#123; //循环计算索引参数key与value长度之和 lcode = *(ngx_http_script_len_code_pt *) le.ip; //key长度，lcode指向方法ngx_http_script_copy_len_code key_len = lcode(&amp;le); lcode = *(ngx_http_script_len_code_pt *) le.ip; //是否必传，lcode指向方法ngx_http_script_copy_len_code skip_empty = lcode(&amp;le); for (val_len = 0; *(uintptr_t *) le.ip; val_len += lcode(&amp;le)) &#123; //value长度，lcode指向方法ngx_http_script_copy_var_len_code（注意value可能又多个值组合而成） lcode = *(ngx_http_script_len_code_pt *) le.ip; &#125; le.ip += sizeof(uintptr_t); //跳参数之间分割的NULL if (skip_empty &amp;&amp; val_len == 0) &#123; //非必传参数，值为空时可跳过 continue; &#125; len += 1 + key_len + ((val_len &gt; 127) ? 4 : 1) + val_len; &#125;&#125; 2）HTTP请求header所需空间大小 1234567891011121314151617181920212223242526272829303132333435363738if (flcf-&gt;upstream.pass_request_headers) &#123; //是否需要向FastCGI应用传递header part = &amp;r-&gt;headers_in.headers.part; header = part-&gt;elts; for (i = 0; /* void */; i++) &#123; //header_params记录fastcgi_param是否配置了以HTTP_开始的参数，headers_hash存储此种类型的配置参数 if (flcf-&gt;header_params) &#123; for (n = 0; n &lt; header[i].key.len; n++) &#123; ch = header[i].key.data[n]; if (ch &gt;= &apos;A&apos; &amp;&amp; ch &lt;= &apos;Z&apos;) &#123; ch |= 0x20; &#125; else if (ch == &apos;-&apos;) &#123; ch = &apos;_&apos;; &#125; hash = ngx_hash(hash, ch); lowcase_key[n] = ch; &#125; if (ngx_hash_find(&amp;flcf-&gt;headers_hash, hash, lowcase_key, n)) &#123; //查询此HTTP请求头是否已经由fastcgi_param指令配置；有则忽略此HTTP请求头 ignored[header_params++] = &amp;header[i]; continue; &#125; n += sizeof(&quot;HTTP_&quot;) - 1; //请求头添加HTTP_前缀（n已经累加到header[i].key.len了） &#125; else &#123; n = sizeof(&quot;HTTP_&quot;) - 1 + header[i].key.len; //请求头添加HTTP_前缀 &#125; len += ((n &gt; 127) ? 4 : 1) + ((header[i].value.len &gt; 127) ? 4 : 1) + n + header[i].value.len; &#125;&#125; 3）创建第一部分buf 1234567891011121314151617181920if (len &gt; 65535) &#123; return NGX_ERROR;&#125; padding = 8 - len % 8;padding = (padding == 8) ? 0 : padding; size = sizeof(ngx_http_fastcgi_header_t) + sizeof(ngx_http_fastcgi_begin_request_t) + sizeof(ngx_http_fastcgi_header_t) /* NGX_HTTP_FASTCGI_PARAMS */ + len + padding + sizeof(ngx_http_fastcgi_header_t) /* NGX_HTTP_FASTCGI_PARAMS */ + sizeof(ngx_http_fastcgi_header_t); /* NGX_HTTP_FASTCGI_STDIN */ b = ngx_create_temp_buf(r-&gt;pool, size);cl = ngx_alloc_chain_link(r-&gt;pool);cl-&gt;buf = b; 3.3填充请求第一部分nginx的缓冲区buf主要关注以下四个字段：12345struct ngx_buf_s &#123; u_char *pos; //当buf所指向的数据在内存里的时候，pos指向的是这段数据开始的位置 u_char *last; //当buf所指向的数据在内存里的时候，last指向的是这段数据结束的位置 off_t file_pos; //当buf所指向的数据是在文件里的时候，file_pos指向的是这段数据的开始位置在文件中的偏移量 off_t file_last;//当buf所指向的数据是在文件里的时候，file_last指向的是这段数据的结束位置在文件中的偏移量 1）填充fastcgi_param参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445if (flcf-&gt;params_len) &#123; e.ip = flcf-&gt;params-&gt;elts; //e.ip是params e.pos = b-&gt;last; le.ip = flcf-&gt;params_len-&gt;elts; ////le.ip是params_len while (*(uintptr_t *) le.ip) &#123; lcode = *(ngx_http_script_len_code_pt *) le.ip; //key的长度 key_len = (u_char) lcode(&amp;le); lcode = *(ngx_http_script_len_code_pt *) le.ip; //是否必传 skip_empty = lcode(&amp;le); for (val_len = 0; *(uintptr_t *) le.ip; val_len += lcode(&amp;le)) &#123; //value的长度 lcode = *(ngx_http_script_len_code_pt *) le.ip; &#125; le.ip += sizeof(uintptr_t); if (skip_empty &amp;&amp; val_len == 0) &#123; //跳过 ………… &#125; *e.pos++ = (u_char) key_len; //填充key_len //填充value_len if (val_len &gt; 127) &#123; *e.pos++ = (u_char) (((val_len &gt;&gt; 24) &amp; 0x7f) | 0x80); *e.pos++ = (u_char) ((val_len &gt;&gt; 16) &amp; 0xff); *e.pos++ = (u_char) ((val_len &gt;&gt; 8) &amp; 0xff); *e.pos++ = (u_char) (val_len &amp; 0xff); &#125; else &#123; *e.pos++ = (u_char) val_len; &#125; //填充key和value的数据内容；key的填充方法为ngx_http_script_copy_code，value的填充方法ngx_http_script_copy_var_code， while (*(uintptr_t *) e.ip) &#123; code = *(ngx_http_script_code_pt *) e.ip; code((ngx_http_script_engine_t *) &amp;e); &#125; e.ip += sizeof(uintptr_t); //跳过参数之间分割的NULL &#125; b-&gt;last = e.pos;&#125; 2）填充HTTP请求头 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455if (flcf-&gt;upstream.pass_request_headers) &#123; part = &amp;r-&gt;headers_in.headers.part; header = part-&gt;elts; for (i = 0; /* void */; i++) &#123; for (n = 0; n &lt; header_params; n++) &#123; //上一步计算长度时，会记录跳过的header在ignored；填充阶段直接跳过 if (&amp;header[i] == ignored[n]) &#123; goto next; &#125; &#125; key_len = sizeof(&quot;HTTP_&quot;) - 1 + header[i].key.len; //填充key长度 if (key_len &gt; 127) &#123; *b-&gt;last++ = (u_char) (((key_len &gt;&gt; 24) &amp; 0x7f) | 0x80); *b-&gt;last++ = (u_char) ((key_len &gt;&gt; 16) &amp; 0xff); *b-&gt;last++ = (u_char) ((key_len &gt;&gt; 8) &amp; 0xff); *b-&gt;last++ = (u_char) (key_len &amp; 0xff); &#125; else &#123; *b-&gt;last++ = (u_char) key_len; &#125; val_len = header[i].value.len; //填充value长度 if (val_len &gt; 127) &#123; *b-&gt;last++ = (u_char) (((val_len &gt;&gt; 24) &amp; 0x7f) | 0x80); *b-&gt;last++ = (u_char) ((val_len &gt;&gt; 16) &amp; 0xff); *b-&gt;last++ = (u_char) ((val_len &gt;&gt; 8) &amp; 0xff); *b-&gt;last++ = (u_char) (val_len &amp; 0xff); &#125; else &#123; *b-&gt;last++ = (u_char) val_len; &#125; b-&gt;last = ngx_cpymem(b-&gt;last, &quot;HTTP_&quot;, sizeof(&quot;HTTP_&quot;) - 1); //填充HTTP_前缀 for (n = 0; n &lt; header[i].key.len; n++) &#123; //填充key数据内容 ch = header[i].key.data[n]; if (ch &gt;= &apos;a&apos; &amp;&amp; ch &lt;= &apos;z&apos;) &#123; ch &amp;= ~0x20; &#125; else if (ch == &apos;-&apos;) &#123; ch = &apos;_&apos;; &#125; *b-&gt;last++ = ch; &#125; b-&gt;last = ngx_copy(b-&gt;last, header[i].value.data, val_len); //填充value数据内容 next: continue; &#125;&#125; 3.4填充请求第二三部分HTTP请求的body同样存储在ngx_chain_t结构中，nginx需要遍历链表的所有buf，构造fastcgi的请求数据； 注意：nginx构造fastcgi请求时，第二部分请求（http_body）的长度最长为32K，当超过此限制时，HTTP请求体会被分割为多个http_body请求；入下图所示： 12345678910111213141516171819202122232425262728do &#123; b = ngx_alloc_buf(r-&gt;pool); b-&gt;pos = pos; pos += 32 * 1024; if (pos &gt;= body-&gt;buf-&gt;last) &#123; //数据小于32k，next赋值为1，结束while循环；否则就切割为了32K大小的数据包 pos = body-&gt;buf-&gt;last; next = 1; &#125; b-&gt;last = pos; len = (ngx_uint_t) (pos - b-&gt;pos); padding = 8 - len % 8; padding = (padding == 8) ? 0 : padding; cl-&gt;next = ngx_alloc_chain_link(r-&gt;pool); cl = cl-&gt;next; //添加http_body请求包到buf链表中 cl-&gt;buf = b; ………… b = ngx_create_temp_buf(r-&gt;pool, sizeof(ngx_http_fastcgi_header_t) + padding); cl-&gt;next = ngx_alloc_chain_link(r-&gt;pool); cl = cl-&gt;next; //添加padding与header请求包到buf链表中 cl-&gt;buf = b; &#125; while (!next); 实战4.1配置nginx配置如下： 12345678910111213141516171819202122232425http&#123; ………… fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; server &#123; listen 80; server_name localhost; root /home/xiaoju; index index.php index.html; location / &#123; fastcgi_index index.php; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; &#125; &#125;&#125; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_method;fastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length; 编写PHP脚本，只是简单的将post入参返回即可：123456&lt;?phpforeach($_POST as $key=&gt;$v)&#123; $ret[&apos;ret-&apos;.$key] = &apos;ret-&apos;.$v;&#125;echo json_encode($ret); 4.2FastCGI请求包我们GDB nginx worker进程； 查看FastCGI请求参数，在ngx_http_fastcgi_create_request方法添加断点，执行到函数最后一行（此时请求数据已经构造完成），输出数据存储在表达式r-&gt;upstream-&gt;request_bufs表示的缓冲区； 查看FastCGI应用（php-fpm）返回的数据，在ngx_http_fastcgi_process_record方法添加断点，方法入参ngx_http_fastcgi_ctx_t的pos和last分别指向读入数据的开始与结尾，此方法杜泽解析读入数据； 添加断点如下： 123456789Num Type Disp Enb Address What1 breakpoint keep y 0x0000000000418f05 in ngx_process_events_and_timers at src/event/ngx_event.c:203 inf 3, 2, 1 breakpoint already hit 17 times2 breakpoint keep y 0x000000000045b7fa in ngx_http_fastcgi_create_request at src/http/modules/ngx_http_fastcgi_module.c:735 inf 3, 2, 1 breakpoint already hit 4 times3 breakpoint keep y 0x000000000045c2af in ngx_http_fastcgi_create_request at src/http/modules/ngx_http_fastcgi_module.c:1190 inf 3, 2, 1 breakpoint already hit 4 times4 breakpoint keep y 0x000000000045a573 in ngx_http_fastcgi_process_record at src/http/modules/ngx_http_fastcgi_module.c:2145 inf 3, 2, 1 breakpoint already hit 1 time 执行到ngx_http_fastcgi_create_request函数结尾（断点3），打印r-&gt;upstream-&gt;request_bufs三个buf： 注意：gdb使用命令p打印字符串时，需设置set print element 0才不会省略部分字符串，否则字符串不会打印完全；@符号表示打印多少个字符（fastcgi请求时二进制数据，不能依据\\0判断结尾）；字符串显示时，显示‘\\222’时，为8进制表示，需转换为10进制计算才行；12345678910111213141516171819202122232425262728293031323334353637383940(gdb) p *r-&gt;upstream-&gt;request_bufs-&gt;buf-&gt;pos@1000$18 =\\001\\001\\000\\001\\000\\b\\000\\000 //8字节头部，type=1（BEGIN_REQUEST）\\000\\001\\000\\000\\000\\000\\000\\000 //8字节BEGIN_REQUEST数据包\\001\\004\\000\\001\\002\\222\\006\\000 //8字节头部，type=4（PARAMS），数据内容长度=2*256+146=658(不是8字节整数倍，需要填充6个字节)\\017\\025SCRIPT_FILENAME/home/xiaoju/test.php //key-value，格式为：keylen+valuelen+key+value\\f\\000QUERY_STRING\\016\\004REQUEST_METHODPOST\\f!CONTENT_TYPEapplication/x-www-form-urlencoded\\016\\002CONTENT_LENGTH19\\v\\tSCRIPT_NAME/test.php\\v\\nREQUEST_URI//test.php\\f\\tDOCUMENT_URI/test.php\\r\\fDOCUMENT_ROOT/home/xiaoju\\017\\bSERVER_PROTOCOLHTTP/1.1\\021\\aGATEWAY_INTERFACECGI/1.1\\017\\vSERVER_SOFTWAREnginx/1.6.2\\v\\tREMOTE_ADDR127.0.0.1\\v\\005REMOTE_PORT54276\\v\\tSERVER_ADDR127.0.0.1\\v\\002SERVER_PORT80\\v\\tSERVER_NAMElocalhost\\017\\003REDIRECT_STATUS200\\017dHTTP_USER_AGENTcurl/7.19.7 (x86_64-redhat-linux-gnu) libcurl/7.19.7 NSS/3.27.1 zlib/1.2.3 libidn/1.18 libssh2/1.4.2\\t\\tHTTP_HOSTlocalhost\\v\\003HTTP_ACCEPT*/*\\023\\002HTTP_CONTENT_LENGTH19\\021!HTTP_CONTENT_TYPEapplication/x-www-form-urlencoded\\000\\000\\000\\000\\000\\000 //6字节内容填充\\001\\004\\000\\001\\000\\000\\000\\000 //8字节头部，type=4（PARAMS），表示PARAMS请求结束\\001\\005\\000\\001\\000\\023\\005\\000 //8字节头部，type=5（STDIN），请求体数据长度19个字节 (gdb) p *r-&gt;upstream-&gt;request_bufs-&gt;next-&gt;buf-&gt;pos@20$19 = &quot;name=hello&amp;gender=1&quot; //HTTP请求体，长度19字节，需填充5个字节 (gdb) p *r-&gt;upstream-&gt;request_bufs-&gt;next-&gt;next-&gt;buf-&gt;pos@20$20 =\\000\\000\\000\\000\\000 //5字节填充\\001\\005\\000\\001\\000\\000\\000 //8字节头部，type=5（STDIN），表示STDIN请求结束 执行到方法ngx_http_fastcgi_process_record，打印读入请求数据： 12345678910111213(gdb)p *f-&gt;pos@1000$26 =\\001\\006\\000\\001\\000\\377\\001\\000 //8字节头部，type=6（STDOUT），返回数据长度为255字节（需要填充1个字节）Set-Cookie: PHPSESSID=3h9lmb2mvp6qlk1rg11id3akd3; path=/\\r\\n //返回数据内容，以换行符分隔Expires: Thu, 19 Nov 1981 08:52:00 GMT\\r\\nCache-Control: no-store, no-cache, must-revalidate\\r\\nPragma: no-cache\\r\\nContent-type: text/html; charset=UTF-8\\r\\n\\r\\n&#123;\\&quot;ret-name\\&quot;:\\&quot;ret-hello\\&quot;,\\&quot;ret-gender\\&quot;:\\&quot;ret-1\\&quot;&#125;\\000\\001\\003\\000\\001\\000\\b\\000\\000 //8字节头部，type=3（END_REQUEST），表示fastcgi请求结束，数据长度为8\\000\\000\\000\\000\\000m\\&quot; //8字节END_REQUEST数据 END_REQUEST请求数据体8个字节，其定义可以在php源码中查看： 12345678typedef struct _fcgi_end_request &#123; unsigned char appStatusB3; ////结束状态，0为正常 unsigned char appStatusB2; unsigned char appStatusB1; unsigned char appStatusB0; unsigned char protocolStatus; //为协议所处的状态，0为正常状态 unsigned char reserved[3];&#125; fcgi_end_request; 总结本文通过分析ngx_http_fastcgi_module模块构造FastCGI请求的代码，学习FastCGI协议格式，并通过GDB打印FastCGI请求与相应数据，以此对FastCGI协议有了更直观的理解。","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"CGI","slug":"CGI","permalink":"https://lives.xtcgch.ink/tags/CGI/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"Linux之vi篇","slug":"Linux之vi篇-20190309","date":"2019-03-09T02:26:37.000Z","updated":"2021-10-10T08:22:35.642Z","comments":true,"path":"2019/03/09/Linux之vi篇/","link":"","permalink":"https://lives.xtcgch.ink/2019/03/09/Linux之vi篇/","excerpt":"摘要：本章主要介绍vim编译器常用的快捷命令","text":"摘要：本章主要介绍vim编译器常用的快捷命令 移动 向上移动一行：k 向上移动9行：9k -&gt; n行：nk 移动到当前行行尾:$ 移动到当前行的第一个字符上:0(数字0) 移动到下一行的行尾:1$ 移动到下n行的行尾:n$ 在当前行上查找下一个字符x（向右方向）:fx 跳转到与当前光标下的括号相匹配的那一个括号:% ;( -&gt; ),) -&gt; ( 显示行号：set number(set nu) 关闭行号：set nonumber(set nonu) 显示光标位置：set ruler ma：在当前光标的位置标记一个书签，名字为a。书签名只能是小写字母。你看不见书签的存在，但它确实已经在那里了 &#39;`&#39;a , 到书签a处。注意这个不是单引号，它一般位于大部分键盘的1的左边 &#39;`&#39;.：到你上次编辑文件的地方。这个命令很有用，而且你不用自己去标记它。 w：光标往前移动一个词。 b： 光标往后移动一个词 ^：移动光标到当前行的第一个字母位置 H：移动光标到屏幕上面 M：移动光标到屏幕中间 L：移动光标到屏幕下面 查找替换 从光标向后查找整个关键词 从光标向前查找整个关键词 查找替换例子：: s/SEARCH/REPLACE: s/If/Since 将下一个”If”换成”Since”: %s/If/Since 将全部”If”换成”Since”: 1,3 s/If/Since/g 只对1,3行有效,如无前缀,只对当前行有效 选择文本 v 从光标当前位置开始，光标所经过的地方会被选中，再按一下v结束 V 从光标当前行开始，光标经过的行都会被选中，再按一下Ｖ结束 Ctrl + v 从光标当前位置开始，选中光标起点和终点所构成的矩形区域，再按一下Ｃtrl + v结束 ggVG 选中全部的文本， 其中gg为跳到行首，V选中整行，G末尾 删除文本 删除字符:x 删除3个字符：3x -&gt; n个字符：nx 删除一行:dd 删除换行符:j 撤销：u x 删除当前光标下的字符(“dl”的快捷命令) X 删除当前光标之前的字符(“dh”的快捷命令) D 删除自当前光标至行尾的内容(“d$”的快捷命令) dw 删除自当前光标至下一个word的开头 db 删除自当前光标至前一个word的开始 diw 删除当前光标所在的word(不包括空白字符) daw 删除当前光标所在的word(包括空白字符) dG 删除当前行至文件尾的内容 dgg 删除当前行至文件头的内容 复制文本 复制一个字符：y 复制一行：yy 复制n个字符：yn 复制一个单词：yw 粘贴文本 p:粘贴所有的复制和剪切内容 编辑文本 全文查找：/target,下一个：n,上一个：N -&gt; 下3个：3n,上3个：3N 在文本中查找下一个word:*,# 查匹配单词的开头：\\&lt; , 查匹配单词的结尾：> ,如 /the>不会匹配they Ctrl+N : 文本提示 ：缩进所有选择的代码 编辑文本 当前光标之前插入文本：i 当前光标之后插入文本：a 在当前行的下面另起一行插入文本：o 在当前行的上面另起一行插入文本：O 丢弃所有的修改并退出:”:q!” 放弃所有修改并重新载入该文件的原始内容:”:e!” 放弃所有操作并退出：qall 保存所有:wall 保存所有并退出:qwall 使用vimdiff查看不同:vimdiff main.c~ main.c 划分窗格 :split/vsplit 分隔一个窗口 new/vnew 创建一个新的窗口 sf {filename} 在新窗口中打开filename close 关闭当前窗口 only 关闭除当前窗口外所有窗口 ctrl-w h 到左面的窗口 ctrl-w j 到下面的窗口 ctrl-w k 到上面的窗口 ctrl-w l 到右面的窗口 ctrl-w t 到顶部的窗口 ctrl-w b 到底部的窗口","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"一些有用的收藏","slug":"一些有用的收藏-20190304","date":"2019-03-04T14:51:31.000Z","updated":"2020-11-30T03:30:50.530Z","comments":true,"path":"2019/03/04/一些有用的收藏/","link":"","permalink":"https://lives.xtcgch.ink/2019/03/04/一些有用的收藏/","excerpt":"摘要：本文主要是记录那些在平时零碎时间看到的有趣的片段。","text":"摘要：本文主要是记录那些在平时零碎时间看到的有趣的片段。 好用的网站和工具1、临时邮箱 -&gt; 传送门 2、疯狂影视搜索 -&gt; 传送门 3、PocketAnimation（口袋动画） -&gt; 传送门 4、图像在线编辑工具 -&gt; 传送门 5、磁盘文件扫描工具 -&gt; 传送门 6、录屏软件 -&gt; 传送门 7、Inpaint图片修改工具 -&gt; 传送门 8、ScreenToGif（2M）–最让人依赖的动态图捕捉工具 -&gt; 传送门 9、AI人工智能图片放大 -&gt; 传送门 冷技巧1、用支付宝免费下载全网论文 -&gt; 办理浙江图书馆读者证","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"收藏","slug":"收藏","permalink":"https://lives.xtcgch.ink/tags/收藏/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"IPC之信号篇","slug":"IPC之信号篇-20190215","date":"2019-02-15T01:06:33.000Z","updated":"2021-10-10T08:31:53.942Z","comments":true,"path":"2019/02/15/IPC之信号篇/","link":"","permalink":"https://lives.xtcgch.ink/2019/02/15/IPC之信号篇/","excerpt":"摘要：简单的介绍常用信号，信号的三种状态、信号的处理方式和信号集。","text":"摘要：简单的介绍常用信号，信号的三种状态、信号的处理方式和信号集。 Linux常用信号在linux下有很多信号，按可靠性分为可靠信号和非可靠信号，按时间分为实时信号和非实时信号，linux进程也有三种方式来处理收到的信号： 忽略信号，即对信号不做任何处理，其中，有两个信号不能忽略：SIGKILL及SIGSTOP； 捕捉信号。定义信号处理函数，当信号发生时，执行相应的处理函数； 执行缺省操作，Linux对每种信号都规定了默认操作。 Linux进程对实时信号的缺省反应是进程终止。但是对于高性能服务器编程来说，这是致命的缺陷，对于这类服务器需要保证在收到各种信号后仍然可以可靠运行，所以我们需要在理解各种信号的缘由和正确的处理方式。本文将笔者经常碰到的一些信号进行整理，结合自己的使用经验简要分析。 SIGHUP 和控制台操作有关，当控制台被关闭时系统会向拥有控制台sessionID的所有进程发送HUP信号，默认HUP信号的action是 exit，如果远程登陆启动某个服务进程并在程序运行时关闭连接的话会导致服务进程退出，所以一般服务进程都会用nohup工具启动(该命令就是让忽略该信号)或写成一个 daemon(利用setsid进行)。 以下五组可以放在一块类比 SIGINT 终止进程，通常我们的Ctrl+C就发送的这个消息。 SIGQUIT 和SIGINT类似, 但由QUIT字符(通常是Ctrl- / )来控制. 进程收到该消息退出时会产生core文件。 SIGKILL 消息编号为9，我们经常用kill -9来杀死进程发送的就是这个消息，程序收到这个消息立即终止，这个消息不能被捕获，封锁或这忽略，所以是杀死进程的终极武器。 SIGTERM 是不带参数时kill默认发送的信号，默认是杀死进程。 SIGSTOP 停止进程的执行，同SIGKILL一样不可以被应用程序所处理，注意它和terminate以及interrupt的区别:该进程还未结束, 只是暂停执行。 SIGCONT 当SIGSTOP发送到一个进程时，通常的行为是暂停该进程的当前状态。如果发送SIGCONT信号，该进程将仅恢复执行。除了其他目的，SIGSTOP和SIGCONT用于Unix shell中的作业控制，无法捕获或忽略SIGCONT信号。 SIGPIPE 这个是向一个没有读进程的管道写数据产生的错误，这种解释过于官方。在网络编程中这个信号发生在如果客户端已经关闭了套接字, 而服务器调用了一次write，服务器就会收到一个RST segment，如果服务器再次调用write，这个时候就会产生SIGPIPE信号，系统默认的处理方式是关掉这个进程， 但是对于一个高可用的服务器程序来说，需要手动处理这个信号，所以你会看到许多服务器程序代码会在前面显式加上signal (SIGPIPE, SIG_IGN)来忽略这个信号。 SIGCHILD 这个同样是高性能服务器需要关注的信号，如果服务器采用fork产生的子进程推出后要调用wait进行资源回收，防止僵尸进程的产生，但是如果程序对子进程退出后的状态不感兴趣的话可以调用signal(SIGCHLD,SIG_IGN); 交给系统init去回收。子进程也不会产生僵尸进程了。 SIGSEGV 就是SegmentFault 试图访问未分配给自己的内存, 或试图往没有写权限的内存地址写数据，官方举得三个例子是： buffer overflow — usually caused by a pointer reference out of range. 野指针stack overflow — please keep in mind that the default stack size is 8192K. 栈溢出illegal file access — file operations are forbidden on our judge system. 非法文件访问SIGBUS 指针所对应的地址是有效地址，但总线不能正常使用该指针。通常是未对齐的数据访问所致。试图访问一块无文件内容对应的内存区域，比如超过文件尾的内存区域，或者以前有文件内容对应，现在为另一进程截断过的内存区域。 SIGURG I/O紧急信号，也就是tcp传输带外数据时使用，但是tcp手册 RFC6093中已经不建议使用紧急指针了，所以这个信号也就没什么用了。 SIGIO 当描述符上可以进行I/O时产生这个信号，这时五大IO模型中信号驱动IO模型的实现信号。 SIGALRM 时钟定时信号, 计算的是实际的时间或时钟时间.alarm函数使用该信号. 信号的三种状态 信号递达：实际执行信号的处理动作。 信号未决：信号从产生到递达之间的状态。 进程可以选择阻塞（block）某个信号。一旦该信号被阻塞就不会被抵达，只有解除阻塞才可被递达。 被阻塞的信号产生时将保持在未决状态，直到进程解除对此信号的阻塞，才执行递达的动作。 阻塞与忽略是不同的，只要信号阻塞就不会被递达，忽略是在递达之后可选的一种处理动作。 信号的三种处理方式 忽略此信号。 执⾏行该信号的默认处理动作（终止该信号）。 提供⼀个信号处理函数（自定义动作）,要求内核在处理该信号时切换到用户态执行这个处理函数,这种方式称为捕捉(Catch)一个信号。 这三种处理方式的信号状态都为信号递达。 信号在内核中的表示（三张表）这3张表分别对应3种状态： 信号阻塞（block） 信号未决（pending） 信号递达—自定义捕捉函数（handler） 其中，前两张表都是位图（BitSet）来存储的。block表中信号被阻塞就将相应位置1，否则置0。而pending表中，若置1则表示信号存在，0则相反。即可这样说。pending表中的数据是判断信号是否存在的唯一依据。 结合上图就可以知道： SIGHUP信号未阻塞也未产生过，但当它递达时就会执行默认处理动作。 SIGINT信号产生过，但已被阻塞。所以暂时不能递达。虽然它的处理动作是忽略。但在没有解除阻塞之前不能忽略这个信号，因为进程仍有机会改变处理动作之后再解除阻塞。 SIGQUIT信号未产生过，一旦产⽣将被阻塞，它的处理动作是用户自定义的捕捉函数handler。 那么可以将信号的三张表总结成这样： 如果一个信号被block，若收到信号，则该信号必定被Pending。 一个进程收到信号时不会立即递达，在此过程中一直被Pending。 一个标准：如果在进程解除对信号的阻塞之前，该信号产生过多次，将如何处理呢？ 答：POSIX.1允许系统递送该信号一次或多次。 Linux是这样规定的：常规信号在递达之前产生多次只记一次，而实时信号在递达之前产生多从可以依次放在一个队列中。 信号集概念信号集是一个包含了所有信号的集合。信号的发送与接收都是以信号集为单位进行发送。 信号集Sigset_t结构在上图中，未决和阻塞标志都可以用相同的数据结构（位图）存储。所以当然可以用同一数据类型来表示，这就是sigset_t. sigset_t称为信号集，这个类型可以表示每个信号的“有效”或“无效”状态。 在阻塞信号集其含义是该信号是否被阻塞；在未决信号集中就代表该信号是否处于未决状态。 操作函数123456789#include&lt;signal.h&gt;int sigemptyset(sigset_t *set);//初始化set所指的信号集，使其中所有信号的对应bit清零，表示该信号集不包含任何有效信号。int sigfillset(sigset_t *set);//初始化set所指的信号集，使其中所有信号的对应bit置位，表示该信号集的有效信号包括系统支持的所有信号。int sigaddset(sigset_t *set,int signo);int sigdelset(sigset_t *set,int signo);int sigismember(const sigset_t *set,int signo);//是一个布尔函数，用于判断一个信号集的有效信号中是否包含某种信号，若包含则返回1，不包含返回0，出错返回-1. 除了sigismember，其他四种函数都是成功返回0，出错返回-1. Sigprocmask函数调用函数Sigprocmask可以获取或更改进程的信号屏蔽字（阻塞信号集） 12#include&lt;signal.h&gt;int sigprocmask(int how,const sigset_t *set,sigset_t *oset);//返回值：成功返回0，出错返回-1. 参数：how参数的可选值： oset：原来的信号屏蔽字。 如果oset和set都是非空指针，则先将原来的信号屏蔽字备份到oset中，然后根据set和how参数更改信号屏蔽字。 注：如果调用sigprocmask解除了对当前若干个未决信号的阻塞，则在sigprocmask返回前，至少将其中一个信号递达。 Sigpending函数读取当前进程的未决信号集 12#include&lt;signal.h&gt;int Sigpending（sigset_t *set）；//返回值：成功返回0，出错返回-1. Demo下面来进行代码测验：阻塞SIGINT信号，按Ctrl-c将SIGINT信号处于未决状态。比特位变为1.1234567891011121314151617181920212223242526272829303132333435363738#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;void handler(int signo)&#123; printf(&quot;get a %d signo\\n&quot;,signo); exit(1);&#125;void show_pending(sigset_t *pending)&#123; int i=1; for(;i&lt;32;i++) &#123; if(sigismember(pending,i))&#123; printf(&quot;1&quot;); &#125;else&#123; printf(&quot;0&quot;); &#125; &#125; printf(&quot;\\n&quot;);&#125;int main()&#123; sigset_t set,oset,pending; sigemptyset(&amp;set);//初始化 sigaddset(&amp;set,2);//添加2号信号 signal(2,handler); sigprocmask(SIG_SETMASK,&amp;set,&amp;oset);//设置阻塞信号屏蔽字 int count=0; while(1)&#123; sigpending(&amp;pending);//获取当前未决信号 show_pending(&amp;pending); sleep(1); &#125; return 0;&#125; 解除2号信号的阻塞状态，使其抵达。捕捉到2号信号后，信号集数据又从1变0，变为以前的状态。再次crtl+c后，就不会发生1中的变化了。 123456789101112131415161718192021222324252627282930313233343536373839404142#include&lt;stdio.h&gt;#include&lt;signal.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;void handler(int signo)&#123; printf(&quot;get a %d signo\\n&quot;,signo);// exit(1);&#125;void show_pending(sigset_t *pending)&#123; int i=1; for(;i&lt;32;i++) &#123; if(sigismember(pending,i))&#123; printf(&quot;1&quot;); &#125;else&#123; printf(&quot;0&quot;); &#125; &#125; printf(&quot;\\n&quot;);&#125;int main()&#123; sigset_t set,oset,pending; sigemptyset(&amp;set); sigaddset(&amp;set,2); signal(2,handler); sigprocmask(SIG_SETMASK,&amp;set,&amp;oset); int count=0; while(1)&#123; sigpending(&amp;pending); show_pending(&amp;pending); sleep(1); count++; if(count==15)&#123; sigprocmask(SIG_SETMASK,&amp;oset,NULL);//解除了屏蔽 &#125; &#125; return 0;&#125; Linux支持的信号列表 查看命令 1kill -l POSIX.1中列出的信号 信号 值 处理动作 发出信号的原因 SIGHUP 1 终止进程 终端挂起或者控制进程终止 SIGINT 2 终止进程 键盘中断（如break键被按下） SIGQUIT 3 终止进程 键盘的退出键被按下 SIGILL 4 终止进程 非法指令 SIGABRT 6 终止进程 由abort(3)发出的退出指令 SIGFPE 8 终止进程 浮点异常 SIGKILL 9 AEF Kill信号 SIGSEGV 11 终止进程 无效的内存引用 SIGPIPE 13 终止进程 管道破裂:写一个没有读端口的管道 SIGALRM 14 终止进程 由alarm(2)发出的信号 SIGTERM 15 终止进程 终止信号 SIGUSR1 30,10,16 终止进程 用户自定义信号1 SIGUSR2 31,12,17 终止进程 用户自定义信号2 SIGCHLD 20,17,18 忽略信号 子进程结束信号 SIGCONT 19,18,25 进程继续（曾被停止的进程） SIGSTOP 17,19,23 停止进程、不能被捕获、不能被忽略 终止进程 SIGTSTP 18,20,24 终止进程 控制终端（tty）上按下停止键 SIGTTIN 21,21,26 终止进程 后台进程企图从控制终端读 SIGTTOU 22,22,27 终止进程 后台进程企图从控制终端写 SUSv2中列出的信号 信号 值 处理动作 发出信号的原因 SIGBUS 10,7,10 终止进程 总线错误(错误的内存访问) SIGPOLL 终止进程 Sys V定义的Pollable事件，与SIGIO同义 SIGPROF 27,27,29 终止进程 Profiling定时器到 SIGSYS 12,-,12 终止进程 无效的系统调用 SIGTRAP 5 终止进程 跟踪断点捕获 SIGURG 16,23,21 忽略信号 Socket出现紧急条件 SIGVTALRM 26,26,28 终止进程 实际时间报警时钟信号 SIGXCPU 24,24,30 终止进程 超出设定的CPU时间限制 SIGXFSZ 25,25,31 终止进程 超出设定的文件大小限制 总结信号是Linux系统编程的一个重要概念，要尽快掌握。","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"信号","slug":"信号","permalink":"https://lives.xtcgch.ink/tags/信号/"},{"name":"IPC","slug":"IPC","permalink":"https://lives.xtcgch.ink/tags/IPC/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"机器学习入门","slug":"机器学习入门-20190121","date":"2019-01-21T02:36:00.000Z","updated":"2020-11-30T03:30:40.581Z","comments":true,"path":"2019/01/21/机器学习入门/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/21/机器学习入门/","excerpt":"摘要：这是本文主要是机器学习的笔记！","text":"摘要：这是本文主要是机器学习的笔记！ 脑图 其他模板的标题 1、笔记 定义 如果一个程序可在任务T上，随着经验E的增加，效果P随之增加，则这个程序可以从经验中学习。 三个要素 数据、算法、算力 应用概述 预测和分类 图像识别、语音识别和自然语言处理 神经网络的搭建 搭建神经网络的八股：准备、前传、后传和迭代 准备：import，常量定义，生成数据集 前向传播：定义输入、参数和输出 反向传播：定义损失函数、反向传播方法 迭代：生成会话、训练STEPS轮 神经网络的优化 常见函数 损失函数 激活函数 relu sigmold tanh 优化内容 损失函数 学习率 滑动平均 正则化 损失函数 激活函数 总结","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://lives.xtcgch.ink/categories/人工智能/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://lives.xtcgch.ink/tags/机器学习/"}],"keywords":[{"name":"人工智能","slug":"人工智能","permalink":"https://lives.xtcgch.ink/categories/人工智能/"}]},{"title":"【实战】 IPC之管道使用","slug":"IPC之管道使用-20190118","date":"2019-01-18T04:21:45.000Z","updated":"2021-10-10T08:47:51.917Z","comments":true,"path":"2019/01/18/IPC之管道使用/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/18/IPC之管道使用/","excerpt":"摘要：本文是匿名管道和命名管道在Linux下的使用例子。","text":"摘要：本文是匿名管道和命名管道在Linux下的使用例子。 匿名管道的使用12345678910111213141516171819202122232425262728293031323334353637#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#define MAXLINE 1024int main(void)&#123; int n; int fd[2]; pid_t pid; char line[MAXLINE]; if (pipe(fd) &lt; 0) &#123; perror(&quot;pipe&quot;); exit(1); &#125; pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork&quot;); exit(1); &#125; else if (pid &gt; 0) /* parent */ &#123; close(fd[0]); // 关闭读端 write(fd[1], &quot;hello world\\n&quot;, 12); &#125; else /* child */ &#123; close(fd[1]); // 关闭写端 n = read(fd[0], line, MAXLINE); write(STDOUT_FILENO, line, n); &#125; return 0;&#125; 命名管道的使用进程A创建管道(mkfifo) -&gt; 进程A写打开管道(open) -&gt; 进程B读打开管道(open) -&gt; 进程A开始往管道里写数据(write) -&gt; 进程B从管道中读数据(read) -&gt; 进程A关闭管道(close) -&gt; 进程B关闭管道(close) -&gt; 删除管道(unlink) 进程A：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include&lt;sys/stat.h&gt;#include&lt;fcntl.h&gt;#include&lt;iostream&gt;#include&lt;cstdlib&gt;#include&lt;cstring&gt;#include&lt;unistd.h&gt;using namespace std;#define PIPENAME &quot;pipetest&quot;const int open_mode = O_WRONLY;int main()&#123; int ret = 0; if(access(PIPENAME, F_OK) == -1) &#123; //PIPENAME文件描述符不存在,则创建 ret = mkfifo(PIPENAME, 0666); if(ret != 0) &#123; cout &lt;&lt; &quot;Could not create fifo &quot; &lt;&lt;PIPENAME&lt;&lt;endl; exit(EXIT_FAILURE); &#125; &#125; // 打开管道的写模式 int fd = open(PIPENAME, open_mode); if(-1 == fd) &#123; cout&lt;&lt;&quot;open fail, maybe file not exist&quot;&lt;&lt;endl; return -1; &#125; unlink(PIPENAME); int i = 0; for(i = 0; i &lt; 10; i++) &#123; ret = write(fd, &amp;i, sizeof(i)); if(ret == -1) &#123; cout &lt;&lt; &quot;Write error on pipe&quot; &lt;&lt;endl; exit(EXIT_FAILURE); &#125; cout&lt;&lt;&quot;i:&quot;&lt;&lt;i&lt;&lt;endl; sleep(1); // 这个是以秒为单位挂起 &#125; // 关闭管道 close(fd); return 0;&#125; 进程B： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include&lt;sys/stat.h&gt;#include&lt;fcntl.h&gt;#include&lt;iostream&gt;#include&lt;unistd.h&gt;#include&lt;cstdlib&gt;#include&lt;cstring&gt;#include&lt;stdio.h&gt;using namespace std;#define PIPENAME &quot;pipetest&quot;const int open_mode = O_RDONLY;int main()&#123; int ret = 0; if(access(PIPENAME, F_OK) == -1) &#123; //PIPENAME文件描述符不存在,则创建 ret = mkfifo(PIPENAME, 0666); if(ret != 0) &#123; fprintf(stderr, &quot;Could not create fifo %s\\n&quot;, PIPENAME); exit(EXIT_FAILURE); &#125; &#125; // 打开管道的读模式 int fd = open(PIPENAME, open_mode); if(-1 == fd) &#123; cout&lt;&lt;&quot;open fail, maybe file not exist&quot;&lt;&lt;endl; return -1; &#125; int num = 0; int i = 0; for(i = 0; i &lt; 10; i++) &#123; ret = read(fd, &amp;num, sizeof(int)); if(ret == -1) &#123; cout &lt;&lt; &quot;Write error on pipe&quot; &lt;&lt;endl; exit(EXIT_FAILURE); &#125; cout&lt;&lt;&quot;num:&quot;&lt;&lt;num&lt;&lt;endl; fflush(stdout); // 强制刷新输出缓冲区 &#125; close(fd); return 0;&#125; 输出： 解释： 命名管道读和写的顺序不是强制的,但是由于管道的使用要依赖于共享文件,因此在写代码时需要注意读和写时要先判断管道共享文件是否已经存在,write()和read()函数是阻塞式IO。 在调用mkfifo(PIPENAME, 0666)函数后，会创建一个名为PIPENAME的文件,如下图所示。当调用unlink(PIPENAME)函数后,将会延迟删除PIPENAME文件","categories":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}],"tags":[{"name":"IPC","slug":"IPC","permalink":"https://lives.xtcgch.ink/tags/IPC/"},{"name":"POSIX","slug":"POSIX","permalink":"https://lives.xtcgch.ink/tags/POSIX/"},{"name":"管道","slug":"管道","permalink":"https://lives.xtcgch.ink/tags/管道/"}],"keywords":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}]},{"title":"【实战】 IPC之消息队列使用","slug":"IPC之消息队列使用-20190117","date":"2019-01-17T07:36:54.000Z","updated":"2021-10-10T15:53:37.451Z","comments":true,"path":"2019/01/17/IPC之消息队列使用/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/17/IPC之消息队列使用/","excerpt":"摘要：本章是关于posix消息队列的测试例子，相关解说在其他文章中。","text":"摘要：本章是关于posix消息队列的测试例子，相关解说在其他文章中。 1. demo1 测试消息队列的获取特性的函数 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;cstring&gt; #include &lt;errno.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;mqueue.h&gt;#include &lt;cstdlib.h&gt; using namespace std; int main()&#123; mqd_t mqID; mqID = mq_open(&quot;/anonymQueue&quot;, O_RDWR | O_CREAT, 0666, NULL); if (mqID &lt; 0) &#123; cout&lt;&lt;&quot;open message queue error...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; mq_attr mqAttr; if (mq_getattr(mqID, &amp;mqAttr) &lt; 0) &#123; cout&lt;&lt;&quot;get the message queue attribute error&quot;&lt;&lt;endl; return -1; &#125; cout&lt;&lt;&quot;mq_flags:&quot;&lt;&lt;mqAttr.mq_flags&lt;&lt;endl; cout&lt;&lt;&quot;mq_maxmsg:&quot;&lt;&lt;mqAttr.mq_maxmsg&lt;&lt;endl; cout&lt;&lt;&quot;mq_msgsize:&quot;&lt;&lt;mqAttr.mq_msgsize&lt;&lt;endl; cout&lt;&lt;&quot;mq_curmsgs:&quot;&lt;&lt;mqAttr.mq_curmsgs&lt;&lt;endl;&#125; 2. demo2 使用消息队列进行数据的收发 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;mqueue.h&gt;#include &lt;cstdlib.h&gt; using namespace std; int main()&#123; mqd_t mqID; mqID = mq_open(&quot;/anonymQueue&quot;, O_RDWR | O_CREAT | O_EXCL, 0666, NULL); if (mqID &lt; 0) &#123; if (errno == EEXIST) &#123; mq_unlink(&quot;/anonymQueue&quot;); mqID = mq_open(&quot;/anonymQueue&quot;, O_RDWR | O_CREAT, 0666, NULL); &#125; else &#123; cout&lt;&lt;&quot;open message queue error...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; &#125; if (fork() == 0) &#123; mq_attr mqAttr; mq_getattr(mqID, &amp;mqAttr); char *buf = new char[mqAttr.mq_msgsize]; for (int i = 1; i &lt;= 5; ++i) &#123; if (mq_receive(mqID, buf, mqAttr.mq_msgsize, NULL) &lt; 0) &#123; cout&lt;&lt;&quot;receive message failed. &quot;; cout&lt;&lt;&quot;error info:&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; continue; &#125; cout&lt;&lt;&quot;receive message &quot;&lt;&lt;i&lt;&lt;&quot;: &quot;&lt;&lt;buf&lt;&lt;endl; &#125; exit(0); &#125; char msg[] = &quot;yuki&quot;; for (int i = 1; i &lt;= 5; ++i) &#123; if (mq_send(mqID, msg, sizeof(msg), i) &lt; 0) &#123; cout&lt;&lt;&quot;send message &quot;&lt;&lt;i&lt;&lt;&quot; failed. &quot;; cout&lt;&lt;&quot;error info:&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; &#125; cout&lt;&lt;&quot;send message &quot;&lt;&lt;i&lt;&lt;&quot; success. &quot;&lt;&lt;endl; sleep(1); &#125;&#125; 3. 生产者和消费者 单生产者 + 单消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/time.h&gt;#include &lt;pthread.h&gt;#include &lt;mqueue.h&gt; #define POSIX_QUEUE &quot;/mqueue&quot;#define MAX_THREADS 1#define MAX_ITEMS 1000000 struct Shared&#123; mqd_t mqdes; int nput; int nval;&#125;; struct Shared shared; void shared_init()&#123; shared.mqdes = mq_open(POSIX_QUEUE, O_RDWR | O_CREAT, 0666, NULL); //在我的系统中，Posix消息队列最大容量为10 mq_unlink(POSIX_QUEUE);&#125; void shared_destroy()&#123; mq_close(shared.mqdes);&#125; void *produce(void *arg)&#123; while (1) &#123; if (shared.nput &gt;= MAX_ITEMS) &#123; pthread_exit(NULL); &#125; mq_send(shared.mqdes, (char *)&amp;shared.nval, sizeof(shared.nval), 0); shared.nput++; shared.nval++; /* 线程tid_produce[i]每执行一次，就累加count[i]的值 */ *((int *)arg) += 1; &#125; pthread_exit(NULL);&#125; void *consume(void *arg)&#123; struct mq_attr attr; int nval; int i; mq_getattr(shared.mqdes, &amp;attr); printf(&quot;system defaut mq_maxmsg = %ld, mq_msgsize = %ld\\n&quot;, attr.mq_maxmsg, attr.mq_msgsize); for (i = 0; i &lt; MAX_ITEMS; i++) &#123; //消费者线程按顺序取出消息,根据mq_getattr返回结果来设置mq_receive的参数len mq_receive(shared.mqdes, (char *)&amp;nval, attr.mq_msgsize, NULL); if (nval != i) &#123; printf(&quot;error: buff[%d] = %d\\n&quot;, i, nval); &#125; &#125; pthread_exit(NULL);&#125; int main()&#123; pthread_t tid_produce[MAX_THREADS]; pthread_t tid_consume; int count[MAX_THREADS]; struct timeval start_time; struct timeval end_time; float time_sec; int i; shared_init(); gettimeofday(&amp;start_time, NULL); for (i = 0; i &lt; MAX_THREADS; i++) &#123; count[i] = 0; pthread_create(&amp;tid_produce[i], NULL, produce, &amp;count[i]); &#125; pthread_create(&amp;tid_consume, NULL, consume, NULL); for (i = 0; i &lt; MAX_THREADS; i++) &#123; pthread_join(tid_produce[i], NULL); printf(&quot;count[%d] = %d\\n&quot;, i, count[i]); //输出每个线程的执行次数 &#125; pthread_join(tid_consume, NULL); gettimeofday(&amp;end_time, NULL); time_sec = (end_time.tv_sec - start_time.tv_sec) + (end_time.tv_usec - start_time.tv_usec) / 1000000.0; printf(&quot;%d produce and %d consume total spend %.2f second\\n&quot;, MAX_THREADS, 1, time_sec); shared_destroy(); return 0;&#125; 4. 生产者和消费者 多生产者 + 单消费者 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/time.h&gt;#include &lt;pthread.h&gt;#include &lt;mqueue.h&gt; #define POSIX_QUEUE &quot;/mqueue&quot;#define MAX_THREADS 10#define MAX_ITEMS 1000000 struct Shared&#123; pthread_mutex_t mutex; mqd_t mqdes; int nput; int nval;&#125;; struct Shared shared; void shared_init()&#123; pthread_mutex_init(&amp;shared.mutex, NULL); shared.mqdes = mq_open(POSIX_QUEUE, O_RDWR | O_CREAT, 0666, NULL); //在我的系统中，Posix消息队列最大容量为10 mq_unlink(POSIX_QUEUE);&#125; void shared_destroy()&#123; pthread_mutex_destroy(&amp;shared.mutex); mq_close(shared.mqdes);&#125; void *produce(void *arg)&#123; while (1) &#123; pthread_mutex_lock(&amp;shared.mutex); if (shared.nput &gt;= MAX_ITEMS) &#123; pthread_mutex_unlock(&amp;shared.mutex); pthread_exit(NULL); &#125; //生产者线程依次累加nval的值，并以无优先级消息方式放入消息队列 mq_send(shared.mqdes, (char *)&amp;shared.nval, sizeof(shared.nval), 0); shared.nput++; shared.nval++; pthread_mutex_unlock(&amp;shared.mutex); /* 线程tid_produce[i]每执行一次，就累加count[i]的值 */ *((int *)arg) += 1; &#125; pthread_exit(NULL);&#125; void *consume(void *arg)&#123; struct mq_attr attr; int nval; int i; mq_getattr(shared.mqdes, &amp;attr); printf(&quot;system defaut mq_maxmsg = %ld, mq_msgsize = %ld\\n&quot;, attr.mq_maxmsg, attr.mq_msgsize); for (i = 0; i &lt; MAX_ITEMS; i++) &#123; mq_receive(shared.mqdes, (char *)&amp;nval, attr.mq_msgsize, NULL); //根据mq_getattr返回结果来设置mq_receive的参数len if (nval != i) &#123; printf(&quot;error: buff[%d] = %d\\n&quot;, i, nval); &#125; &#125; pthread_exit(NULL);&#125; int main()&#123; pthread_t tid_produce[MAX_THREADS]; pthread_t tid_consume; int count[MAX_THREADS]; struct timeval start_time; struct timeval end_time; float time_sec; int i; shared_init(); gettimeofday(&amp;start_time, NULL); for (i = 0; i &lt; MAX_THREADS; i++) &#123; count[i] = 0; pthread_create(&amp;tid_produce[i], NULL, produce, &amp;count[i]); &#125; pthread_create(&amp;tid_consume, NULL, consume, NULL); for (i = 0; i &lt; MAX_THREADS; i++) &#123; pthread_join(tid_produce[i], NULL); printf(&quot;count[%d] = %d\\n&quot;, i, count[i]); //输出每个线程的执行次数 &#125; pthread_join(tid_consume, NULL); gettimeofday(&amp;end_time, NULL); time_sec = (end_time.tv_sec - start_time.tv_sec) + (end_time.tv_usec - start_time.tv_usec) / 1000000.0; printf(&quot;%d produce and %d consume total spend %.2f second\\n&quot;, MAX_THREADS, 1, time_sec); shared_destroy(); return 0;&#125; 5. 编译命令 g++ -lrt -o test main.cpp","categories":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}],"tags":[{"name":"IPC","slug":"IPC","permalink":"https://lives.xtcgch.ink/tags/IPC/"},{"name":"POSIX","slug":"POSIX","permalink":"https://lives.xtcgch.ink/tags/POSIX/"},{"name":"消息队列","slug":"消息队列","permalink":"https://lives.xtcgch.ink/tags/消息队列/"}],"keywords":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}]},{"title":"【原理】 IPC之消息队列","slug":"IPC之消息队列-20190115","date":"2019-01-15T13:03:42.000Z","updated":"2021-10-10T14:54:17.442Z","comments":true,"path":"2019/01/15/IPC之消息队列/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/15/IPC之消息队列/","excerpt":"摘要：消息队列是一种异步处理数据的方式，本文只讲posix标准下的系统级的消息队列。","text":"摘要：消息队列是一种异步处理数据的方式，本文只讲posix标准下的系统级的消息队列。 脑图 1、概述1.1 简介消息队列是Linux IPC中很常用的一种通信方式，它通常用来在不同进程间发送特定格式的消息数据。 消息是从人类自然语言的角度来称呼，从技术角度来看就是一个数据结构，如字符串，结构体或者类，等等。消息队列中的每条消息具有以下属性： 一个表示优先级的整数 消息的数据部分的长度 消息数据本身 POSIX消息队列的一个可能的设计是一个如下图所示的消息链表，链表头部有消息队列的属性信息。 1.2 分类消息队列常有以下种类： System V消息队列 posix消息队列 自定义的各种语言的消息队列 其中前2种属于系统级别，可以通过系统调用来进行使用。最后一种是用户自己实现和维护的。 1.3 描述符和消息队列的关系消息队列描述符是一个进程级别的句柄，它引用了系统层面的打开着的消息队列描述表中的一个条目，而该条目则引用了一个消息队列对象。 1.4 特性 Posix消息队列与System V消息队列主要区别： 对Posix消息队列的读总是返回最高优先级的消息，对System V消息队列的读则可以返回任一指定优先级消息。 往空队列放置消息时，Posix消息队列允许产生一个信号或启动一个线程，System V则不提供类似机制 Posix消息队列与管道或FIFO的主要区别： 在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。对管道和FIFO来说，除非读出者已存在，否则先有写入者是没有意义的。 管道和FIFO是字节流模型，没有消息边界；消息队列则指定了数据长度，有边界。 1.5 评价（1）优点 （2）缺点 （3）限制 POSIX消息队列本身的限制就是mq_attr中的mq_maxmsg和mq_msgsize， 分别用于限定消息队列中的最大消息数和每个消息的最大字节数。 这两个参数可以在调用mq_open创建一个消息队列的时候设定。当这个设定是受到系统内核限制的。 消息队列的大小为800KB 2、操作2.1 打开 头文件：mqueue.h API:mqd_t mq_open(const char name, int oflag,…/ mode_t mode, struct mq_attr attr /); name:必填，消息队列的名称 oflag：必填，打开消息队列的选项参数，如下表所示： O_CREAT：队列不存在时创建 O_EXCL：与O_CREAT一起创建队列，如果已经存在同名消息队列，则返回失败。 O_RDONLY:只读 O_WRONLY:只写 O_RDWR:可写可读 O_NONBLOCK:以非阻塞方式打开。打开失败会返回EAGAIN错误。 mode：选填 attr：选填 返回：成功-&gt;消息队列描述符（mqd_t类型），失败-&gt;-1 说明： O_CREAT和O_EXCL一起使用时，如果此时已经存在同名的消息队列，则返回失败。 2.2 关闭一个消息队列 头文件： API：mqd_t mq_close(mqd_t mqdes); mqdes：消息队列描述符 返回：成功-&gt;消息队列描述符（mqd_t类型），失败-&gt;-1 说明：close()函数只是断开当前进程与消息队列的关联。删除消息队列需要使用mq_unlick()函数。 2.3 删除一个消息队列 头文件：mqueue.h API:mqd_t mq_unlink(const char * name); name：消息队列的名称 返回：成功-&gt;消息队列描述符（mqd_t类型），失败-&gt;-1 说明：mq_unlink函数被调用时首先打上了删除消息队列的标记，当所有的进程都退出使用消息队列后，该消息队列才真正被删除。 2.4 发送消息 头文件：mqueue.h 函数：mqd_t mq_send(mqd_t mqdes, const char * msg_ptr,size_t msg_len, unsigned msg_prio); mqdes：消息队列描述符 msg_ptr：指向缓冲区的指针 msg_len：要发送的数据长度，单位-&gt;字节 msg_prio：优先级 返回：成功-&gt;消息队列描述符（mqd_t类型），失败-&gt;-1 说明： 函数:int mq_timedsend(mqd_t mqdes, char msg_ptr, size_t msg_len,unsigned int msg_prio, const struct timespec abs_timeout) mqdes:消息队列描述符 msg_ptr:指向接收数据的缓冲区的指针 msg_len:数据长度 msg_prio:消息优先级 abs_timeout:超时时间 返回：成功-&gt;0，失败-&gt;-1 说明： 2.5 接收消息 头文件：mqueue.h 函数：mqd_t mq_receive(mqd_t mqdes, char msg_ptr, size_t msg_len, unsigned msg_prio); mqdes:消息队列描述符 msg_ptr:指向要存储的缓冲区的指针 msg_len:接收数据的长度，单位-&gt;字节 msg_prio:优先级 返回：成功-&gt;消息队列描述符（mqd_t类型），失败-&gt;-1 说明： 函数：ssize_t mq_timedreceive(mqd_t mqdes, char msg_ptr, size_t msg_len,unsigned int msg_prio, const struct timespec abs_timeout) mqdes:消息队列描述符 msg_ptr:指向接收数据的缓冲区的指针 msg_len:数据长度 msg_prio:消息优先级 abs_timeout:超时时间 返回：成功-&gt;接收的字节数，失败-&gt;-1 说明： 2.6 获取消息队列特性 头文件：mqueue.h 函数：mq_getattr(mqd_t mqdes,struct mq_attr * attr); mqdes: attr:消息队列的属性，包含一下四个属性 long mq_flags //消息队列的标志：0或O_NONBLOCK,用来表示是否阻塞 long mq_maxmsg //消息队列的最大消息数 long mq_msgsize //消息队列中每个消息的最大字节数 long mq_curmsgs //消息队列中当前的消息数目 返回：成功返回0，失败返回-1 说明： 2.7 设置消息队列的特性 头文件：msqueue.h 函数:mqd_t mq_setattr(mqd_t mqdes, struct mq_attr newattr, struct mq_attr oldattr); mqdes:消息队列描述符 newattr:新的特性 oldattr:旧的特性 返回：成功-&gt;消息队列描述符（mqd_t类型），失败-&gt;-1 说明： 2.8 消息通知Posix消息队列允许异步事件通知，以告知何时有一个消息放置到了某个空消息队列中。这种通知有两种方式可供选择： 产生一个信号 创建一个线程来执行指定的函数 头文件：msqueue.h 函数:int mq_notify(mqd_t mqdes, const struct sigevent * notification); mqdes:消息队列描述符 notification:新的特性 返回：成功-&gt;0，失败-&gt;-1 说明： 注册一个进程，当消息队列中有消息到来时，该进程被通知，并在其信号处理程序中取出消息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;stdio.h&gt; #include &lt;mqueue.h&gt; #include &lt;errno.h&gt; #include &lt;stdlib.h&gt; #include &lt;signal.h&gt; #define ERR_EXIT(m)\\ &#123;\\ printf(&quot;%s() error %d: %s\\n&quot;, m, errno, strerror(errno));\\ exit(EXIT_FAILURE);\\ &#125; mqd_t mqd; void *buff; struct mq_attr attr; struct sigevent event; static void sig_usr1(int signo); int main(int argc, char *argv[]) &#123; if (signal(SIGUSR1, sig_usr1) == SIG_ERR) ERR_EXIT(&quot;signal&quot;); if ((mqd = mq_open(argv[1], O_RDONLY)) == -1) ERR_EXIT(&quot;mq_open&quot;); if (mq_getattr(mqd, &amp;attr) == -1) ERR_EXIT(&quot;mq_getattr&quot;); buff = malloc(attr.mq_msgsize); //注册进程接收队列的通知 event.sigev_notify = SIGEV_SIGNAL; event.sigev_signo = SIGUSR1; if (mq_notify(mqd, &amp;event) == -1)//注册进程，消息队列中有消息来时，触发事件。 ERR_EXIT(&quot;mq_notify&quot;); //一直执行，等待信号到来 for (;;) pause(); exit(0); &#125; static void sig_usr1(int signo) &#123; //重新注册 if (mq_notify(mqd, &amp;event) == -1) ERR_EXIT(&quot;mq_notify&quot;); //取出消息 ssize_t n; unsigned int prio; if ((n = mq_receive(mqd, buff, attr.mq_msgsize, &amp;prio)) == -1) ERR_EXIT(&quot;mq_receive&quot;); printf(&quot;SIGUSR1 received, read %d bytes, priority = %d\\n&quot;, n, prio); &#125; 空消息队列有消息到来时，通知注册进程，注册进程创建一个线程执行指定函数操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;stdio.h&gt; #include &lt;mqueue.h&gt; #include &lt;errno.h&gt; #include &lt;stdlib.h&gt; #include &lt;fcntl.h&gt; #include &lt;unistd.h&gt; #define ERR_EXIT(m)\\ &#123;\\ printf(&quot;%s() error %d: %s\\n&quot;, m, errno, strerror(errno));\\ exit(EXIT_FAILURE);\\ &#125; mqd_t mqd; struct mq_attr attr; struct sigevent event; static void thread_func(union sigval); int main(int argc, char *argv[]) &#123; if (argc != 2) &#123; printf(&quot;argument error\\n&quot;); exit(-1); &#125; //打开消息队列 if ((mqd = mq_open(argv[1], O_RDONLY | O_NONBLOCK)) == -1) ERR_EXIT(&quot;mq_open&quot;); if (mq_getattr(mqd, &amp;attr) == -1) ERR_EXIT(&quot;mq_getattr&quot;); //注册进程 event.sigev_notify = SIGEV_THREAD; event.sigev_value.sival_ptr = NULL; event.sigev_notify_attributes = NULL; event.sigev_notify_function = thread_func; if (mq_notify(mqd, &amp;event) == -1) ERR_EXIT(&quot;mq_notify&quot;); for (;;) pause(); exit(0); &#125; void thread_func(union sigval value) &#123; ssize_t n; void *buff; long len; unsigned int prio; buff = malloc(attr.mq_msgsize); len = attr.mq_msgsize; if (mq_notify(mqd, &amp;event) == -1)//重新注册进程 ERR_EXIT(&quot;mq_notify&quot;); if ((n = mq_receive(mqd, buff, len, &amp;prio))) printf(&quot;read %d bytes, priority = %d\\n&quot;, n, prio); free(buff); pthread_exit((void *)0); &#125; 3、其他API和数据结构 4、使用流程 5、应用场景 6、FAQ 问：是否线程安全？答：是 7、demo传送门 总结 目前只做过demo，暂无总结","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"IPC","slug":"IPC","permalink":"https://lives.xtcgch.ink/tags/IPC/"},{"name":"POSIX","slug":"POSIX","permalink":"https://lives.xtcgch.ink/tags/POSIX/"},{"name":"消息队列","slug":"消息队列","permalink":"https://lives.xtcgch.ink/tags/消息队列/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 IPC之内存映射","slug":"操作系统之内存映射-20190115","date":"2019-01-15T12:53:09.000Z","updated":"2021-10-10T16:01:13.674Z","comments":true,"path":"2019/01/15/IPC之内存映射/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/15/IPC之内存映射/","excerpt":"摘要：内存映射是Linux系统中IPC的一种方式，对于学习Linux的系统原理或是在Linux系统下进行编程都有很大的帮助。","text":"摘要：内存映射是Linux系统中IPC的一种方式，对于学习Linux的系统原理或是在Linux系统下进行编程都有很大的帮助。 脑图 1、概述1.1 简介1.2 特性1.3 评价（1）优点 （2）缺点 （3）限制 2、操作2.1 创建2.2 使用2.3 删除 3、应用场景 4、API 5、使用流程 6、demo 总结","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"POSIX","slug":"POSIX","permalink":"https://lives.xtcgch.ink/tags/POSIX/"},{"name":"内存映射","slug":"内存映射","permalink":"https://lives.xtcgch.ink/tags/内存映射/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 IPC之共享内存","slug":"IPC之共享内存-20190115","date":"2019-01-15T12:48:27.000Z","updated":"2021-10-10T14:46:50.613Z","comments":true,"path":"2019/01/15/IPC之共享内存/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/15/IPC之共享内存/","excerpt":"摘要：posix共享内存是IPC的一种方式，相似地，还有System V共享内存，本文只讲posix标准下的共享内存知识。","text":"摘要：posix共享内存是IPC的一种方式，相似地，还有System V共享内存，本文只讲posix标准下的共享内存知识。 脑图 1、概述1.1 简介1.2 特性1.3 评价（1）优点 （2）缺点 （3）限制 2、操作2.1 创建2.2 删除2.3 使用 3、使用场景 4、API 5、使用流程 6、demo 总结","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"IPC","slug":"IPC","permalink":"https://lives.xtcgch.ink/tags/IPC/"},{"name":"共享内存","slug":"共享内存","permalink":"https://lives.xtcgch.ink/tags/共享内存/"},{"name":"POSIX","slug":"POSIX","permalink":"https://lives.xtcgch.ink/tags/POSIX/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【实战】 编程语言之C++常见错误汇总篇","slug":"编程语言之C++常见错误汇总篇-20190112","date":"2019-01-12T10:17:51.000Z","updated":"2021-10-10T16:02:16.727Z","comments":true,"path":"2019/01/12/编程语言之C++常见错误汇总篇/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/12/编程语言之C++常见错误汇总篇/","excerpt":"摘要：本文主要记录在编译、开发和其他场景下遇到的问题和解决方案！","text":"摘要：本文主要记录在编译、开发和其他场景下遇到的问题和解决方案！ 编译错误类makefile的语法错误（一）（1）错误信息 *** missing separator. Stop. （2）问题描述 在使用makefile时遇到的报错 （3）场景描述 操作系统：CentOS 7 ，64位 编译环境：g++,gcc 4.8.5版本，root权限 （4）截图 （5）问题分类 makefile （6）问题分析和解决方案 makefile中语句的缩进必须用tab键 （7）总结 对makefile不熟悉，多加训练 直接复制内容到makefile，有可能会引起相同的问题 g++编译错误类（1）错误信息 undefined reference to &#39;mq_open&#39; (2)问题描述 在编译posix消息队列程序时报错 （3）场景描述 操作系统：CentOS 7 ，64位 编译环境：g++,gcc 4.8.5版本，root权限 （4）截图 （5）问题分类 posix 消息队列 （6）问题分析和解决方案 在编译时添加 -lrt 命令 （7）总结 文件格式错误（1）错误信息 /bin/bash^M: bad interpreter错误解决方法 （2）问题描述 在windows系统中创建sh文件，然后在centos7系统中运行shell脚本 （3）场景描述 操作系统：CentOS 7 ，64位 编译环境：g++,gcc 4.8.5版本，root权限 4）截图 略 5）问题分类 bash shell （6）问题分析和解决方案 由于是在windows系统中创建的文件，文件的格式和Linux系统中的文件格式有区别，特别是sh这样的可执行文本 打开文件，使用命令set ff?检查，看看是不是dos字样，如果是，则将执行命令set ff=unix，然后执行命令wq进行保存更改，退出重进即可 开发错误类","categories":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}],"tags":[{"name":"错误汇总","slug":"错误汇总","permalink":"https://lives.xtcgch.ink/tags/错误汇总/"}],"keywords":[{"name":"实战","slug":"实战","permalink":"https://lives.xtcgch.ink/categories/实战/"}]},{"title":"【原理】 Linux之CentOS下编译动态库和静态库","slug":"Linux之CentOS下编译动态库和静态库-20190110","date":"2019-01-10T05:30:18.000Z","updated":"2021-10-10T15:57:06.064Z","comments":true,"path":"2019/01/10/CentOS下编译动态库和静态库/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/10/CentOS下编译动态库和静态库/","excerpt":"摘要：本篇文章主要简单介绍下，在CentOS7环境下编译动态库和静态库的方法和遇到的坑。","text":"摘要：本篇文章主要简单介绍下，在CentOS7环境下编译动态库和静态库的方法和遇到的坑。 1、脑图 2、开发动态库（1）库代码 dynamicmath.h文件 ： 12345678910111213141516171819#ifndef DYNAMICMATH_H#define DYNAMICMATH_H #include &lt;iostream&gt; class DynamicMath&#123;public: DynamicMath(); ~DynamicMath(); double add(double x, double y); double sub(double x, double y); double mul(double x, double y); double div(double x, double y); void print();&#125;; #endif // DYNAMICMATH_H dynamicmath.cpp文件: 1234567891011121314151617181920212223242526272829303132333435363738394041#include &quot;dynamicmath.h&quot; DynamicMath::DynamicMath()&#123; &#125; DynamicMath::~DynamicMath()&#123; &#125; double DynamicMath::add(double x, double y)&#123; return x + y;&#125; double DynamicMath::sub(double x, double y)&#123; return x - y;&#125; double DynamicMath::mul(double x, double y)&#123; return x * y;&#125; double DynamicMath::div(double x, double y)&#123; if (y &gt; -0.000001 &amp;&amp; y &lt; 0.000001) &#123; return 0; &#125; else &#123; return x/y; &#125; &#125; void DynamicMath::print()&#123; std::cout &lt;&lt; &quot;Hello World&quot; &lt;&lt; std::endl;&#125; (2)编译 g++ -fPIC -shared -o libdynmath.so dynamicmath.cpp 解释： -fPIC：作用于编译阶段，告诉编译器产生与位置无关代码(Position-Independent Code)。则产生的代码中，没有绝对地址，全部使用相对地址，故而代码可以被加载器加载到内存的任意位置，都可以正确的执行。这正是共享库所要求的，共享库被加载时，在内存的位置不是固定的。 -shared：表示生成动态库文件 因此，生成了libdynmath.so。 （3）使用动态库 前言：项目要引进动态库，必须要包含头文件和动态库。 test.cpp: 123456789101112131415161718#include &quot;dynamicmath.h&quot;#include &lt;iostream&gt; int main() &#123; double x = 10; double y = 2; DynamicMath dm; std::cout &lt;&lt; dm.add(x, y) &lt;&lt; std::endl; std::cout &lt;&lt; dm.sub(x, y) &lt;&lt; std::endl; std::cout &lt;&lt; dm.mul(x, y) &lt;&lt; std::endl; std::cout &lt;&lt; dm.div(x, y) &lt;&lt; std::endl; dm.print(); return 0; &#125; 编译命令： g++ test_d.cpp -L/root/Documents/test/libs/ -ldynmath -I./include 解释： -L：表示动态库的路径，相对路径或者绝对路径。如果未配置这个参数，则默认从系统路径/usr/lib64等位置寻找。 -l：L的小写形式，用于指明要引入的动态库，其中名字不包含前缀’lib’和扩展名’.so’，例如-ldynmath表示libdynmath.so文件 -I：表示头文件所在的文件夹，可相对路径和绝对路径。 重点说明： 编译后会生成a.out文件，但是无法执行，因为找不到依赖的libdynmath.so库，这时候有两种解决方法： 方法一：把libdynmath.so库复制到/usr/lib64/文件夹，然后执行命令ldconfig刷新缓存，再执行./a.out即可 方法二：编辑/etc/ld.so.conf文件，增加库文件所在文件夹的路径，然后执行命令ldconfig刷新缓存，再执行./a.out即可。需要root权限。 方法三（最简单，推荐）：使用shell临时环境变量。export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/Documents/test/libs/。 3、开发静态库（1）库代码 mymethod.h文件： 1234567#include &lt;stdio.h&gt;#include &lt;iostream&gt;using namespace std;int add(int a,int b);int myminus(int a,int b); mymethod.cpp文件： 1234567891011#include&lt;mymethod.h&gt;int add(int a,int b)&#123; return a+b;&#125;int myminus(int a,int b)&#123; return a-b;&#125; (2)编译&amp;链接&amp;测试 编译命令： g++ -c mymethod.cpp -o mymethod.o 备注：普通的cpp编译 链接命令： ar -cr libmymethod.a mymethod.o 备注： ar：ar命令可以用来创建、修改库，也可以从库中提出单个模块（所谓的库就是生成的静态库） -c 选项表示 创建一个库。不管库是否存在，都将创建。（不存在则创建，存在则替换） -r 选项表示 将模块插入库，如果库中有对应的模块，那么进行更新。（模块是对源文件.h,.cpp而言） 如果把多个.o文件插入库.a里,只需要在后面用空格分开写出来。格式：ar -cr 静态库libname.a name1.o name2.o 至此，则生成了静态库。 静态库的命名有规则,格式为lib+库名+.a 。 （3）测试 main.cpp文件： 1234567891011#include&quot;mymethod.h&quot;#include&lt;iostream&gt;using namespace std;int main()&#123; cout&lt;&lt;add(5,6)&lt;&lt;endl; cout&lt;&lt;myminus(6,5)&lt;&lt;endl; return 0;&#125; 编译&amp;链接&amp;运行： g++ main.cpp -o main -I ./ -L ./ -lmymethod 说明： -I（i的大写形式）：后面接引用头文件所在文件夹，可相对路径和绝对路径。 -L：后面接静态库文件所在的路径，可相对路径和绝对路径。 -l：后面接静态库的名字。注意，lib+名字+.a组成静态库的库名。 4、总结第一次学习，肯定要先学会抄，抄熟了再学会变通。[手动狗头]","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 Linux之CentOS7环境配置篇","slug":"Linux之CentOS7环境配置篇-20190109","date":"2019-01-09T12:48:51.000Z","updated":"2021-11-29T08:41:06.193Z","comments":true,"path":"2019/01/09/Linux之CentOS7环境配置篇/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/09/Linux之CentOS7环境配置篇/","excerpt":"摘要：本文主要介绍在CentOS7下组件的安装和环境的配置。","text":"摘要：本文主要介绍在CentOS7下组件的安装和环境的配置。 1、脑图 前言:都是在root权限下进行安装和配置。 ★★★ MYSQL8的安装和配置 ★★★检测操作系统自带安装的mysql和mariadb服务 检测操作系统自带安装的mysql和mariadb服务12rpm -qa | grep mysqlrpm -qa | grep mariadb 卸载mysql和mariadb服务1234rpm -e mariadb-devel* --nodepsrpm -e mariadb-libs* --nodepsrpm -e qt5-qtbase-mysql* --nodepsrpm -e qt-mysql* --nodeps 查看repo源1yum repolist all | grep mysql 使用repo源在线安装 repo源下载和安装 下载一：https://dev.mysql.com/downloads/repo/yum/ 下载二：wget https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm 安装：rpm -ivh mysql80-community-release-el7-1.noarch.rpm 安装mysql-server1yum install mysql-server 至此，mysql已经安装完成！可以小高兴一会！ mysql默认安装位置 查看mysql相关: whereis mysql 头文件： lib包： /usr/lib64/mysql 可执行文件： /usr/bin/mysql 日志: socket: /var/lib/mysql/mysql.sock 配置文件: /etc/my.cnf mysqldump文件位置:/usr/bin/mysqldump mysql数据目录:/var/lib/mysql mysql服务的管理 启动：service mysqld start或systemctl start mysql 重启：service mysqld restart或systemctl restart mysql 关闭：service mysqld stop或systemctl stop mysql 查看初始密码sudo grep &#39;temporary password&#39; /var/log/mysqld.log 设置密码密码组合规则：大写字母+小写字母+数字和符号1ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &quot;ROOTroot@123456&quot;; 立即生效：1flush privileges; 修改root远程登录访问权限123update user set host=&apos;%&apos; where user=&apos;root&apos;; flush privileges; 创建用户12CREATE USER &apos;gch&apos;@&apos;%&apos; IDENTIFIED BY &apos;GCHgch@123456&apos;;flush privileges; 安装mysql.h1sudo yum install mysql-devel LINUX的配置 安装firewalld在CentOS 7中防火墙已经由firewalld来管理,Centos7默认安装了firewalld,没有安装的可以用yum 命令安装，与iptables区别不小 1yum install firewalld firewalld-config 查看防火墙状态1systemctl status firewalld //或者 firewall-cmd --state 启动防火墙1systemctl start firewalld.service 重启防火墙1firewall-cmd --reload 或者 service firewalld restart 防火墙开放3306端口1firewall-cmd --zone=public --add-port=3306/tcp --permanent //--permanent永久生效,没有此参数防火墙重启便失效 防火墙关闭开放的3306端口1firewall-cmd --zone=public --remove-port=3306/tcp --permanent 禁用防火墙1systemctl stop firewalld 设置开机启动1systemctl enable firewalld 停止并禁用开机启动1sytemctl disable firewalld 查看端口列表1firewall-cmd --permanent --list-port 进入：mysql -uroot,注意，不要使用-p 查看：use mysql; , show tables; , describe user; 配置新密码：update user set password=password(&#39;new password&#39;) where user=&#39;root&#39;;注意，密码要使用password(‘’)函数进行散列化 刷新缓存，让配置立即生效：flush privileges; my.cnf文件解读1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889[client]port = 3306socket = /usr/local/services/mysql/var/data/mysql.sock[mysqld]bind-address = 0.0.0.0port = 3306socket = /usr/local/services/mysql/var/data/mysql.sockpid-file = /usr/local/services/mysql/var/logs/mysql.pidcharacter-set-server = utf8basedir = /usr/local/services/mysqldatadir = /usr/local/services/mysql/var/dataskip-external-lockingskip-name-resolvelower_case_table_names = 1log-bin-trust-function-creators = 1max_connections = 6000max_user_connections = 6000max_connect_errors = 4000wait_timeout = 86400interactive_timeout = 86400table_open_cache = 512max_allowed_packet = 32Msort_buffer_size = 2Mjoin_buffer_size = 2Mthread_cache_size = 8thread_concurrency = 8query_cache_size = 32M#default-storage-engine = InnoDB#sql_mode=&quot;STRICT_ALL_TABLES,NO_AUTO_CREATE_USER&quot;server-id = 1log-short-formatlog-error = /usr/local/services/mysql/var/logs/mysql.logslow_query_loglong_query_time = 2slow_query_log_file = /usr/local/services/mysql/var/logs/mysql-slow.loglog-bin = /usr/local/services/mysql/var/binlog/mysql-binlog_bin_trust_function_creators=1binlog_format = MIXEDexpire_logs_days = 10# INNODB Specific optionsinnodb_data_home_dir = /usr/local/services/mysql/var/datainnodb_log_group_home_dir = /usr/local/services/mysql/var/redologinnodb_additional_mem_pool_size = 10Minnodb_buffer_pool_size = 4Ginnodb_data_file_path = ibdata1:100M:autoextendinnodb_file_io_threads = 4innodb_thread_concurrency = 8innodb_flush_log_at_trx_commit = 0innodb_flush_method = O_DIRECTinnodb_log_buffer_size = 128Minnodb_log_file_size = 256Minnodb_log_files_in_group = 3innodb_max_dirty_pages_pct = 90innodb_lock_wait_timeout = 50innodb_file_per_table = 1# MyISAM Specific optionskey_buffer_size = 384Mread_buffer_size = 4Mread_rnd_buffer_size = 8Mmyisam_sort_buffer_size = 128Mmyisam_max_sort_file_size = 1Gmyisam_repair_threads = 1myisam_recover[mysqldump]quickmax_allowed_packet = 16M[mysql]default-character-set = utf8no-auto-rehashsocket = /usr/local/services/mysql/var/data/mysql.sock[myisamchk]key_buffer_size = 256Msort_buffer_size = 256Mread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout ★★★ 安装REDIS ★★★ 前置条件 gcc : for redis tcl 8.5: for make test TCL安装使用ActiveTcl代替tcl 下载，从浏览器下载源码包：1https://platform.activestate.com/unistd68/ActiveTcl-8.6 安装1234tar zxvf ActiveTcl-8.6.11.1.0000-x86_64-linux-glibc-2.17-e4e2f327.tar.gzmv ActiveTcl-8.6.11.1.0000-x86_64-linux-glibc-2.17-e4e2f327 ActiveTclcd ActiveTclsh install.sh 加入环境变量1234#/etc/profile文件export PATH=&quot;/opt/ActiveTcl-8.6/bin:$PATH&quot;export PATH=&quot;/usr/local/redis/bin:$PATH&quot;source /etc/profile 源码安装1234wget https://download.redis.io/releases/redis-6.2.5.tar.gztar xzf redis-6.2.5.tar.gzcd redis-6.2.5make &amp; make test 检查是否安装成功 本地客户端 无密码：12345#在src下有redis-server可执行文件cd src./redis-cliset foo barget foo 有密码：12345#在src下有redis-cli可执行文件cd src./redis-cli config set requirepass 123456 #设置密码 config get requirepass #查看密码 远程客户端 123#在src下有redis-server可执行文件cd src./redis-cli -h 127.0.0.1 -p 6379 -a &quot;123456&quot; 环境配置进入redis目录下:绑定外界可以访问的ip地址12#redis.confbind 127.0.0.1 192.168.1.105 1cd deps/hiredis 1sudo make install prefix=/usr/local/redis 防火墙开启6379端口参考mysql8的环境配置 ★★★ 网络配置 ★★★ 网卡配置文件解读 常见的命名规则：ifcfg-en*,如：ifcfg-enp0s3 配置文件地址：/etc/sysconfig/network-scripts/ifcfg-你的网卡名字 参数说明：12345678910111213141516171819202122TYPE=Ethernet #局域网PROXY_METHOD=none #是否设置代理BROWSER_ONLY=no #BOOTPROTO=static #是否静态IP ，static/dhcp#BOOTPROTO=dhcpDEFROUTE=yes IPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=enp0s3 #网卡名称UUID=b5701d6a-414e-48d8-85f2-9c8fa2bf7512 #MAC地址DEVICE=enp0s3 #设备名称ONBOOT=yes #是否系统boot引导启动时加载，或手动启动IPADDR=192.168.1.113 #静态IPV4地址，BOOTPROTO=static时必须设置PREFIX=24 #IPV4掩码GATEWAY=192.168.1.1 #IPV4网关DNS1=114.114.114.114 #DNS首选地址DNS2=114.114.115.115 #DNS备选地址ZONE=public 安装网络工具包网络工具包包含的常见工具有： ifconfig ping yum 查看是否安装ifconfig cd /sbin ll 安装工具包 sudo yum install net-tools ★★★ 安装使用rz/sz命令 ★★★ 查看提供sz/rz命令的工具包 12yum whatprovides rz #yum install -y lrzsz ★★★ 安装VIM ★★★1yum -y install vim* 配置vim123456&quot;/etc/vimrcset nu &quot; 设置显示行号set showmode &quot; 设置在命令行界面最下面显示当前模式等set ruler &quot; 在右下角显示光标所在的行数等信息set autoindent &quot; 设置每次单击Enter键后，光标移动到下一行时与上一行的起始字符对齐syntax on &quot; 即设置语法检测，当编辑C或者Shell脚本时，关键字会用特殊颜色显示 ★★★ 安装JEKINS ★★★ 前提依赖 openjdk oraclejdk git openjdk安装 oraclejdk安装 git安装 JEKINS安装 先从清华大学网站下载并安装repo源12wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/redhat-stable/jenkins-2.303.1-1.1.noarch.rpmrpm -ivh jenkins-2.303.1-1.1.noarch.rpm 根据官方步骤走安装流程12345sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyyum install epel-release # repository that provides &apos;daemonize&apos;yum install java-11-openjdk-develyum install jenkins 配置 1234vim /etc/sysconfig/jenkins#监听端口JENKINS_PORT=&quot;8080&quot; 配置权限 1234vim /etc/sysconfig/jenkins#修改配置$JENKINS_USER=&quot;root&quot; 修改目录权限 123chown -R root:root /var/lib/jenkinschown -R root:root /var/cache/jenkinschown -R root:root /var/log/jenkins 重启12service jenkins restartps -ef | grep jenkins 浏览器地址1http://192.168.1.113:8080/ 初始密码文件1/var/lib/jenkins/secrets/initialAdminPassword 修改jenkins源为国内源 插件搜索配置文件配置：/var/lib/jenkins/hudson.model.UpdateCenter.xml插件更新配置文件位置：/var/lib/jenkins/updates/default.json 123#/var/lib/jenkins/hudson.model.UpdateCenter.xmlsed -i &apos;s/http:\\/\\/mirror.esuni.jp\\/jenkins\\/updates\\/update-center.json\\//https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins\\/updates\\/update-center.json&apos; /var/lib/jenkins/hudson.model.UpdateCenter.xml 12345#var/lib/jenkins/updates/default.jsonsed -i &apos;s/http:\\/\\/updates.jenkins-ci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g&apos; /var/lib/jenkins/updates/default.json &amp;&amp; sed -i &apos;s/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g&apos; /var/lib/jenkins/updates/default.json &amp;&amp; sed -i &apos;s/updates.jenkins.io\\/download\\/plugins\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins\\/plugins/g&apos; /var/lib/jenkins/updates/default.jsonsystemctl restart jenkins 使用技巧 Jenkins默认会在Build结束后Kill掉所有的衍生进程 注意事项 ★★★ 安装RABBITMQ ★★★ 依赖 erlang erlang安装 123curl -s https://packagecloud.io/install/repositories/rabbitmq/erlang/script.rpm.sh &gt; script.rpm.shsh script.rpm.shsudo yum install erlang 安装RABBITMQ 12345https://github.com/rabbitmq/rabbitmq-server/releasesrpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.ascrpm -ivh rabbitmq-server-3.9.7-1.el7.noarch.rpmsystemctl start rabbitmq-server 打开防火墙端口 1234567firewall-cmd --zone=public --permanent --add-port=4369/tcpfirewall-cmd --zone=public --permanent --add-port=25672/tcpfirewall-cmd --zone=public --permanent --add-port=5671-5672/tcpfirewall-cmd --zone=public --permanent --add-port=15672/tcpfirewall-cmd --zone=public --permanent --add-port=61613-61614/tcpfirewall-cmd --zone=public --permanent --add-port=1883/tcpfirewall-cmd --zone=public --permanent --add-port=8883/tcp 将防火墙配置重新载入 1firewall-cmd --reload RabbitMQ 设置自动启动 1systemctl enable rabbitmq-server 查看 RabbitMQ 的进程运行状态 1systemctl status rabbitmq-server RabbitMQ 启用 Web 管理界面 1rabbitmq-plugins enable rabbitmq_management 提供 RabbitMQ 用户和对用户使用的权限进行赋权1chown -R rabbitmq:rabbitmq /var/lib/rabbitmq/ 新建用户并授权123rabbitmqctl add_user admin StrongPasswordrabbitmqctl set_user_tags admin administratorrabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; url:http://192.168.1.113:15672/ RabbitMQ 运行和管理 启动 1./sbin/rabbitmq-server 后台启动 1./sbin/rabbitmq-server -detached 查询服务器状态 1./sbin/rabbitmqctl status 关闭 RabbitMQ 节点 12./sbin/rabbitmqctl stop./sbin/rabbitmqctl -n rabbit@server.example.com stop 关闭 RabbitMQ 应用程序 1./sbin/rabbitmqctl stop_app 启动 RabbitMQ 应用程序 1./sbin/rabbitmqctl start_app 重置 RabbitMQ 节点 1./sbin/rabbitmqctl reset 查看已声明的队列 1./sbin/rabbitmqctl list_queues 查看交换器 12./sbin/rabbitmqctl list_exchanges./sbin/rabbitmqctl list_exchanges name type durable auto_delete 查看绑定 1./sbin/rabbitmqctl list_bindings 修改RabbitMQ默认端口 RabbitMQ默认开启了几个端口： 4369：erlang发现口 5672：client端通信口，客户端要连接RabbitMQ服务时要用到 15672：后台管理界面ui端口，进入管理后台时访问url如：http://localhost:15672/ 25672：server间内部通信口 配置文件的默认位置： /etc/rabbitmq/rabbitmq.conf ★★★ 安装OPENSSL ★★★ 依赖 1git clone git@github.com:openssl/openssl.git ★★★ 更换repo源 ★★★ 依赖 备份原镜像 12sudo mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupsudo mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.backup 下载国内的Base源和EPEL源 1234567891011#阿里云的Base源和EPEL源 sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo sudo wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo#腾讯云的Base源和EPEL源 sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.cloud.tencent.com/repo/centos7_base.repo sudo wget -O /etc/yum.repos.d/epel.repo http://mirrors.cloud.tencent.com/repo/epel-7.repo#163的Base源 sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo 清理和生成缓存 1234sudo yum clean allsudo rm -rf /var/cache/yum/ sudo yum listsudo yum makecache ★★★ 同步时间 ★★★ 设置时区 查看时区 1timedatectl status|grep &apos;Time zone&apos; 设置时区 12345#设置硬件时钟调整为与本地时钟一致timedatectl set-local-rtc 1#设置时区为上海timedatectl set-timezone Asia/Shanghai 设置时区 12345678#安装ntpdateyum -y install ntpdate#同步时间ntpdate -u pool.ntp.org#同步完成后,date命令查看时间是否正确date 同步时间后可能部分服务器过一段时间又会出现偏差，因此最好设置crontab来定时同步时间，方法如下：1234567891011#安装crontabyum -y install crontab#创建crontab任务crontab -e#添加定时任务*/20 * * * * /usr/sbin/ntpdate pool.ntp.org &gt; /dev/null 2&gt;&amp;1#重启crontabservice crond reload ★★★ 安装nslookup ★★★ 安装 1sudo yum -y install bind-utils 安装NPM 下载node国内镜像 网站：https://npm.taobao.org/mirrors/node 下载：wget https://npm.taobao.org/mirrors/node/v10.14.1/node-v10.14.1-linux-x64.tar.gz 解压并重命名文件夹 12tar -xvf node-v10.14.1-linux-x64.tar.gzmv node-v10.14.1-linux-x64 node 添加环境变量 1vim /etc/profile 在文件最后添加以下配置 12export NODE_HOME=/usr/local/node export PATH=$NODE_HOME/bin:$PATH 刷新配置 1source /etc/profile 安装vue管理后台注意：npm为6.0版本以上时，对代码和依赖检查严格，老项目容易缺乏依赖而报错 1234567mkdir &lt;your-project-name&gt;cd &lt;your-project-name&gt;yarn create umi git initnpm i --legacy-peer-deps //应对npm6.0以上版本的依赖问题npm installnpm start centos7扩容 磁盘扩容 虚拟机扩容：虚拟机管理中分配磁盘空间 实体机扩容：安装新的磁盘 简介 CentOS7，LVM根分区扩容 CentOS7，非LVM根分区扩容 MBR（Master Boot Record）（主引导记录）和GPT（GUID Partition Table）（GUID意为全局唯一标识符）是在磁盘上存储分区信息的两种不同方式 对于传统的MBR分区方式，有很多的限制： 最多4个主分区（3个主分区+1个扩展分区(扩展分区里面可以放多个逻辑分区)），无法创建大于2TB的分区，使用fdisk分区工具，而GPT分区方式不受这样的限制。 GPT分区方式将不会有这种限制，使用的工具是parted 逻辑卷管理(LVM)，是 Logical Volume Manager（逻辑卷管理）的简写，lvm是卷的一种管理方式，并不是分区工具（也可不采用这种LVM管理方式） LVM扩容思维流程：创建一个物理分区–&gt;将这个物理分区转换为物理卷–&gt;把这个物理卷添加到要扩展的卷组中–&gt;然后才能用extend命令扩展此卷组中的逻辑卷 如何查看本地机器是否使用LVM管理？ pvdisplay #查看物理卷 vgdisplay #查看卷组 lvdisplay #查看逻辑卷 分区配置 查看可用空间:需保证有一定的可用空间 1df -h 查看可扩展容量 1fdisk -l 可知，磁盘的路径是：/dev/sda 执行命令：fdisk /dev/sda 使用命令m获取命令 已经存在分区sda1和sda2，所以需要添加分区sda3 添加分区：输入命令n分区号：输入命令3并且默认使用起始扇区地址 分区id更改 输入命令：t 选择分区号: 3 输入分区代码： 8e 保存退出： w 同步文件系统 12345partprobe #重读分区表pvcreate /dev/sda3 #硬盘分区vgextend centos /dev/sda3 #物理卷扩展lvextend -l +100%FREE /dev/centos/root #逻辑卷扩展xfs_growfs /dev/mapper/centos-root #同步文件系统 这时输入df -h即可看到实际磁盘容量了 glibc2.33安装 磁盘扩容 minio 设置永久链接 123456789101112131415161718# 将已存在的minio桶加入管理./mc config host add minio http://192.168.1.113:9000 minioadmin minioadmin./mc admin info minio./mc admin policy list minio./mc policy get minio/video./mc policy set download minio/videohttp://192.168.1.113:9000/video/天下足球/《天下足球》 20170213 兰帕德：神灯长明.mp4insert into tb_address_info(no,title,type,url) values(&apos;01&apos;,&apos;(天下足球)20191216 百大球星-一球成名&apos;,&apos;mp4&apos;,&apos;(天下足球)20191216 百大球星-一球成名.mp4&apos;);./mc policy set download minio/webscripthttp://192.168.1.113:9000/webscript/js/video.jshttp://192.168.1.113:9000/webscript/style/video.css","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"},{"name":"MYSQL","slug":"MYSQL","permalink":"https://lives.xtcgch.ink/tags/MYSQL/"},{"name":"REDIS","slug":"REDIS","permalink":"https://lives.xtcgch.ink/tags/REDIS/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 Linux之Centos7下编译安装Boost","slug":"Linux之Centos7下编译安装Boost-20190108","date":"2019-01-08T02:59:19.000Z","updated":"2021-10-10T15:40:25.672Z","comments":true,"path":"2019/01/08/Linux之Centos7下编译安装Boost/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/08/Linux之Centos7下编译安装Boost/","excerpt":"摘要：新手入门，保持更新！","text":"摘要：新手入门，保持更新！ 1、脑图 2、boost的下载&amp;解压 官网：https://www.boost.org/ 下载centos版本，如boost_1_69_0.tar.gz 解压：tar -zxvf boost_1_69_0.tar.gz 3、执行bootstrap.sh12cd boost_1_69_0./bootstrap.sh 4、编译：./b2 参数这时没有说编译安装，是因为在非root账户下，编译安装过程中产生的各种库文件放不进去/usr/local/目录下。 默认的编译参数保存在project-config.jam下，可用vim自己查看。 ./b2有诸多的参数可以选择，如下（./b2 –help）： 先使用比较简单的参数：1./b2 --without-python stage debug 编译时间会比较久，编译成功后会生成boost目录（头文件）、stage/lib目录（动态库及静态库）。 5、头文件及库文件拷贝将编译产生的boost目录拷贝至/usr/include/，将stage/lib/下的所有文件拷贝至/usr/lib64/下，如下：12sudo cp -rf boost /usr/includesudo cp -rf stage/lib/* /usr/lib64 6、测试测试文件test.cpp: 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;boost/regex.hpp&gt;int main()&#123; std::string str = &quot;192.168.1.1&quot;; boost::regex expression(&quot;([0-9]+).([0-9]+).([0-9]+)&quot;); boost::smatch what; if(boost::regex_search(str, what, expression)) &#123; std::cout &lt;&lt; what.size() &lt;&lt; std::endl; for(size_t i = 0; i &lt; what.size(); i++) &#123; if(what[i].matched) &#123; std::cout &lt;&lt; what[i] &lt;&lt; std::endl; &#125; &#125; &#125; return 0;&#125; Makefile: 12345678910111213INC_DIR=-I/usr/include/LIB_DIR=-L/usr/lib64/LIB=-lboost_regexCC=g++ -gCFLAGS=-WallEXE=testall: $(CC) $(CFLAGS) $(EXE).cpp -o $(EXE) $(INC_DIR) $(LIB_DIR) $(LIB)clean: rm -rf *.o $(EXE) 7、Boost库“卸载”因为我们只是简单地拷贝头文件和库文件，因此，我们直接删除Boost库头文件和库文件就可以了，如下：12sudo rm -rf /usr/include/boostsudo rm /usr/lib64/*boost*","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】Centos下C++开发常用命令","slug":"Linux之CentOS7下C++开发常用命令-20190105","date":"2019-01-05T02:59:19.000Z","updated":"2021-10-02T13:36:42.836Z","comments":true,"path":"2019/01/05/Centos下C++开发常用命令/","link":"","permalink":"https://lives.xtcgch.ink/2019/01/05/Centos下C++开发常用命令/","excerpt":"摘要：新手入门，保持更新！","text":"摘要：新手入门，保持更新！ 1、脑图 本人是在Centos6.4 64bit系统上进行测试的，GCC版本是4.4.7。 2、编译命令2.1 引进外部头文件2.1.1 方法一 在编译时添加命令 -I(i的大写) 2.1.2 方法二在环境变量中进行设置(临时) （1）gcc中查找路径12C_INCLUDE_PATH=/usr/include/ export C_INCLUDE_PATH (2)g++的查找路径12CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/usr/include/ export CPLUS_INCLUDE_PATH 2.2 引进外部静态/动态库2.2.1 动态库（1）方法一：添加编译命令 库目录：-L/lib/库文件：-l/libsoci_mysql ,代表着libsoci_mysql.so库 （2）方法二：添加环境变量 12LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/MyLib export LD_LIBRARY_PATH 2.2.2 静态库（1）方法一：添加编译命令 库目录：-L/lib/ -static库文件：-l/libsoci_mysql ,代表着libsoci_mysql.so库 （2）方法二：添加环境变量 12LIBRARY_PATH=$LIBRARY_PATH:/MyLib export LIBRARY_PATH 2.3 使用C++11标准进行编译1-std=c++11（字母都是小写形式） 3 调试命令3.1 strings命令：查看系统glibc支持的版本1234567891011121314151617181920212223242526272829303132333435363738[root@lzv6 c++]# strings /usr/lib64/libstdc++.so.6 | grep GLIBCGLIBCXX_3.4GLIBCXX_3.4.1GLIBCXX_3.4.2GLIBCXX_3.4.3GLIBCXX_3.4.4GLIBCXX_3.4.5GLIBCXX_3.4.6GLIBCXX_3.4.7GLIBCXX_3.4.8GLIBCXX_3.4.9GLIBCXX_3.4.10GLIBCXX_3.4.11GLIBCXX_3.4.12GLIBCXX_3.4.13GLIBC_2.2.5GLIBC_2.3GLIBC_2.4GLIBC_2.3.2GLIBCXX_FORCE_NEWGLIBCXX_DEBUG_MESSAGE_LENGTH[root@lzv6 c++]# strings /lib64/libc.so.6 | grep GLIBC_GLIBC_2.2.5GLIBC_2.2.6GLIBC_2.3GLIBC_2.3.2GLIBC_2.3.3GLIBC_2.3.4GLIBC_2.4GLIBC_2.5GLIBC_2.6GLIBC_2.7GLIBC_2.8GLIBC_2.9GLIBC_2.10GLIBC_2.11GLIBC_2.12GLIBC_PRIVATE 3.2 g++ -E选项：预处理源文件12345[root@lzv6 c++]# g++ -E -o vec2.cpp vec.cpp [root@lzv6 c++]# wc vec.cpp vec2.cpp 33 71 557 vec.cpp 20958 45683 534803 vec2.cpp 20991 45754 535360 总用量 上面每行分别代表行数、单次数、字节数。 从这里也可以看出引入多余头文件是件多么可怕的事情，多引入一个头文件，就要预处理N行。你可以试着#include &lt;stdio.h&gt;,然后再看看增加了多少行。 3.3 ldd命令：显示目标文件的依赖库1234567891011121314151617181920212223242526272829303132333435363738394041[root@lzv6 c++]# ldd vec linux-vdso.so.1 =&gt; (0x00007fff8fbff000) libstdc++.so.6 =&gt; /usr/lib64/libstdc++.so.6 (0x0000003317800000) libm.so.6 =&gt; /lib64/libm.so.6 (0x000000309ca00000) libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x0000003317400000) libc.so.6 =&gt; /lib64/libc.so.6 (0x000000309ce00000) /lib64/ld-linux-x86-64.so.2 (0x000000309c600000) [root@lzv6 c++]# ldd -v vec // -v 表示 打印所有信息，例如包括符号的版本信息 linux-vdso.so.1 =&gt; (0x00007fff585ff000) libstdc++.so.6 =&gt; /usr/lib64/libstdc++.so.6 (0x0000003317800000) libm.so.6 =&gt; /lib64/libm.so.6 (0x000000309ca00000) libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x0000003317400000) libc.so.6 =&gt; /lib64/libc.so.6 (0x000000309ce00000) /lib64/ld-linux-x86-64.so.2 (0x000000309c600000) Version information: ./vec: libgcc_s.so.1 (GCC_3.0) =&gt; /lib64/libgcc_s.so.1 libc.so.6 (GLIBC_2.2.5) =&gt; /lib64/libc.so.6 libstdc++.so.6 (CXXABI_1.3) =&gt; /usr/lib64/libstdc++.so.6 libstdc++.so.6 (GLIBCXX_3.4) =&gt; /usr/lib64/libstdc++.so.6 /usr/lib64/libstdc++.so.6: libm.so.6 (GLIBC_2.2.5) =&gt; /lib64/libm.so.6 ld-linux-x86-64.so.2 (GLIBC_2.3) =&gt; /lib64/ld-linux-x86-64.so.2 libgcc_s.so.1 (GCC_4.2.0) =&gt; /lib64/libgcc_s.so.1 libgcc_s.so.1 (GCC_3.3) =&gt; /lib64/libgcc_s.so.1 libgcc_s.so.1 (GCC_3.0) =&gt; /lib64/libgcc_s.so.1 libc.so.6 (GLIBC_2.4) =&gt; /lib64/libc.so.6 libc.so.6 (GLIBC_2.3) =&gt; /lib64/libc.so.6 libc.so.6 (GLIBC_2.3.2) =&gt; /lib64/libc.so.6 libc.so.6 (GLIBC_2.2.5) =&gt; /lib64/libc.so.6 /lib64/libm.so.6: libc.so.6 (GLIBC_PRIVATE) =&gt; /lib64/libc.so.6 libc.so.6 (GLIBC_2.2.5) =&gt; /lib64/libc.so.6 /lib64/libgcc_s.so.1: libc.so.6 (GLIBC_2.4) =&gt; /lib64/libc.so.6 libc.so.6 (GLIBC_2.2.5) =&gt; /lib64/libc.so.6 /lib64/libc.so.6: ld-linux-x86-64.so.2 (GLIBC_PRIVATE) =&gt; /lib64/ld-linux-x86-64.so.2 ld-linux-x86-64.so.2 (GLIBC_2.3) =&gt; /lib64/ld-linux-x86-64.so.2 3.4 objdump命令：查看目标文件的动态引用符号表123456789101112131415161718192021222324[root@lzv6 c++]# objdump -T vecvec: file format elf64-x86-64DYNAMIC SYMBOL TABLE:0000000000000000 DF *UND* 0000000000000000 GLIBCXX_3.4 _ZSt20__throw_length_errorPKc0000000000000000 DF *UND* 0000000000000000 GLIBCXX_3.4 _ZNSolsEi0000000000000000 w D *UND* 0000000000000000 __gmon_start__0000000000000000 w D *UND* 0000000000000000 _Jv_RegisterClasses0000000000000000 DF *UND* 0000000000000000 GLIBCXX_3.4 _ZdlPv0000000000000000 DF *UND* 0000000000000000 CXXABI_1.3 __cxa_rethrow0000000000000000 DF *UND* 0000000000000000 GLIBCXX_3.4 _ZNSt8ios_base4InitC1Ev0000000000000000 DF *UND* 0000000000000000 GLIBC_2.2.5 __libc_start_main0000000000000000 DF *UND* 0000000000000000 GLIBC_2.2.5 __cxa_atexit0000000000000000 DF *UND* 0000000000000000 GLIBCXX_3.4 _ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc0000000000000000 DF *UND* 0000000000000000 GLIBC_2.2.5 memmove0000000000000000 DF *UND* 0000000000000000 CXXABI_1.3 __cxa_end_catch0000000000000000 DF *UND* 0000000000000000 GLIBCXX_3.4 _ZSt17__throw_bad_allocv0000000000000000 DF *UND* 0000000000000000 CXXABI_1.3 __cxa_begin_catch0000000000000000 DF *UND* 0000000000000000 GLIBCXX_3.4 _Znwm0000000000000000 DF *UND* 0000000000000000 GCC_3.0 _Unwind_Resume0000000000400910 DF *UND* 0000000000000000 GLIBCXX_3.4 _ZNSt8ios_base4InitD1Ev00000000006026e0 g DO .bss 0000000000000110 GLIBCXX_3.4 _ZSt4cout0000000000400970 DF *UND* 0000000000000000 CXXABI_1.3 __gxx_personality_v0 – 3.4 objdump命令：查看目标文件引用了GLIBC的哪些版本中的哪些函数12341 [root@lzv6 c++]# objdump -T vec | grep GLIBC_2 0000000000000000 DF *UND* 0000000000000000 GLIBC_2.2.5 __libc_start_main3 0000000000000000 DF *UND* 0000000000000000 GLIBC_2.2.5 __cxa_atexit4 0000000000000000 DF *UND* 0000000000000000 GLIBC_2.2.5 memmove 3.6 nm命令：显示vec程序中使用的函数123451 [root@lzv6 c++]# nm -o vec | grep print2 vec:0000000000400c50 t _GLOBAL__I__Z9print_vecRKSt6vectorIiSaIiEE3 vec:0000000000400b0c T _Z9print_inti4 vec:0000000000400b42 T _Z9print_strPc5 vec:0000000000400a84 T _Z9print_vecRKSt6vectorIiSaIiEE 3.7 c++filt命令：显示未重整(unmangled)的原函数声明123456789101112[root@lzv6 c++]# nm vec | grep &apos;print&apos;00000000004009e0 t _GLOBAL__I__Z9print_vecRKSt6vectorIiSaIiEE0000000000400b00 T _Z9print_inti0000000000400a90 T _Z9print_strPc0000000000400a10 T _Z9print_vecRKSt6vectorIiSaIiEE[root@lzv6 c++]# c++filt _Z9print_intiprint_int(int)[root@lzv6 c++]# nm vec | grep print | c++filt00000000004009e0 t global constructors keyed to _Z9print_vecRKSt6vectorIiSaIiEE0000000000400b00 T print_int(int)0000000000400a90 T print_str(char*)0000000000400a10 T print_vec(std::vector&lt;int, std::allocator&lt;int&gt; &gt; const&amp;) 3.8 nm命令：显示目标文件的所有符号清单123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117[root@lzv6 c++]# nm -o vecvec:0000000000602460 d _DYNAMICvec:0000000000602628 d _GLOBAL_OFFSET_TABLE_vec:0000000000400c50 t _GLOBAL__I__Z9print_vecRKSt6vectorIiSaIiEEvec:00000000004019b8 R _IO_stdin_usedvec: w _Jv_RegisterClassesvec: U _Unwind_Resume@@GCC_3.0vec:0000000000400c10 t _Z41__static_initialization_and_destruction_0iivec:0000000000400b0c T _Z9print_intivec:0000000000400b42 T _Z9print_strPcvec:0000000000400a84 T _Z9print_vecRKSt6vectorIiSaIiEEvec:0000000000401504 W _ZN9__gnu_cxx13new_allocatorIiE10deallocateEPimvec:00000000004014b6 W _ZN9__gnu_cxx13new_allocatorIiE7destroyEPivec:00000000004015e8 W _ZN9__gnu_cxx13new_allocatorIiE8allocateEmPKvvec:0000000000400eae W _ZN9__gnu_cxx13new_allocatorIiE9constructEPiRKivec:0000000000401664 W _ZN9__gnu_cxx13new_allocatorIiEC1Evvec:0000000000401664 W _ZN9__gnu_cxx13new_allocatorIiEC2Evvec:00000000004014fa W _ZN9__gnu_cxx13new_allocatorIiED1Evvec:00000000004014fa W _ZN9__gnu_cxx13new_allocatorIiED2Evvec:00000000004014c4 W _ZN9__gnu_cxx17__normal_iteratorIPiSt6vectorIiSaIiEEEC1ERKS1_vec:00000000004014c4 W _ZN9__gnu_cxx17__normal_iteratorIPiSt6vectorIiSaIiEEEC2ERKS1_vec:00000000004013fb W _ZN9__gnu_cxxmiIPiSt6vectorIiSaIiEEEENS_17__normal_iteratorIT_T0_E15difference_typeERKS8_SB_vec:00000000004016bc W _ZNK9__gnu_cxx13new_allocatorIiE8max_sizeEvvec:00000000004012a6 W _ZNK9__gnu_cxx17__normal_iteratorIPiSt6vectorIiSaIiEEE4baseEvvec:00000000004012fa W _ZNK9__gnu_cxx17__normal_iteratorIPiSt6vectorIiSaIiEEEdeEvvec:00000000004016ae W _ZNKSt12_Vector_baseIiSaIiEE19_M_get_Tp_allocatorEvvec:000000000040130c W _ZNKSt6vectorIiSaIiEE12_M_check_lenEmPKcvec:0000000000400c78 W _ZNKSt6vectorIiSaIiEE4sizeEvvec:000000000040159a W _ZNKSt6vectorIiSaIiEE8max_sizeEvvec:0000000000400ca2 W _ZNKSt6vectorIiSaIiEEixEmvec:00000000004014e0 W _ZNSaIiEC1Evvec:00000000004014e0 W _ZNSaIiEC2Evvec:0000000000401232 W _ZNSaIiED1Evvec:0000000000401232 W _ZNSaIiED2Evvec: U _ZNSolsEi@@GLIBCXX_3.4vec:0000000000401861 W _ZNSt11__copy_moveILb0ELb1ESt26random_access_iterator_tagE8__copy_mIiEEPT_PKS3_S6_S4_vec:0000000000401526 W _ZNSt12_Destroy_auxILb1EE9__destroyIPiEEvT_S3_vec:0000000000401442 W _ZNSt12_Vector_baseIiSaIiEE11_M_allocateEmvec:00000000004011f4 W _ZNSt12_Vector_baseIiSaIiEE12_Vector_implC1Evvec:00000000004011f4 W _ZNSt12_Vector_baseIiSaIiEE12_Vector_implC2Evvec:0000000000400dc4 W _ZNSt12_Vector_baseIiSaIiEE12_Vector_implD1Evvec:0000000000400dc4 W _ZNSt12_Vector_baseIiSaIiEE12_Vector_implD2Evvec:000000000040124c W _ZNSt12_Vector_baseIiSaIiEE13_M_deallocateEPimvec:0000000000400e76 W _ZNSt12_Vector_baseIiSaIiEE19_M_get_Tp_allocatorEvvec:0000000000400dde W _ZNSt12_Vector_baseIiSaIiEEC1Evvec:0000000000400dde W _ZNSt12_Vector_baseIiSaIiEEC2Evvec:0000000000400df8 W _ZNSt12_Vector_baseIiSaIiEED1Evvec:0000000000400df8 W _ZNSt12_Vector_baseIiSaIiEED2Evvec:0000000000401534 W _ZNSt12__miter_baseIPiLb0EE3__bES0_vec:000000000040166e W _ZNSt12__niter_baseIPiLb0EE3__bES0_vec:00000000004016fd W _ZNSt20__copy_move_backwardILb0ELb1ESt26random_access_iterator_tagE13__copy_move_bIiEEPT_PKS3_S6_S4_vec:0000000000401765 W _ZNSt20__uninitialized_copyILb1EE18uninitialized_copyIPiS2_EET0_T_S4_S3_vec:0000000000400ee6 W _ZNSt6vectorIiSaIiEE13_M_insert_auxEN9__gnu_cxx17__normal_iteratorIPiS1_EERKivec:00000000004011ca W _ZNSt6vectorIiSaIiEE3endEvvec:00000000004013d6 W _ZNSt6vectorIiSaIiEE5beginEvvec:0000000000400d4a W _ZNSt6vectorIiSaIiEE9push_backERKivec:0000000000400cc2 W _ZNSt6vectorIiSaIiEEC1Evvec:0000000000400cc2 W _ZNSt6vectorIiSaIiEEC2Evvec:0000000000400cdc W _ZNSt6vectorIiSaIiEED1Evvec:0000000000400cdc W _ZNSt6vectorIiSaIiEED2Evvec: U _ZNSt8ios_base4InitC1Ev@@GLIBCXX_3.4vec: U _ZNSt8ios_base4InitD1Ev@@GLIBCXX_3.4vec:0000000000401830 W _ZSt13__copy_move_aILb0EPiS0_ET1_T0_S2_S1_vec:00000000004012b4 W _ZSt13copy_backwardIPiS0_ET0_T_S2_S1_vec:00000000004017d8 W _ZSt14__copy_move_a2ILb0EPiS0_ET1_T0_S2_S1_vec: U _ZSt17__throw_bad_allocv@@GLIBCXX_3.4vec:00000000004016d0 W _ZSt18uninitialized_copyIPiS0_ET0_T_S2_S1_vec: U _ZSt20__throw_length_errorPKc@@GLIBCXX_3.4vec:000000000040167c W _ZSt22__copy_move_backward_aILb0EPiS0_ET1_T0_S2_S1_vec:0000000000401633 W _ZSt22__uninitialized_copy_aIPiS0_iET0_T_S2_S1_RSaIT1_Evec:000000000040147a W _ZSt22__uninitialized_move_aIPiS0_SaIiEET0_T_S3_S2_RT1_vec:0000000000401542 W _ZSt23__copy_move_backward_a2ILb0EPiS0_ET1_T0_S2_S1_vec:00000000004015bc W _ZSt3maxImERKT_S2_S2_vec:0000000000401792 W _ZSt4copyIPiS0_ET0_T_S2_S1_vec:00000000006026e0 B _ZSt4cout@@GLIBCXX_3.4vec:0000000000401280 W _ZSt8_DestroyIPiEvT_S1_vec:0000000000400e84 W _ZSt8_DestroyIPiiEvT_S1_RSaIT0_Evec:0000000000602800 b _ZStL8__ioinitvec: U _ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc@@GLIBCXX_3.4vec: U _ZdlPv@@GLIBCXX_3.4vec: U _Znwm@@GLIBCXX_3.4vec:0000000000400c65 W _ZnwmPvvec:0000000000602440 d __CTOR_END__vec:0000000000602430 d __CTOR_LIST__vec:0000000000602450 D __DTOR_END__vec:0000000000602448 d __DTOR_LIST__vec:00000000004023d0 r __FRAME_END__vec:0000000000602458 d __JCR_END__vec:0000000000602458 d __JCR_LIST__vec:00000000006026c4 A __bss_startvec: U __cxa_atexit@@GLIBC_2.2.5vec: U __cxa_begin_catch@@CXXABI_1.3vec: U __cxa_end_catch@@CXXABI_1.3vec: U __cxa_rethrow@@CXXABI_1.3vec:00000000006026c0 D __data_startvec:0000000000401970 t __do_global_ctors_auxvec:00000000004009f0 t __do_global_dtors_auxvec:00000000004019c0 R __dso_handlevec: w __gmon_start__vec: U __gxx_personality_v0@@CXXABI_1.3vec:000000000060242c d __init_array_endvec:000000000060242c d __init_array_startvec:00000000004018d0 T __libc_csu_finivec:00000000004018e0 T __libc_csu_initvec: U __libc_start_main@@GLIBC_2.2.5vec:00000000006026c4 A _edatavec:0000000000602808 A _endvec:00000000004019a8 T _finivec:0000000000400878 T _initvec:00000000004009a0 T _startvec:00000000004009cc t call_gmon_startvec:00000000006027f0 b completed.6349vec:00000000006026c0 W data_startvec:00000000006027f8 b dtor_idx.6351vec:0000000000400a60 t frame_dummyvec:0000000000400b7b T mainvec: U memmove@@GLIBC_2.2.5 3.9 strace命令：显示在预处理的时候读取的所有头文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154[root@lzv6 c++]# strace -f -e open cpp vec.cpp -o /dev/null 2&gt;&amp;1 | grep -v ENOENT | awk &apos;&#123;print $3&#125;&apos; ======attachedopen(&quot;/etc/ld.so.cache&quot;,open(&quot;/usr/lib64/libmpfr.so.1&quot;,open(&quot;/usr/lib64/libgmp.so.3&quot;,open(&quot;/lib64/libdl.so.2&quot;,open(&quot;/lib64/libc.so.6&quot;,open(&quot;/usr/lib/locale/locale-archive&quot;,open(&quot;/usr/share/locale/locale.alias&quot;,open(&quot;/usr/share/locale/zh_CN/LC_MESSAGES/gcc.mo&quot;,open(&quot;/usr/lib64/gconv/gconv-modules.cache&quot;,open(&quot;/proc/meminfo&quot;,open(&quot;/proc/meminfo&quot;,open(&quot;/proc/meminfo&quot;,open(&quot;/dev/null&quot;,open(&quot;vec.cpp&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/iostream&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/c++config.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/os_defines.h&quot;,open(&quot;/usr/include/features.h&quot;,open(&quot;/usr/include/sys/cdefs.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/include/gnu/stubs.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/include/gnu/stubs-64.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/cpu_defines.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/ostream&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/ios&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/iosfwd&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stringfwd.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/postypes.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cwchar&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cstddef&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/include/wchar.h&quot;,open(&quot;/usr/include/stdio.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stdarg.h&quot;,open(&quot;/usr/include/bits/wchar.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/include/xlocale.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/exception&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/char_traits.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_algobase.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cstddef&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/functexcept.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/exception_defines.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/cpp_type_traits.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/ext/type_traits.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/ext/numeric_traits.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_pair.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/move.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cstddef&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/concept_check.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_iterator_base_types.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cstddef&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_iterator_base_funcs.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_iterator.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/debug/debug.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cwchar&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cstddef&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/include/wchar.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/localefwd.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/c++locale.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/clocale&quot;,open(&quot;/usr/include/locale.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/include/bits/locale.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cstddef&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cctype&quot;,open(&quot;/usr/include/ctype.h&quot;,open(&quot;/usr/include/bits/types.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/include/bits/typesizes.h&quot;,open(&quot;/usr/include/endian.h&quot;,open(&quot;/usr/include/bits/endian.h&quot;,open(&quot;/usr/include/bits/byteswap.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/ios_base.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/ext/atomicity.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/gthr.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/gthr-default.h&quot;,open(&quot;/usr/include/pthread.h&quot;,open(&quot;/usr/include/sched.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/include/time.h&quot;,open(&quot;/usr/include/bits/sched.h&quot;,open(&quot;/usr/include/time.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/include/bits/time.h&quot;,open(&quot;/usr/include/bits/pthreadtypes.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/include/bits/setjmp.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/include/unistd.h&quot;,open(&quot;/usr/include/bits/posix_opt.h&quot;,open(&quot;/usr/include/bits/environments.h&quot;,open(&quot;/usr/include/bits/wordsize.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/include/bits/confname.h&quot;,open(&quot;/usr/include/getopt.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/atomic_word.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/locale_classes.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/string&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/allocator.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/c++allocator.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/ext/new_allocator.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/new&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cstddef&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/include/stddef.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/ostream_insert.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cxxabi-forced.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_function.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/backward/binders.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/basic_string.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/initializer_list&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/basic_string.tcc&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/locale_classes.tcc&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/streambuf&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/streambuf.tcc&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/basic_ios.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/locale_facets.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cwctype&quot;,open(&quot;/usr/include/wctype.h&quot;,open(&quot;/usr/include/wchar.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/cctype&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/ctype_base.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/streambuf_iterator.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/x86_64-redhat-linux/bits/ctype_inline.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/locale_facets.tcc&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/basic_ios.tcc&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/ostream.tcc&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/istream&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/istream.tcc&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/vector&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_construct.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_uninitialized.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_vector.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/stl_bvector.h&quot;,open(&quot;/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/bits/vector.tcc&quot;,detached(Child 测试代码： 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;vector&gt;void print_vec(const std::vector&lt;int&gt;&amp; vec)&#123; std::cout &lt;&lt; &quot;print vec : &quot;; size_t size = vec.size(); for(size_t i = 0; i&lt;size; i++) std::cout &lt;&lt; vec[i] &lt;&lt; &quot;\\t&quot;; std::cout &lt;&lt; &quot;\\n&quot;;&#125;void print_int(int i)&#123; std::cout&lt;&lt;&quot;print_int : &quot; &lt;&lt; i &lt;&lt; &quot;\\n&quot;; &#125;void print_str(char* str)&#123; std::cout&lt;&lt;&quot;print_str : &quot; &lt;&lt; str &lt;&lt; &quot;\\n&quot;; &#125;int main()&#123; std::vector&lt;int&gt; vec; vec.push_back(1); print_vec(vec); print_int(vec.size()); print_str(&quot;hello world!&quot;); return 0;&#125;//编译：//g++ -o vec vec.cpp","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"CENTOS","slug":"CENTOS","permalink":"https://lives.xtcgch.ink/tags/CENTOS/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 数据结构之平衡树篇","slug":"数据结构之平衡树篇-20181216","date":"2018-12-16T02:28:27.000Z","updated":"2021-10-10T08:29:47.361Z","comments":true,"path":"2018/12/16/数据结构之平衡树篇/","link":"","permalink":"https://lives.xtcgch.ink/2018/12/16/数据结构之平衡树篇/","excerpt":"摘要：平衡树是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。","text":"摘要：平衡树是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 1、脑图 2、简介平衡树，即平衡二叉树（Balanced Binary Tree），具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等。 最小二叉平衡树的节点的公式如下 F(n)=F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 3、旋转 3.1 LL（左左） X指的是一颗子树 y和z都是一个节点 K2是不符合平衡的节点 K1,K2,和子树X的位置分布为左 、左，即LL 代码实现： 12345678910111213static Node* left_left_rotation(AVLTree k2)&#123; AVLTree k1; k1 = k2-&gt;left; k2-&gt;left = k1-&gt;right; k1-&gt;right = k2; k2-&gt;height = MAX( HEIGHT(k2-&gt;left), HEIGHT(k2-&gt;right)) + 1; k1-&gt;height = MAX( HEIGHT(k1-&gt;left), k2-&gt;height) + 1; return k1;&#125; 3.2 RR（右右） Z指的是一颗子树 y和x都是一个节点 K1是不符合平衡的节点 K1,K2,和Z子树的位置分布为右、右，即RR 代码实现： 12345678910111213static Node* right_right_rotation(AVLTree k1)&#123; AVLTree k2; k2 = k1-&gt;right; k1-&gt;right = k2-&gt;left; k2-&gt;left = k1; k1-&gt;height = MAX( HEIGHT(k1-&gt;left), HEIGHT(k1-&gt;right)) + 1; k2-&gt;height = MAX( HEIGHT(k2-&gt;right), k1-&gt;height) + 1; return k2;&#125; 3.3 LR（RR+LL） A,B,C,D都是一个节点 K3是不符合平衡的节点 K1,K2,K3的位置感为左，右，即LR分布 123456static Node* left_right_rotation(AVLTree k3)&#123; k3-&gt;left = right_right_rotation(k3-&gt;left); return left_left_rotation(k3);&#125; 3.4 RL（LL+RR） A,B,C,D都是一个节点 K1是不符合平衡的节点 K1,K2,K3的位置分布为右，左，即RL 123456static Node* right_left_rotation(AVLTree k1)&#123; k1-&gt;right = left_left_rotation(k1-&gt;right); return right_right_rotation(k1);&#125; 4、例子依次添加”3,2,1,4,5,6,7,16,15,14,13,12,11,10,8,9” 到AVL树中，过程如下。 （1）添加3,2 （2）添加1 （3）添加4 （4）添加5 （5）添加6 （6）添加7 （7）添加16 （8）添加15—好像是RL，不是RR （9）添加14 （10）添加13 （11）添加12 （12）添加11 （13）添加10 （14）添加8 （15）添加9","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://lives.xtcgch.ink/tags/数据结构/"},{"name":"树","slug":"树","permalink":"https://lives.xtcgch.ink/tags/树/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【专项】 数据库之SQL","slug":"数据库之SQL-20181214","date":"2018-12-14T04:08:14.000Z","updated":"2021-10-10T14:42:40.627Z","comments":true,"path":"2018/12/14/数据库之SQL/","link":"","permalink":"https://lives.xtcgch.ink/2018/12/14/数据库之SQL/","excerpt":"摘要：SQL 是一门 ANSI 的标准计算机语言，用来访问和操作数据库系统。SQL 语句用于取回和更新数据库中的数据。SQL 可与数据库程序协同工作，比如 MS Access、DB2、Informix、MS SQL Server、Oracle、Sybase 以及其他数据库系统。除了 SQL 标准之外，大部分 SQL 数据库程序都拥有它们自己的私有扩展！","text":"摘要：SQL 是一门 ANSI 的标准计算机语言，用来访问和操作数据库系统。SQL 语句用于取回和更新数据库中的数据。SQL 可与数据库程序协同工作，比如 MS Access、DB2、Informix、MS SQL Server、Oracle、Sybase 以及其他数据库系统。除了 SQL 标准之外，大部分 SQL 数据库程序都拥有它们自己的私有扩展！ 1、脑图 2、分类2.1 DDL数据定义语言DDL用来创建数据库中的各种对象—–表、视图、 索引、同义词、聚簇等如： CREATE TABLE/VIEW/INDEX/SYN/CLUSTER | | | | | 表 视图 索引 同义词 簇 2.2 DML数据操纵语言DML主要有三种形式： 1) 插入：INSERT 2) 更新：UPDATE 3) 删除：DELETE 2.3 DQL数据查询语言DQL基本结构是由SELECT子句，FROM子句，WHERE 子句组成的查询块。 3、关键字3.1 DISTINCT（1）说明 在表中，一个列可能会包含多个重复值，DISTINCT 关键词用于返回唯一不同的值。 （2）用法 SELECT DISTINCT 列名称 FROM 表名称 （3）例子 SELECT DISTINCT Company FROM Orders 3.2 TOP（1）说明 SELECT TOP 子句用于规定要返回的记录的数目。可筛选指定数目或比例。注意：并非所有的数据库系统都支持 SELECT TOP 语句。 MySQL 支持 LIMIT 语句来选取指定的条数数据， Oracle 可以使用 ROWNUM 来选取。 （2）用法 MySQL：SELECT column_name(s) FROM table_name LIMIT number Oracle:SELECT column_name(s) FROM table_name WHERE ROWNUM &lt;= number （3）例子 SELECT * FROM Persons LIMIT 5 SELECT * FROM Persons WHERE ROWNUM &lt;= 5 SELECT TOP 50 PERCENT * FROM Persons 3.3 LIKE（1）说明 LIKE 操作符用于在 WHERE 子句中搜索列中的指定模式。 （2）用法 SELECT column_name(s) FROM table_name WHERE column_name LIKE pattern; （3）例子 SELECT * FROM Websites WHERE name LIKE ‘G%’;- 3.4 IN（1）说明 IN 操作符允许在 WHERE 子句中规定多个值。 （2）用法 SELECT column_name(s) FROM table_name WHERE column_name IN (value1,value2,…); （3）例子 SELECT * FROM Websites WHERE name IN (‘Google’,’菜鸟教程’); （4）in 与 = 相同点：均在WHERE中使用作为筛选条件之一、均是等于的含义 不同点：IN可以规定多个值，等于规定一个值 3.5 BETWEEN（1）说明 BETWEEN 操作符用于选取介于两个值之间的数据范围内的值。 （2）用法 SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2; （3）例子 SELECT * FROM Websites WHERE alexa BETWEEN 1 AND 20; SELECT * FROM Websites WHERE alexa NOT BETWEEN 1 AND 20; 3.6 Alias（1）说明 使用列别名和表别名来简化列名和表名。 （2）用法 SELECT column_name AS alias_name FROM table_name; SELECT column_name(s) FROM table_name AS alias_name; （3）例子 SELECT name AS n, country AS c FROM Websites; SELECT w.name, w.url, a.count, a.date FROM Websites AS w, access_log AS a WHERE a.site_id=w.id and w.name=”菜鸟教程”; 3.7 JOIN（1）说明 SQL JOIN 子句用于把来自两个或多个表的行结合起来，基于这些表之间的共同字段。 （2）用法 SELECT Websites.id, Websites.name, access_log.count, access_log.date FROM Websites INNER JOIN access_log ON Websites.id=access_log.site_id; （3）例子 （4）区别 INNER JOIN：如果表中有至少一个匹配，则返回行 LEFT JOIN：即使右表中没有匹配，也从左表返回所有的行 RIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行 FULL JOIN：只要其中一个表中存在匹配，则返回行 3.8 INNER JOIN（1）说明 INNER JOIN 关键字在表中存在至少一个匹配时返回行。 （2）用法 SELECT column_name(s) FROM table1 INNER JOIN table2 ON table1.column_name=table2.column_name; （3）例子 SELECT Websites.name, access_log.count, access_log.date FROM Websites INNER JOIN access_log ON Websites.id=access_log.site_id ORDER BY access_log.count; 3.9 LEFT JOIN（1）说明 LEFT JOIN 关键字从左表（table1）返回所有的行，即使右表（table2）中没有匹配。如果右表中没有匹配，则结果为 NULL。 （2）用法 SELECT column_name(s) FROM table1 LEFT JOIN table2 ON table1.column_name=table2.column_name; （3）例子 SELECT Websites.name, access_log.count, access_log.date FROM Websites LEFT JOIN access_log ON Websites.id=access_log.site_id ORDER BY access_log.count DESC; 3.10 RIGHT JOIN（1）说明 RIGHT JOIN 关键字从右表（table2）返回所有的行，即使左表（table1）中没有匹配。如果左表中没有匹配，则结果为 NULL。 （2）用法 SELECT column_name(s) FROM table1 RIGHT JOIN table2 ON table1.column_name=table2.column_name; （3）例子 SELECT Websites.name, access_log.count, access_log.date FROM access_log RIGHT JOIN Websites ON access_log.site_id=Websites.id ORDER BY access_log.count DESC; 3.11 FULL JOIN（1）说明 FULL OUTER JOIN 关键字只要左表（table1）和右表（table2）其中一个表中存在匹配，则返回行. FULL OUTER JOIN 关键字结合了 LEFT JOIN 和 RIGHT JOIN 的结果。 （2）用法 SELECT column_name(s) FROM table1 FULL OUTER JOIN table2 ON table1.column_name=table2.column_name; （3）例子 SELECT Websites.name, access_log.count, access_log.date FROM Websites FULL OUTER JOIN access_log ON Websites.id=access_log.site_idORDER BY access_log.count DESC; 3.12 UNION（1）说明 SQL UNION 操作符合并两个或多个 SELECT 语句的结果。 请注意，UNION 内部的每个 SELECT 语句必须拥有相同数量的列。列也必须拥有相似的数据类型。同时，每个 SELECT 语句中的列的顺序必须相同。 （2）用法 SELECT column_name(s) FROM table1 UNION SELECT column_name(s) FROM table2; （3）例子 SELECT country FROM Websites UNION SELECT country FROM apps ORDER BY country; 3.13 SELECT INTO（1）说明 通过 SQL，您可以从一个表复制信息到另一个表。 SELECT INTO 语句从一个表复制数据，然后把数据插入到另一个新表中。 （2）用法 SELECT * INTO newtable [IN externaldb] FROM table1; SELECT column_name(s) INTO newtable [IN externaldb] FROM table1; （3）例子 SELECT * INTO WebsitesBackup2016 FROM Websites; SELECT name, url INTO WebsitesBackup2016 FROM Websites; 3.14 NULL（1）说明 NULL 值的处理方式与其他值不同。 NULL 用作未知的或不适用的值的占位符。 （2）用法 （3）例子 IS NOT NULL:SELECT LastName,FirstName,Address FROM Persons WHERE Address IS NOT NULL IS NULL: SELECT LastName,FirstName,Address FROM Persons WHERE Address IS NULL 4、函数4.1 时间函数（1）用法 NOW(): CURDATE()： CURTIME()： DATE()： EXTRACT()： DATE_ADD()： DATE_SUB()： DATEDIFF()： DATE_FORMAT()： （2）例子 4.2 AVG()（1）说明 AVG() 函数返回数值列的平均值。 （2）用法 SELECT AVG(column_name) FROM table_name （3）例子 SELECT AVG(count) AS CountAverage FROM access_log; 4.3 COUNT()（1）说明 COUNT() 函数返回匹配指定条件的行数。 （2）用法 SELECT COUNT(column_name) FROM table_name; SELECT COUNT( * ) FROM table_name; SELECT COUNT(DISTINCT column_name) FROM table_name; （3）例子 SELECT COUNT(count) AS nums FROM access_log WHERE site_id=3; SELECT COUNT( * ) AS nums FROM access_log; SELECT COUNT(DISTINCT site_id) AS nums FROM access_log; 4.4 FIRST()（1）说明 FIRST() 函数返回指定的列中第一个记录的值。注意：只有 MS Access 支持 FIRST() 函数 （2）用法 SELECT column_name FROM table_name ORDER BY column_name ASC LIMIT 1; SELECT column_name FROM table_name ORDER BY column_name ASC WHERE ROWNUM &lt;=1 （3）例子 SELECT name FROM Websites ORDER BY id ASC LIMIT 1; SELECT name FROM Websites ORDER BY id ASC WHERE ROWNUM &lt;=1; 4.5 LAST()（1）说明 LAST() 函数返回指定的列中最后一个记录的值。注意：只有 MS Access 支持 LAST() 函数。 （2）用法 SELECT column_name FROM table_name ORDER BY column_name DESC LIMIT 1; SELECT column_name FROM table_name ORDER BY column_name DESC WHERE ROWNUM &lt;=1; （3）例子 SELECT name FROM Websites ORDER BY id DESC LIMIT 1; SELECT name FROM Websites ORDER BY id DESC WHERE ROWNUM &lt;=1; 4.6 MAX()（1）说明 MAX() 函数返回指定列的最大值。 （2）用法 SELECT MAX(column_name) FROM table_name; （3）例子 SELECT MAX(alexa) AS max_alexa FROM Websites; 4.7 MIN()（1）说明 MIN() 函数返回指定列的最小值。 （2）用法 SELECT MIN(column_name) FROM table_name; （3）例子 SELECT MIN(alexa) AS min_alexa FROM Websites; 4.8 值为NULL的判断（1）说明 （2）用法 IFNULL() COALESCE() NVL() （3）例子 SELECT ProductName,UnitPrice * (UnitsInStock+IFNULL(UnitsOnOrder,0)) FROM Products SELECT ProductName,UnitPrice * (UnitsInStock+COALESCE(UnitsOnOrder,0)) FROM Products SELECT ProductName,UnitPrice * (UnitsInStock+NVL(UnitsOnOrder,0)) FROM Products 4.9 SUM()（1）说明 SUM() 函数返回数值列的总数。 （2）用法 SELECT SUM(column_name) FROM table_name;- （3）例子 SELECT SUM(count) AS nums FROM access_log;- 4.10 HAVING（1）说明 在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与聚合函数一起使用。 HAVING 子句可以让我们筛选分组后的各组数据。 （2）用法 SELECT column_name, aggregate_function(column_name) FROM table_name WHERE column_name operator value GROUP BY column_name HAVING aggregate_function(column_name) operator value; （3）例子 SELECT Websites.name, Websites.url, SUM(access_log.count) AS nums FROM (access_log INNER JOIN Websites ON access_log.site_id=Websites.id) GROUP BY Websites.name HAVING SUM(access_log.count) &gt; 200; 4.11 UCASE()（1）说明 UCASE() 函数把字段的值转换为大写。 （2）用法 SELECT UCASE(column_name) FROM table_name; （3）例子 SELECT UCASE(name) AS site_title, url FROM Websites; 4.12 LCASE()（1）说明 LCASE() 函数把字段的值转换为小写。 （2）用法 SELECT LCASE(column_name) FROM table_name; （3）例子 SELECT LCASE(name) AS site_title, url FROM Websites; 4.13 MID()（1）说明 MID() 函数用于从文本字段中提取字符。 （2）用法 SELECT MID(column_name,start[,length]) FROM table_name; （3）例子 SELECT MID(name,1,4) AS ShortTitle FROM Websites; 4.14 LEN()（1）说明 LEN() 函数返回文本字段中值的长度。 （2）用法 SELECT LEN(column_name) FROM table_name; （3）例子 SELECT name, LENGTH(url) as LengthOfURL FROM Websites; 4.15 ROUND()（1）说明 ROUND 函数用于把数值字段舍入为指定的小数位数。 （2）用法 SELECT ROUND(column_name,decimals) FROM table_name （3）例子 SELECT ProductName, ROUND(UnitPrice,0) as UnitPrice FROM Products- 4.16 NOW()（1）说明 NOW() 函数返回当前系统的日期和时间。 （2）用法 SELECT NOW() FROM table_name （3）例子 SELECT name, url, Now() AS date FROM Websites; 4.17 FORMAT()（1）说明 FORMAT() 函数用于对字段的显示进行格式化。 （2）用法 SELECT FORMAT(column_name,format) FROM table_name （3）例子 SELECT ProductName, UnitPrice, FORMAT(Now(),’YYYY-MM-DD’) as PerDate FROM Products 5、常见功能5.1 建库（1）用法 CREATE DATABASE （2）例子 5.2 修改库（1）用法 ALTER DATABASE （2）例子 5.3 删库（1）用法 DROP DATABASE （2）例子 5.4 建表（1）用法 CREATE TABLE （2）例子 5.5 修改表（1）用法 ALTER TABLE （2）例子 5.6 删表（1）用法 DROP TABLE （2）例子 5.7 建索引（1）用法 CREATE INDEX （2）例子 5.8 删索引（1）用法 DROP INDEX （2）例子 5.9 创建视图（1）用法 1234CREATE VIEW view_name ASSELECT column_name(s)FROM table_nameWHERE condition （2）例子 1234CREATE VIEW [Current Product List] ASSELECT ProductID,ProductNameFROM ProductsWHERE Discontinued=No 5.10 更新视图（1）用法 1234CREATE OR REPLACE VIEW view_name ASSELECT column_name(s)FROM table_nameWHERE condition （2）例子 1234CREATE VIEW [Current Product List] ASSELECT ProductID,ProductName,CategoryFROM ProductsWHERE Discontinued=No 5.11 删除视图（1）用法 DROP VIEW view_name （2）例子 6、实用例子1、查看表结构 show create table xxx （详细，推荐） describe xxx （简单） 2、查看一条数据的详细信息 select from where *** \\G (\\G的效果是竖直排列，左边是表头，右边是数据) 3、连接mysql数据库 mysql -hxxx(IP) -Pxxx(端口) -uxxx(用户名) -pxxx(密码) -A –default-charset=utf8 xxx(dbname) 4、合计 select sum(amount),count(1),date from xxx group by date 5、选择判断 select if(sex = 1,amount,-amount) from xxx where id = xxx 6、包括所有在 TableA 中但不在 TableB和TableC 中的行并消除所有重复行而派生出一个结果表1(select a from tableA ) except (select a from tableB) except (select a from tableC) 7、随机取出10条数据1select top 10 * from tablename order by newid() 8、初始化表table11TRUNCATE TABLE table1 9、选择第10到15的记录1select top 5 * from (select top 15 * from table order by id asc) table_别名 order by id desc 10、从两表中查询数据1select a.name , b.class from Userinfo a inner join Grade b using(userno)","categories":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://lives.xtcgch.ink/tags/数据库/"},{"name":"SQL","slug":"SQL","permalink":"https://lives.xtcgch.ink/tags/SQL/"}],"keywords":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}]},{"title":"【原理】 网络通信之信号驱动IO篇","slug":"网络通信之信号驱动IO篇-20181207","date":"2018-12-07T03:07:49.000Z","updated":"2021-10-10T08:29:00.972Z","comments":true,"path":"2018/12/07/网络通信之信号驱动IO篇/","link":"","permalink":"https://lives.xtcgch.ink/2018/12/07/网络通信之信号驱动IO篇/","excerpt":"摘要：","text":"摘要： 1、脑图 2、概述 3、原理首先来看信号驱动IO的模型图： 解读： 首先，开启套接字的信号驱动式IO功能，并通过sigaction系统调用安装一个信号处理函数。此时，系统调用立即返回，进程继续工作，即未被阻塞。 当内核数据包准备好之后，内核就为该进程准备一个sigio信号，进程的信号处理函数捕获到该信号时，就进入信号处理函数，然后调用recvfrom进行 读取数据。 当数据完成从内核空间复制到用户空间时 4、tcp套接字的sigio信号 5、udp套接字的sigio信号 6、demo 7、总结","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"网络通信","slug":"网络通信","permalink":"https://lives.xtcgch.ink/tags/网络通信/"},{"name":"IO","slug":"IO","permalink":"https://lives.xtcgch.ink/tags/IO/"},{"name":"网络编程","slug":"网络编程","permalink":"https://lives.xtcgch.ink/tags/网络编程/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 Linux之shell命令","slug":"Linux之shell命令-20181206","date":"2018-12-06T10:47:09.000Z","updated":"2021-10-11T14:40:45.437Z","comments":true,"path":"2018/12/06/Linux之shell命令/","link":"","permalink":"https://lives.xtcgch.ink/2018/12/06/Linux之shell命令/","excerpt":"摘要：本文主要记录centos系统中常用的shell命令。","text":"摘要：本文主要记录centos系统中常用的shell命令。 一、进程1、查看进程状态ps基本命令（1）ps -A：查看所有进程（包括pid，time）（2）ps -a：查看除控制进程和无终端进程外的所有进程（3）ps -d：查看除控制进程外的所有进程（4）ps -ef：查看所有进程的全部信息（5）ps -l：长格式输出（6）ps -f：ps常用命令：（1）ps -aux –sort -pcpu | less | head -n 5：根据cpu占用率降序排序（2） ps -aux –sort -pmem | less：根据内存占用率降序排序（3）ps -aux –sort -pcpu,+pmem | head -n 10：查询cpu和内存占用率最高的10个进程（4）ps -C getty：getty为进程启动的命令，该语句为筛选getty命令启动的进程（5）watch -n 1 ‘ps -aux –sort -pmem, -pcpu | less | head 20’：实时监控进程，根据cpu和内存使用率来排序，1秒刷新一次，只显示前20条（6）查看特定进程的情况（7）根据进程名查看进程pid： pgrep -f processname ps -ef | grep $process | grep -v grep | awk ‘{print $2}’ 查看系统所有进程的pid：top、ps -ef查看当前用户进程：ps -a把进程状态输出到文件：查看进程的running,sleeping,stopped,zombie状态：top | grep zombie 2、杀死进程kill pidkill -9 pid 3、daemon process（守护进程） 二、查看磁盘空间1、df（1）df（2）df -h（因子是1024）（3）df -H（因子是1000） 2、du（1）du（2）du -a：可显示个别文件的大小（3）du -c：可查看所有文件大小总和（4）du -s ：只显示合计大小 3、常用命令（1）du –max-depth=1 -h：查看当前目录下总大小和当前目录下深度为1的目录或文件的大小（2）du -sh：查看当前目录下总大小（3）du -h –max-depth=0：查看当前目录下总大小（4）du -sh /root/sw ：查看目标目录的大小 三、挂载1、mount [-t vfstype] [-o options] device dir（1）挂载iso文件mount -o loop -t iso9660 /home/sunky/mydisk.iso /mnt/vcdrom注释：光盘或光盘镜像：iso9660，loop：用来把一个文件当成硬盘分区挂接上系统 （2）挂接移动硬盘无中文：12mount -t ntfs /dev/sdc1 /mnt/usbhd1mount -t vfat /dev/sdc5 /mnt/usbhd2 有中文：mount -t ntfs -o iocharset=cp936 /dev/sdc1 /mnt/usbhd1 （3）挂载光驱mount /dev/hdc /mnt/cdrom （4）挂载软驱mount /dev/fd0 /mnt/floppy 附：（1）挂载解决中文问题：使用–o iocharset=cp936或–o iocharset=utf-8 2、umount（1）umount 设备：umount /dev/hda5（2）umount 目录：umount /mnt/hda5（3）umount 设备 目录：umount /dev/hda5 /mnt/hda5 四、perl1、perl脚本（1）执行linux命令 （2） 2、perl实现daemon参考文献：https://blog.csdn.net/xuleilx/article/details/8258798 – 五、软件管理1、安装rpm -ivh 2、更新rpm -Uvh 3、删除rpm -e 4、查询一个包是否被安装rpm -q &lt; rpm package name&gt; 5、得到被安装的包的信息rpm -qi &lt; rpm package name&gt; 6、列出该包中有哪些文件rpm -ql &lt; rpm package name&gt; 7、列出所有被安装的rpm packagerpm -qa 8、显示与目标包名相关的包rpm -qa | grep 包名 六、查看程序的安装1、安装路径rpm -qal |grep 2、软件版本软件名 -V(–version) 七、tcp连接状态1、查看8080端口上已经建立连接的tcp连接数netstat –nat | grep 8080 | grep ESTABLISHED| wc -l 八、网络相关121、netstat -rn 输出路由表2、netstat -ap 在上面命令的基础上列出连接的PID(进程号) 九、查看系统信息1、内核及发行版1234- uname -a - uname -sr - cat /etc/issue - lsb_release -a 2、CPU硬件cat /proc/cpuinfo 3、内存情况cat /proc/meminfo 4、磁盘、Swap情况fdisk -lfree -h 5、网络情况 ip a netstat -tln netstat -an | grep 80 | grep CONNECTED 6、网络协议和端口方面（root）： ss -l ss -ta ss -s 7、网络路由（root）： route -n 8、查看打开文件： lsof -i:22 查看物理CPU的个数 ：cat /proc/cpuinfo |grep “physical id”|sort |uniq|wc -l查看逻辑CPU的个数 ：cat /proc/cpuinfo |grep “processor”|wc -l查看CPU是几核：cat /proc/cpuinfo |grep physical |sort -u |wc -l 此命令为查看CPU的个数。查看内存大小：cat /proc/meminfo | grep -i “memtotal”查看内存插槽：dmidecode -t memory，dmidecode -t 17查看有内存条的插槽：dmidecode -t 17 | grep -i size CPU内存负载情况-vmstat -afsd内存使用情况：free 9、任务管理器top 查看特定进程：top -p pid 查看实时消息：top 其他1、发送http请求 curl:传送门 get请求：curl命令默认下就是使用get方式发送http请求。 1curl www.baidu.com post请求:使用-d 后面带 参数。 1curl -d &quot;param1=value1¶m2=value2&quot; www.baidu.com wget get请求： 最基本使用：wget www.baidu.com get方式并指定下载的文件名：wget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080 post请求：1wget --post-data=&quot;user=user1&amp;pass=pass1&amp;submit=Login&quot; http://domain.com/path/page_need_login.php 一些例子 查看xx进程的信息 1ps -ef | grep xxx 查看日志文件的最新动态 1tail -f xxx.log 管道的问题12345# file:note1234567890abcdefghij9876543210jihgfedcba 123456789# file；test.sh#! /bin/bashindex=0cat note | while read paramdo let index++ echo &quot;inter:index($index) param($param)&quot;doneecho &quot;outer:index($index)&quot; 输出： 12345inter:index(1) param(1234567890)inter:index(2) param(abcdefghij)inter:index(3) param(9876543210)inter:index(4) param(jihgfedcba)outer:index(0) 原因： 当启用管道时，会生成一个subshell，while循环的代码在subshell中执行，那么变量index也是在subshell中被修改， while循环结束后，回到主shell，index没有被修改，也就是说，两个index不是同一个index while中修改的index是外层index的副本 修正后的代码如下; 123456789# file；test.sh#! /bin/bashindex=0while read paramdo let index++ echo &quot;inter:index($index) param($param)&quot;done &lt; noteecho &quot;outer:index($index)&quot; 输出如下： 12345inter:index(1) param(1234567890)inter:index(2) param(abcdefghij)inter:index(3) param(9876543210)inter:index(4) param(jihgfedcba)outer:index(4) 下面是一本正经地开始当cv战士了 Shell 不完整教程 传送门 Shell 变量变量名的命名须遵循如下规则： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 变量名和等号之间不能有空格 不能使用标点符号 不能使用bash里的关键字（可用help命令查看保留关键字） 只读变量：readonly 12myUrl=&quot;http://www.google.com&quot;readonly myUrl 删除变量 使用 unset 命令可以删除变量。 unset 命令不能删除只读变量 1unset variable_name Shell 字符串 获取字符串长度 12string=&quot;abcd&quot;echo $&#123;#string&#125; #输出 4 提取子字符串 12string=&quot;runoob is a great site&quot;echo $&#123;string:1:4&#125; # 输出 unoo 查找子字符串 查找字符 i 或 o 的位置(哪个字母先出现就计算哪个)： 12string=&quot;runoob is a great site&quot;echo `expr index &quot;$string&quot; io` # 输出 4 Shell 数组 定义数组 短小型： 1array_name=(value0 value1 value2 value3) 随意型：123456array_name=(value0value1value2value3) 折腾型：123456array_name[0]=value0array_name[1]=value1 . . .array_name[n]=valuen 读取数组 1valuen=$&#123;array_name[n]&#125; 使用 @ 符号可以获取数组中的所有元素 1echo $&#123;array_name[@]&#125; 获取数组的长度 123456# 取得数组元素的个数length=$&#123;#array_name[@]&#125;# 或者length=$&#123;#array_name[*]&#125;# 取得数组单个元素的长度lengthn=$&#123;#array_name[n]&#125; Shell 注释 单行注释 123456789101112#--------------------------------------------# 这是一个注释# author：# slogan：学的不仅是技术，更是梦想！#--------------------------------------------##### 用户配置区 开始 ######## 这里可以添加脚本描述信息# ###### 用户配置区 结束 ##### 多行注释 一本正经型：12345:&lt;&lt;EOF注释内容...注释内容...注释内容...EOF 耍小聪明型：1234567891011:&lt;&lt;&apos;注释内容...注释内容...注释内容...&apos;:&lt;&lt;!注释内容...注释内容...注释内容...! Shell 传递参数向脚本传递参数，脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推 直接上代码： shell脚本内容12345678#!/bin/bash# author:echo &quot;Shell 传递参数实例！&quot;;echo &quot;执行的文件名：$0&quot;;echo &quot;第一个参数为：$1&quot;;echo &quot;第二个参数为：$2&quot;;echo &quot;第三个参数为：$3&quot;; 启动命令1./test.sh 1 2 3 参数处理 说明 $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 demo:12345678910111213#!/bin/bash# author:# url:echo &quot;-- \\$* 演示 ---&quot;for i in &quot;$*&quot;; do echo $idoneecho &quot;-- \\$@ 演示 ---&quot;for i in &quot;$@&quot;; do echo $idone $* 与 $@ 区别和联系： 相同点：都是引用所有参数。 不同点：只有在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 “ * “ 等价于 “1 2 3”（传递了一个参数），而 “@” 等价于 “1” “2” “3”（传递了三个参数）。 Shell 基本运算符 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符 原生bash不支持简单的数学运算，但是可以通过其他命令来实现，例如 awk 和 expr，expr 最常用。 算术运算符123456789101112131415161718192021222324252627282930#!/bin/bash# author:菜鸟教程# url:www.runoob.coma=10b=20val=`expr $a + $b`echo &quot;a + b : $val&quot;val=`expr $a - $b`echo &quot;a - b : $val&quot;val=`expr $a \\* $b`echo &quot;a * b : $val&quot;val=`expr $b / $a`echo &quot;b / a : $val&quot;val=`expr $b % $a`echo &quot;b % a : $val&quot;if [ $a == $b ]then echo &quot;a 等于 b&quot;fiif [ $a != $b ]then echo &quot;a 不等于 b&quot;fi 注意： 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。 完整的表达式要被 包含，注意这个字符不是常用的单引号，在 Esc 键下边。 乘号(*)前边必须加反斜杠()才能实现乘法运算 关系运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否不相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 上代码：12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bash# author:# url:a=10b=20if [ $a -eq $b ]then echo &quot;$a -eq $b : a 等于 b&quot;else echo &quot;$a -eq $b: a 不等于 b&quot;fiif [ $a -ne $b ]then echo &quot;$a -ne $b: a 不等于 b&quot;else echo &quot;$a -ne $b : a 等于 b&quot;fiif [ $a -gt $b ]then echo &quot;$a -gt $b: a 大于 b&quot;else echo &quot;$a -gt $b: a 不大于 b&quot;fiif [ $a -lt $b ]then echo &quot;$a -lt $b: a 小于 b&quot;else echo &quot;$a -lt $b: a 不小于 b&quot;fiif [ $a -ge $b ]then echo &quot;$a -ge $b: a 大于或等于 b&quot;else echo &quot;$a -ge $b: a 小于 b&quot;fiif [ $a -le $b ]then echo &quot;$a -le $b: a 小于或等于 b&quot;else echo &quot;$a -le $b: a 大于 b&quot;fi 布尔运算符 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 上代码：12345678910111213141516171819202122232425262728293031#!/bin/bash# author:# url:a=10b=20if [ $a != $b ]then echo &quot;$a != $b : a 不等于 b&quot;else echo &quot;$a != $b: a 等于 b&quot;fiif [ $a -lt 100 -a $b -gt 15 ]then echo &quot;$a 小于 100 且 $b 大于 15 : 返回 true&quot;else echo &quot;$a 小于 100 且 $b 大于 15 : 返回 false&quot;fiif [ $a -lt 100 -o $b -gt 100 ]then echo &quot;$a 小于 100 或 $b 大于 100 : 返回 true&quot;else echo &quot;$a 小于 100 或 $b 大于 100 : 返回 false&quot;fiif [ $a -lt 5 -o $b -gt 100 ]then echo &quot;$a 小于 5 或 $b 大于 100 : 返回 true&quot;else echo &quot;$a 小于 5 或 $b 大于 100 : 返回 false&quot;fi 逻辑运算符 运算符 说明 举例 &amp;&amp; 逻辑的 AND [[ $a -lt 100 &amp;&amp; $b -gt 100 ]] 返回 false 两个或符合 逻辑的 OR [[ $a -lt 100 $b -gt 100 ]] 返回 true 简单的例子：1234567891011121314151617181920#!/bin/bash# author:# url:a=10b=20if [[ $a -lt 100 &amp;&amp; $b -gt 100 ]]then echo &quot;返回 true&quot;else echo &quot;返回 false&quot;fiif [[ $a -lt 100 || $b -gt 100 ]]then echo &quot;返回 true&quot;else echo &quot;返回 false&quot;fi 字符串运算符 运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否为0，不为0返回 true。 [ -n “$a” ] 返回 true。 $ 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 上代码：12345678910111213141516171819202122232425262728293031323334353637#!/bin/bash# author:# url:a=&quot;abc&quot;b=&quot;efg&quot;if [ $a = $b ]then echo &quot;$a = $b : a 等于 b&quot;else echo &quot;$a = $b: a 不等于 b&quot;fiif [ $a != $b ]then echo &quot;$a != $b : a 不等于 b&quot;else echo &quot;$a != $b: a 等于 b&quot;fiif [ -z $a ]then echo &quot;-z $a : 字符串长度为 0&quot;else echo &quot;-z $a : 字符串长度不为 0&quot;fiif [ -n &quot;$a&quot; ]then echo &quot;-n $a : 字符串长度不为 0&quot;else echo &quot;-n $a : 字符串长度为 0&quot;fiif [ $a ]then echo &quot;$a : 字符串不为空&quot;else echo &quot;$a : 字符串为空&quot;fi 文件测试运算符 操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/bash# author:# url:file=&quot;/var/www/runoob/test.sh&quot;if [ -r $file ]then echo &quot;文件可读&quot;else echo &quot;文件不可读&quot;fiif [ -w $file ]then echo &quot;文件可写&quot;else echo &quot;文件不可写&quot;fiif [ -x $file ]then echo &quot;文件可执行&quot;else echo &quot;文件不可执行&quot;fiif [ -f $file ]then echo &quot;文件为普通文件&quot;else echo &quot;文件为特殊文件&quot;fiif [ -d $file ]then echo &quot;文件是个目录&quot;else echo &quot;文件不是个目录&quot;fiif [ -s $file ]then echo &quot;文件不为空&quot;else echo &quot;文件为空&quot;fiif [ -e $file ]then echo &quot;文件存在&quot;else echo &quot;文件不存在&quot;fi Shell 流程控制 if else 123456789if conditionthen command1 command2 ... commandNelse commandfi if else-if else 123456789if condition1then command1elif condition2 then command2else commandNfi for 循环 1234567for var in item1 item2 ... itemNdo command1 command2 ... commandNdone in列表是可选的，如果不用它，for循环使用命令行的位置参数。 demo1:1234for loop in 1 2 3 4 5do echo &quot;The value is: $loop&quot;done 输出： 12345The value is: 1The value is: 2The value is: 3The value is: 4The value is: 5 demo2:1234for str in &apos;This is a string&apos;do echo $strdone 输出： 1This is a string while 语句1234while conditiondo commanddone demo1：1234567#!/bin/bashint=1while(( $int&lt;=5 ))do let &quot;int++&quot;doneecho $int 输出：15 demo2:1234567#!/bin/bashint=1while(( $int&lt;=5 ))do let int++doneecho $int 输出：11 demo3:123456echo &apos;按下 &lt;CTRL-D&gt; 退出&apos;echo -n &apos;输入你最喜欢的网站名: &apos;while read FILMdo echo &quot;是的！$FILM 是一个好网站&quot;done 无限循环 123456789101112131415while :do commanddone或while truedo commanddone或for (( ; ; )) until 循环 一般 while 循环优于 until 循环，但在某些时候—也只是极少数情况下，until 循环更加有用。 1234until conditiondo commanddone demo:123456789#!/bin/basha=0until [ ! $a -lt 10 ]do echo $a a=`expr $a + 1`done case1234567891011121314case 值 in模式1) command1 command2 ... commandN ;;模式2） command1 command2 ... commandN ;;esac 取值后面必须为单词in 每一模式必须以右括号结束 匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;; 每个case分支用右圆括号，用两个分号表示break 如果无一匹配模式，使用星号 * 捕获该值 esac（就是case反过来）作为结束标记 demo: 123456789101112131415echo &apos;输入 1 到 4 之间的数字:&apos;echo &apos;你输入的数字为:&apos;read aNumcase $aNum in 1) echo &apos;你选择了 1&apos; ;; 2) echo &apos;你选择了 2&apos; ;; 3) echo &apos;你选择了 3&apos; ;; 4) echo &apos;你选择了 4&apos; ;; *) echo &apos;你没有输入 1 到 4 之间的数字&apos; ;;esac Shell 函数 定义 123456789[ function ] funname [()]&#123; action; [return int;]&#125; 可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。 参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 return后跟数值n(0-255) 返回值 demo1：（无return关键词）12345678910#!/bin/bash# author:菜鸟教程# url:www.runoob.comdemoFun()&#123; echo &quot;这是我的第一个 shell 函数!&quot;&#125;echo &quot;-----函数开始执行-----&quot;demoFunecho &quot;-----函数执行完毕-----&quot; 输出：123-----函数开始执行-----这是我的第一个 shell 函数!-----函数执行完毕----- demo2：（带return关键词）123456789101112131415#!/bin/bash# author:菜鸟教程# url:www.runoob.comfunWithReturn()&#123; echo &quot;这个函数会对输入的两个数字进行相加运算...&quot; echo &quot;输入第一个数字: &quot; read aNum echo &quot;输入第二个数字: &quot; read anotherNum echo &quot;两个数字分别为 $aNum 和 $anotherNum !&quot; return $(($aNum+$anotherNum))&#125;funWithReturnecho &quot;输入的两个数字之和为 $? !&quot; 输出：1234567这个函数会对输入的两个数字进行相加运算...输入第一个数字: 1输入第二个数字: 2两个数字分别为 1 和 2 !输入的两个数字之和为 3 ! 函数参数 在Shell中，调用函数时可以向其传递参数。在函数体内部，通过 \\$n 的形式来获取参数的值，例如，$1表示第一个参数，$2表示第二个参数… 注意，$10 不能获取第十个参数，获取第十个参数需要${10}。当n&gt;=10时，需要使用${n}来获取参数。 带参数的函数示例：1234567891011121314#!/bin/bash# author:# url:funWithParam()&#123; echo &quot;第一个参数为 $1 !&quot; echo &quot;第二个参数为 $2 !&quot; echo &quot;第十个参数为 $10 !&quot; echo &quot;第十个参数为 $&#123;10&#125; !&quot; echo &quot;第十一个参数为 $&#123;11&#125; !&quot; echo &quot;参数总数有 $# 个!&quot; echo &quot;作为一个字符串输出所有参数 $* !&quot;&#125;funWithParam 1 2 3 4 5 6 7 8 9 34 73 输出：1234567第一个参数为 1 !第二个参数为 2 !第十个参数为 10 !第十个参数为 34 !第十一个参数为 73 !参数总数有 11 个!作为一个字符串输出所有参数 1 2 3 4 5 6 7 8 9 34 73 ! 特殊字符: 参数处理 | 说明：–：|：–$# | 传递到脚本的参数个数$ | 以一个单字符串显示所有向脚本传递的参数$$ | 脚本运行的当前进程ID号$! | 后台运行的最后一个进程的ID号$@ | 与$相同，但是使用时加引号，并在引号中返回每个参数。$- | 显示Shell使用的当前选项，与set命令功能相同。$? | 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 文件io获取命令行参数获取参数个数count=$# 获取某个参数12param1=$1param2=$2 获取运行状态 123456do somethingif [ $? -ne 0 ];thenecho &apos;do something failed!!!&apos;elseecho &apos;do something ok!!!&apos;fi","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"LINUX","slug":"LINUX","permalink":"https://lives.xtcgch.ink/tags/LINUX/"},{"name":"SHELL","slug":"SHELL","permalink":"https://lives.xtcgch.ink/tags/SHELL/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【故事】文章封面故事","slug":"story-index","date":"2018-12-06T06:50:50.000Z","updated":"2020-11-22T02:42:04.971Z","comments":true,"path":"2018/12/06/story-index/","link":"","permalink":"https://lives.xtcgch.ink/2018/12/06/story-index/","excerpt":"摘要: 这个栏目是用来介绍每篇文章的封面中包含的故事，构造这样的一个栏目的目的是让我保持写博客的习惯。","text":"摘要: 这个栏目是用来介绍每篇文章的封面中包含的故事，构造这样的一个栏目的目的是让我保持写博客的习惯。","categories":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}],"tags":[{"name":"故事","slug":"故事","permalink":"https://lives.xtcgch.ink/tags/故事/"}],"keywords":[{"name":"其他","slug":"其他","permalink":"https://lives.xtcgch.ink/categories/其他/"}]},{"title":"【原理】 网络通信之TCP和UDP篇","slug":"网络通信之TCP和UDP篇-20181124","date":"2018-11-24T14:49:27.000Z","updated":"2021-10-10T08:26:52.910Z","comments":true,"path":"2018/11/24/网络通信之TCP和UDP篇/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/24/网络通信之TCP和UDP篇/","excerpt":"摘要：本文主要介绍TCP和UDP的基础知识点。","text":"摘要：本文主要介绍TCP和UDP的基础知识点。 协议的区别1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接 2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保 证可靠交付 3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的 UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等） 4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信 5、TCP首部开销20字节;UDP的首部开销小，只有8个字节 6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道 具体编程时的区别1.socket()的参数不同 2.UDP Server不需要调用listen和accept 3.UDP收发数据用sendto/recvfrom函数 4.TCP：地址信息在connect/accept时确定 5.UDP：在sendto/recvfrom函数中每次均 需指定地址信息 6.UDP：shutdown函数无效 UDP应用场景1.面向数据报方式 2.网络数据大多为短消息 3.拥有大量Client 4.对数据安全性无特殊要求 5.网络负担非常重，但对响应速度要求高 UDP编程的服务器端一般步骤是1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt();* 可选 3、绑定IP地址、端口等信息到socket上，用函数bind(); 4、循环接收数据，用函数recvfrom(); 5、关闭网络连接； UDP编程的客户端一般步骤是1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt();* 可选 3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 4、设置对方的IP地址和端口等属性; 5、发送数据，用函数sendto(); 6、关闭网络连接； TCP编程的服务器端一般步骤是1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt(); * 可选 3、绑定IP地址、端口等信息到socket上，用函数bind(); 4、开启监听，用函数listen()； 5、接收客户端上来的连接，用函数accept()； 6、收发数据，用函数send()和recv()，或者read()和write(); 7、关闭网络连接； 8、关闭监听； TCP编程的客户端一般步骤是1、创建一个socket，用函数socket()； 2、设置socket属性，用函数setsockopt();* 可选 3、绑定IP地址、端口等信息到socket上，用函数bind();* 可选 4、设置要连接的对方的IP地址和端口等属性； 5、连接服务器，用函数connect()； 6、收发数据，用函数send()和recv()，或者read()和write(); 7、关闭网络连接； TCP和UDP的应用 TCP和UDP协议的比较 TCP/UDP编程模型","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://lives.xtcgch.ink/tags/网络/"},{"name":"TCP","slug":"TCP","permalink":"https://lives.xtcgch.ink/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"https://lives.xtcgch.ink/tags/UDP/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"数据结构之指针","slug":"数据结构之指针-20181123","date":"2018-11-23T14:49:27.000Z","updated":"2021-11-22T16:01:45.821Z","comments":true,"path":"2018/11/23/数据结构之指针/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/23/数据结构之指针/","excerpt":"摘要：本文主要讲C++中指针相关的知识点。","text":"摘要：本文主要讲C++中指针相关的知识点。 1、脑图 2、概述 3、特点（1）指针 （2）引用 4、指针类别4.1 空指针 在C++11之前，使用0或者NULL来赋予空指针 在C++11之后，使用nullptr来赋予空指针 4.2 智能指针1、简介：（1）头文件（2）在C++11标准后才正式可用 2、shared_ptr&lt;&gt;()（1）特点 引用计数，复制时只是复制指针，当计数为0时，调用元素的析构函数（2）初始化：使用make_shared&lt;&gt;()进行构造智能指针（3）复制：（4）注意事项： 3、unique_ptr&lt;&gt;()（1）特点 unique_ptr只能有一个使用权，不同的unique_ptr之间只能进行move转移使用权（2）初始化：使用make_unique&lt;&gt;()进行构造只能指针（3）复制：（4）注意事项： 4、weak_ptr&lt;&gt;()（1）特点 unique_ptr只能有一个使用权，不同的unique_ptr之间只能进行move转移使用权（2）初始化：使用make_unique&lt;&gt;()进行构造只能指针（3）复制：（4）注意事项： 4.3 数组指针1、简介本质是一个指针，指向一个数组 2、声明和定义int (* p)[10]; p、* p++、p[1] 3、删除delete[] 4、例子1234int a[3][4];int (* p)[4]; //该语句是定义一个数组指针，指向含4个元素的一维数组。 p=a; //将该二维数组的首地址赋给p，也就是a[0]或&amp;a[0][0] p++; //该语句执行过后，也就是p=p+1;p跨过行a[0][]指向了行a[1][] 4.4 指针数组1、简介本质是一个数组，存放的都是指针 2、声明和定义int * (p[]) 3、删除delete[] p 4、例子int p[3];int a[3][4];p++; //该语句表示p数组指向下一个数组元素。注：此数组每一个元素都是一个指针for(i=0;i&lt;3;i++)p[i]=a[i]这里int p[3] 表示一个一维数组内存放着三个指针变量，分别是p[0]、p[1]、p[2]所以要分别赋值。比如要表示数组中i行j列一个元素： (p[i]+j)、 ( (p+i)+j)、(* (p+i))[j]、p[i][j] 5、指针操作5.1 移动当指针为数组指针时，有2种移动指针的方法，一种是使用加法：p+=n，一种是使用下标：p[n]。 5.2 初始化和赋值（1）可以使用zeromemory()和memset()函数来进行指针初始化。（2）可以使用memcpy()函数来进行数组指针的赋值。 5.3 内存申请和删除（1）使用new进行申请内存，通过判断p是否为空指针来知晓是否申请内存成功（2）new申请的内存： 指针指向单个对象时，使用delete进行删除 指针指向数组时，使用delete[]进行删除 6、指针和引用的区别 定义和性质区别： （1）指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元; 而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已 （2）可以有const指针，但是没有const引用 （3）指针可以有多级，但是引用只能是一级（int ** p；合法 而 int &amp;&amp;a是不合法的） （4）指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化 (5)指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了 (6)”sizeof引用”得到的是所指向的变量(对象)的大小，而”sizeof指针”得到的是指针本身的大小 (7)指针和引用的自增(++)运算意义不一样 作为函数参数进行传递时的区别 指针传递的是一个副本，引用传递的是本身 7、注意事项（1）空指针 使用时需要先判断是否为空指针，方法有if(nullptr==p)或者assert(nullptr==p) 如果指针指向了一块堆内的内存，如果在未删除内存时把指针设为空指针，则造成了内存泄漏 （2）野指针 造成原因：删除指针指向的内存后，未给指针赋空值，所以原指针指向了一个不确定的内存 解决方案：删除指针指向的内存后，使用nullptr赋值为空指针","categories":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"数据结构","slug":"数据结构","permalink":"https://lives.xtcgch.ink/tags/数据结构/"},{"name":"指针","slug":"指针","permalink":"https://lives.xtcgch.ink/tags/指针/"},{"name":"引用","slug":"引用","permalink":"https://lives.xtcgch.ink/tags/引用/"}],"keywords":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}]},{"title":"【原理】 编程语言之C++类篇","slug":"编程语言之C++类篇-20181123","date":"2018-11-23T14:49:27.000Z","updated":"2021-10-10T16:03:04.280Z","comments":true,"path":"2018/11/23/编程语言之C++类篇/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/23/编程语言之C++类篇/","excerpt":"摘要：本文主要讲C++中类相关的知识点。","text":"摘要：本文主要讲C++中类相关的知识点。 模板类 只能在头文件中定义和实现 虚函数表、虚指针、纯虚函数 虚函数表在编译时开始生成 虚指针在运行时生成 纯虚函数每个类中只能有一个，并且占用4(32位机)/8(64位机)个字节 ##成员初始化列表 按照成员的定义顺序来初始化 ##重写构造函数，=，[]，&gt;，&lt; ClassA&amp; operator=(const ClassA&amp;){} ClassA operator\\{} ClassA operator&gt;(const ClassA&amp;){} ClassA operator&lt;(const ClassA&amp;){} ##指针成员的内存分配和内存释放 new 和delete new[]和delete[] char * p =0 ; const在函数中的用法 const定义参数时可以当做判断重载的条件之一 const主要是为了提高效率 （1）fun（）const {} 表示fun不能改变修改类的成员。可用在一些只读数据的函数中，避免程序员误操作对数据进行了修改 （2）const string &amp; fun（）{} 表示返回string对象的常量引用 const在指针中的用法（1）const char p == char const p p所指内容是常量 （2）char * const p p是常量，所指向的内容可以修改 空类的大小占1个字节 explicit的使用常用在赋值构造函数，表明要显示调用 派生类向基类转换1Derive d=new Base(); 构造函数的调用场景（1）无参构造函数 先基类，后派生类 （2）赋值构造函数 函数参数的传递 （3）复制构造函数–&gt;oprater== 函数返回值（似乎已经进行了优化，不再提供类型转换，即赋值构造函数的调用了） （4）析构函数 先基类，后派生类 区分构造函数、赋值构造函数和复制构造函数的调用（1）A a–&gt;构造函数 （2）A a =b–&gt;初始化 （3）A a,b;a=b;–&gt;赋值构造函数 指针成员的初始化（1）定义char * p （2）在默认构造函数中：p=new char[1];p[0]=’ \\0 ‘; 目的有： 为了防止p为野指针 为了析构函数能正常调用delete[]","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://lives.xtcgch.ink/tags/C/"},{"name":"类","slug":"类","permalink":"https://lives.xtcgch.ink/tags/类/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】回调函数","slug":"回调-20181122","date":"2018-11-23T08:00:00.000Z","updated":"2020-11-30T03:26:32.009Z","comments":true,"path":"2018/11/23/callback-function/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/23/callback-function/","excerpt":"","text":"摘要：回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用来调用其所指向的函数时，我们就说这是回调函数。回调函数不是由该函数的实现方直接调用，而是在特定的事件或条件发生时由另外的一方调用的，用于对该事件或条件进行响应。 1、同步调用同步调用是一种阻塞式调用，调用方要等待对方执行完毕才返回，它是一种单向调用 2、异步调用异步调用是一种类似消息或事件的机制，不过它的调用方向刚好相反，接口的服务在收到某种讯息或发生某种事件时，会主动通知客户方（即调用客户方的接口） —&gt; 文章1—&gt; 文章2 3、回调回调是一种双向调用模式，也就是说，被调用方在接口被调用时也会调用对方的接口 附：回调和异步调用的关系非常紧密，通常我们使用回调来实现异步消息的注册，通过异步调用来实现消息的通知","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"回调","slug":"回调","permalink":"https://lives.xtcgch.ink/tags/回调/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 操作系统之内存分配篇","slug":"操作系统之内存分配篇-20181122","date":"2018-11-23T08:00:00.000Z","updated":"2021-10-10T08:23:31.522Z","comments":true,"path":"2018/11/23/操作系统之内存分配篇/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/23/操作系统之内存分配篇/","excerpt":"摘要：内存分配是指在程序执行的过程中分配或者回收存储空间的分配内存的方法。","text":"摘要：内存分配是指在程序执行的过程中分配或者回收存储空间的分配内存的方法。 栈和堆（1）栈上的内存主要是由操作系统分配，不会发生内存泄漏，堆上的内存一般由程序员分配释放，若不释放，程序结束时可能由OS回收 （2）栈上的分配内存的大小是有限制，超出上限会分配失败，而堆上的内存分配则是没有大小限制 （3）堆区是公有的，栈区是线程独有的 （4）什么是堆：堆是大家共有的空间，分全局堆和局部堆。全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程 初始化的时候分配，运行过程中也可以向系统要额外的堆，但是记得用完了要还给操作系统，要不然就是内存泄漏。 什么是栈：栈是线程独有的，保存其运行状态和局部自动变量的。栈在线程开始的时候初始化，每个线程的栈互相独立。每个函数都有自己的栈，栈被用来在函数之间传递参数。操作系统在切换线程的时候会自动的切换栈，就是切换SS/ESP寄存器。栈空间不需要在高级语言里面显式的分配和释放。 注意：堆区与数据结构中的堆是两回事，分配方式倒是类似于链表。 错误示例： void Function(void) { char *p = (char *)malloc(100 * sizeof(char)); } 就这个例子，千万不要认为函数返回，函数所在的栈被销毁指针也跟着销毁，申请的内存也就一样跟着销毁了！这绝对是错误的！因为申请的内存在堆上，而函数所在的栈被销毁跟堆完全没有啥关系。 动态内存分配和静态内存分配动态内存分配动态内存分配(Dynamic Memory Allocation)就是指在程序执行的过程中动态地分配或者回收存储空间的分配内存的方法。动态内存分配不象数组等静态内存分配方法那样需要预先分配存储空间，而是由系统根据程序的需要即时分配，且分配的大小就是程序要求的大小。 静态内存分配静态的内存使用的是栈空间内存，不用程序员自己来分配。因为静态变量占用的存储空间对于编译器而言是可预计的，静态内存只需要编程的时候直接声明就可以了。 malloc 和 new1、联系 （1）都是动态分配内存 （2）在释放内存后，原指针要进行相关的处理 2、区别 （1）申请的内存所在位置 new操作符从自由存储区（free store）上为对象动态分配内存空间（自由存储区可以是堆，可以是静态存储区） malloc函数从堆上动态分配内存 （2）返回类型安全性 new是符合类型安全性的操作符：new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换 malloc是非类型安全性的操作符：malloc内存分配成功则是返回void * ，需要通过强制类型转换将void * 指针转换成我们需要的类型 （3）内存分配失败时的返回值 new内存分配失败时，会抛出bac_alloc异常，它不会返回NULL malloc分配内存失败时返回NULL，需要去判断是否分配成功 malloc检查分配内存是否成功： 123456789int *a = (int *)malloc ( sizeof (int ));if(NULL == a)&#123; ...&#125;else &#123; ...&#125; new检查分配内存是否成功： 12345678try&#123; int *a = new int();&#125;catch (bad_alloc)&#123; ...&#125; （4）是否需要指定内存大小 new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算，而malloc则需要显式地指出所需内存的尺寸 121、int* parr = new int [100] ; 则分配大小为 sizeof(int) * 100 2、int* parr = （int *）malloc （100 * sizeof（int）） （5）是否调用构造函数/析构函数 使用new操作符来分配对象内存时会经历三个步骤： 第一步：调用operator new 函数（对于数组是operator new[]）分配一块足够大的，原始的，未命名的内存空间以便存储特定类型的对象。第二步：编译器运行相应的构造函数以构造对象，并为其传入初值。第三步：对象构造完成后，返回一个指向该对象的指针。 使用delete操作符来释放对象内存时会经历两个步骤： 第一步：调用对象的析构函数。 第二步：编译器调用operator delete(或operator delete[])函数释放内存空间。 总之来说，new/delete会调用对象的构造函数/析构函数以完成对象的构造/析构。而malloc则不会。 （6）对数组的处理 new对数组的支持体现在它会分别调用构造函数函数初始化每一个数组元素，释放对象时为每个对象调用析构函数。 注意delete[]要与new[]配套使用，不然会找出数组对象部分释放的现象，造成内存泄漏。 至于malloc，它并知道你在这块内存上要放的数组还是啥别的东西，反正它就给你一块原始的内存，在给你个内存的地址就完事。 所以如果要动态分配一个数组的内存，还需要我们手动自定数组的大小 （7）new与malloc是否可以相互调用 operator new /operator delete的实现可以基于malloc，而malloc的实现不可以去调用new （8）是否可以被重载 opeartor new /operator delete可以被重载。标准库是定义了operator new函数和operator delete函数的8个重载版本 而malloc/free并不允许重载 （9）能够直观地重新分配内存 使用malloc分配的内存后，如果在使用过程中发现内存不足，可以使用realloc函数进行内存重新分配实现内存的扩充。 realloc先判断当前的指针所指内存是否有足够的连续空间，如果有，原地扩大可分配的内存地址，并且返回原来的地址指针；如果空间不够，先按照新指定的大小分配空间，将原有数据从头到尾拷贝到新分配的内存区域，而后释放原来的内存区域。 new没有这样直观的配套设施来扩充内存。 （10）客户处理内存分配不足 在operator new抛出异常以反映一个未获得满足的需求之前，它会先调用一个用户指定的错误处理函数，这就是new-handler 对于malloc，客户并不能够去编程决定内存不足以分配时要干什么事，只能看着malloc返回NULL 注意：（1）重复分配内存会使得内存泄漏（2）重复释放内存会发生错误 连续内存分配方式1）固定分区分配 将内存划分成若干个固定大小的块。将程序装入块中即可。内存划分成各个块之后，块大小不再改变。当然，划分块的方式有：所有的块大小相等；划分的块大小不相等。 这种方式，在实际的内存分配之前，就已经知道了所有的内存块大小了。 2）动态分区分配 需要一个空闲表 或者 空闲链 来记录目前系统中空间的内存区域。在内存分配时，需要查找空间表或空闲链找到一块内存分配给当前进程。 动态分区分配算法： a)首次适应法 b)循环首次适应法 c)最佳适应法 d)最坏适应法 e)快速适应法 3）可重定位分区分配 说白了，就是增加了内存移动的功能。由于若干次内存分配与回收之后，各个空闲的内存块不连续了。通过“重定位”，将已经分配的内存“紧凑”在一块（就类似于JVM垃圾回收中的复制算法）从而空出一大块空闲的内存出来。 ”紧凑“是需要开销的，比如需要重新计算 地址，这也为什么JVM垃圾回收会导致STW的原因。 而离散分配方式–不管是分页还是分段，都是直接将程序放到各个离散的页中。从而就不存在“紧凑”一说了。 连续内存分配方式涉及两种操作：内存分配操作 和 内存回收操作 离散内存分配方式内存资源是有限的，程序要运行，必须得加载到内存。如果内存已经满了，而现在又有新的程序要运行，怎么办？—SWAP 把当前不用的程序(数据)先换出内存，从而就有空间 加载当前需要运行的程序的一部分数据进入内存，这样大大提高了内存的利用率。 由于牵涉到换入与换出，前面的连续内存分配方式就有点不适用了。因为，最明显的一个问题：对于连续内存分配方式，究竟换出哪部分数据呢？ 而这种只装入部分”数据”就可以使程序运行的机制，就是虚拟存储器的本质。 参考文章 文章一 文章二","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://lives.xtcgch.ink/tags/内存管理/"},{"name":"内存分配","slug":"内存分配","permalink":"https://lives.xtcgch.ink/tags/内存分配/"},{"name":"操作系统","slug":"操作系统","permalink":"https://lives.xtcgch.ink/tags/操作系统/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【原理】 编译原理之Makefile篇","slug":"编译原理之Makefile篇-20181122","date":"2018-11-23T08:00:00.000Z","updated":"2021-10-16T15:54:40.383Z","comments":true,"path":"2018/11/23/makefile/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/23/makefile/","excerpt":"摘要：在unix/linux服务器下编译工程时，特别是大型工程，使用makefile语法是一个非常好的选择。","text":"摘要：在unix/linux服务器下编译工程时，特别是大型工程，使用makefile语法是一个非常好的选择。 脑图 简述 Makefile里有什么？ Makefile里主要包含了五个东西：显式规则、隐晦规则、变量定义、文件指示和注释。 （1）显式规则。显式规则说明了，如何生成一个或多的的目标文件。这是由Makefile的书写者明显指出，要生成的文件，文件的依赖文件，生成的命令。 （2）隐晦规则。由于我们的make有自动推导的功能，所以隐晦的规则可以让我们比较粗糙地简略地书写Makefile，这是由make所支持的。 （3）变量的定义。在Makefile中我们要定义一系列的变量，变量一般都是字符串，这个有点你C语言中的宏，当Makefile被执行时，其中的变量都会被扩展到相应的引用位置上。 （4）文件指示。其包括了三个部分，一个是在一个Makefile中引用另一个Makefile，就像C语言中的include一样；另一个是指根据某些情况指定Makefile中的有效部分，就像C语言中的预编译#if一样；还有就是定义一个多行的命令。有关这一部分的内容，我会在后续的部分中讲述。 （5）注释。Makefile中只有行注释，和UNIX的Shell脚本一样，其注释是用“#”字符，这个就像C/C++中的“//”一样。如果你要在你的Makefile中使用“#”字符，可以用反斜框进行转义，如：“#”。 Makefile的文件名 （1）默认情况：“GNUmakefile”、“makefile”、“Makefile” （2）自定义：“Make.Linux”，“Make.Solaris”，“Make.AIX” Make （1）默认文件：“GNUmakefile”、“makefile”、“Makefile” （2）指定要make的文件：make -f filename或make -file filename,如：make -f Make.Linux或make --file Make.AIX。 make运行时机 make会比较targets文件和prerequisites文件的修改日期，如果prerequisites文件的日期要比targets文件的日期要新，或者target不存在的话，那么，make就会执行后续定义的命令 目的 自动化管理工程项目的编译命令 工作原理 编译 编译时，编译器需要的是语法的正确，函数与变量的声明的正确。对于后者，通常是你需要告诉编译器头文件的所在位置（头文件中应该只是声明，而定义应该放在C/C++文件中），只要所有的语法正确，编译器就可以编译出中间目标文件。一般来说，每个源文件都应该对应于一个中间目标文件（O文件或是OBJ文件） 链接 链接时，主要是链接函数和全局变量，所以，我们可以使用这些中间目标文件（O文件或是OBJ文件）来链接我们的应用程序。链接器并不管函数所在的源文件，只管函数的中间目标文件（Object File），在大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以，我们要给中间目标文件打个包，在Windows下这种包叫“库文件”（Library File)，也就是 .lib 文件，在UNIX下，是Archive File，也就是 .a 文件。 使用规则环境变量 变量的基础 声明时，需要给变量赋予初值使用时，需要给在变量名前加上“$”符号，但最好用小括号“（）”或是大括号“{}”把变量给包括起来。如果你要使用真实的“$”字符，那么你需要用“$$”来表示。变量可以使用在许多地方，如规则中的“目标”、“依赖”、“命令”以及新的变量中。 （1）变量定义 1objects = program.o foo.o utils.o （2）变量的引用 12program : $(objects)cc -o program $(objects) 变量会在使用它的地方精确地展开，就像C/C++中的宏一样 123foo = prog.cprog.o : $(foo)cc -c $(foo) 展开后得到： 12prog.o : prog.ccc -c prog.c 变量的变量 在定义变量的值时，我们可以使用其它变量来构造变量的值，在Makefile中有两种方式来在用变量定义变量的值 第一种方式：简单的使用“=”号，在=左侧是变量，右侧是变量的值，右侧变量的值可以定义在文件的任何一处12345foo = $(bar)bar = $(ugh)ugh = Huh?all:echo $(foo) 输出： 1Huh? 第二种方式：使用的是:=操作符, 并且必须先定义变量，才能被引用123x := fooy := $(x) barx := later 等价于 12y := foo barx := later 变量值的替换 普通模式 替换变量中的共有的部分，其格式是$(var:a=b)或是${var:a=b}，其意思是，把变量var中所有以a字串“结尾”的a替换成b字串。这里的“结尾”意思是空格或是结束符 12foo := a.o b.o c.obar := $(foo:.o=.c) 解释： 先定义了一个$(foo)变量，而第二行的意思是把$(foo)中所有以.o字串结尾全部替换成.c，所以我们的“$(bar)”的值就是a.c b.c c.c 静态模式 12foo := a.o b.o c.obar := $(foo:%.o=%.c) 这依赖于被替换字串中的有相同的模式，模式中必须包含一个“%”字符，这个例子同样让$(bar)变量的值为“a.c b.c c.c” 把变量的值再当成变量 123x = yy = za := $($(x)) 在这个例子中，$(x)的值是“y”，所以$($(x))就是$(y)，于是$(a)的值就是“z”。（注意，是“x=y”，而不是“x=$(y)”） 追加变量值 12objects = main.o foo.o bar.o utils.oobjects += another.o $(objects)值：main.o foo.o bar.o utils.o another.o override 指示符 如果有变量是通常make的命令行参数设置的，那么Makefile中对这个变量的赋值会被忽略。如果你想在Makefile中设置这类参数的值，那么，你可以使用“override”指示符。其语法是：12override &lt;variable&gt; = &lt;value&gt;override &lt;variable&gt; := &lt;value&gt; 追加： 1override &lt;variable&gt; += &lt;more text&gt; 多行变量 语法： define 指示符后面跟的是变量的名字，另起一行定义变量的值，以endef关键字结束定义。 1234define two-linesecho fooecho $(bar)endef 环境变量 make 运行时的系统环境变量可以在make开始运行时被载入到Makefile文件中,但是如果Makefile中已定义了这个变量,或是这个变量由make命令行带入,那么系统的环境变量的值将被覆盖。 如果我们在环境变量中设置了CFLAGS环境变量，那么我们就可以在所有的Makefile中使用这个变量了 如果Makefile中定义了CFLAGS,那么则会使用Makefile中的这个变量,如果没有定义则使用系统环境变量的值 当make嵌套调用时,上层Makefile中定义的变量会以系统环境变量的方式传递到下层的Makefile中 默认情况下,只有通过命令行设置的变量会被传递。而定义在文件中的变量,如果要向下层 Makefile传递,则需要使用exprot关键字来声明 目标变量 为某个目标设置局部变量,它可以和“全局变量”同名,因为它的作用范围只在这条规则以及连带规则中,所以其值也只在作用范围内有效,而不会影响规则链以外的全局变量的值 语法： 12&lt;target ...&gt; : &lt;variable-assignment&gt;&lt;target ...&gt; : overide &lt;variable-assignment&gt; &lt;variable-assignment&gt;可以是前面讲过的各种赋值表达式，如“=”、“:=”、“+=”或是“？=”。第二个语法是针对于make命令行带入的变量，或是系统环境变量。 示例： 123456789101112131415prog : CFLAGS = -gprog : prog.o foo.o bar.o$(CC) $(CFLAGS) prog.o foo.o bar.oprog.o : prog.c$(CC) $(CFLAGS) prog.cfoo.o : foo.c$(CC) $(CFLAGS) foo.cbar.o : bar.c$(CC) $(CFLAGS) bar.c 不管全局的$(CFLAGS)的值是什么，在prog目标，以及其所引发的所有规则中（prog.o foo.o bar.o的规则），$(CFLAGS)的值都是“-g” 模式变量 1%.o : CFLAGS = -O 或 12345678910libs_for_gcc = -lgnunormal_libs =foo: $(objects)ifeq ($(CC),gcc)$(CC) -o foo $(objects) $(libs_for_gcc)else$(CC) -o foo $(objects) $(normal_libs)endif 语法规则 基础使用 123target... : prerequisites ... command ... target也就是一个目标文件，可以是Object File，也可以是执行文件。还可以是一个标签（Label），对于标签这种特性，在后续的“伪目标”章节中会有叙述。 prerequisites就是，要生成那个target所需要的文件或是目标。 command也就是make需要执行的命令。（任意的Shell命令） 12foo.o: foo.c defs.h # foo模块 cc -c -g foo.c 注解：（1）foo.o是target，目标文件；（2）foo.c defs.h是prerequisites，依赖文件；（3）cc -c -g foo.c就是command，即make需要执行的命令。 规则包含两个部分，一个是依赖关系，一个是生成目标的方法。 函数方面 函数调用 123（1）$(&lt;function&gt; &lt;arguments&gt; )（2）$&#123;&lt;function&gt; &lt;arguments&gt;&#125; 例子： 1“$(subst a,b,$(x))” 其中，subst就是函数名，a,b,S(x)就是参数 字符串函数 1$(subst &lt;from&gt;,&lt;to&gt;,&lt;text&gt; ) 示例 1$(subst ee,EE,feet on the street) 作用：把feet on the street中的ee替换成EE结果：返回fEEt on the strEEt。 加前缀函数——addprefix 功能：把前缀加到中的每个单词后面。返回：返回加过前缀的文件名序列。示例：$(addprefix src/,foo bar)返回值是“src/foo src/bar” 加后缀函数——addsuffix 功能：把后缀加到中的每个单词后面。返回：返回加过后缀的文件名序列。示例：$(addsuffix .c,foo bar)返回值是“foo.cbar.c” 取前缀函数——basename 功能：从文件名序列中取出各个文件名的前缀部分。返回：返回文件名序列的前缀序列，如果文件没有前缀，则返回空字串。示例：$(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar hacks” 取后缀函数——suffix 功能：从文件名序列中取出各个文件名的后缀。返回：返回文件名序列的后缀序列，如果文件没有后缀，则返回空字串。示例：$(suffix src/foo.c src-1.0/bar.chacks)返回值是“.c.c” 取目录函数——dir 功能：从文件名序列中取出目录部分。目录部分是指最后一个反斜杠（“/”）之前的部分。如果没有反斜杠，那么返回“./”。返回：返回文件名序列的目录部分。示例：$(dir src/foo.c hacks)返回值是“src/./” foreach 函数 这个函数的意思是，把参数中的单词逐一取出放到参数所指定的变量中，然后再执行所包含的表达式。每一次会返回一个字符串，循环过程中， 的所返回的每个字符串会以空格分隔，最后当整个循环结束时，所返回的每个字符串所组成的整个字符串（以空格分隔）将会是foreach函数的返回值。 所以，最好是一个变量名，可以是一个表达式，而中一般会使用这个参数来依次枚举中的单词 示例： 12names := a b c dfiles := $(foreach n,$(names),$(n).o) 输出：a.o b.o c.o d.o if 函数 12$(if &lt;condition&gt;,&lt;then-part&gt; )$(if &lt;condition&gt;,&lt;then-part&gt;,&lt;else-part&gt; ) call函数 语法：$(call ,,,…)功能：当make执行这个函数时，参数中的变量，如$(1)，$(2)，$(3)等，会被参数，，依次取代。而的返回值就是call函数的返回值。示例：123reverse = $(1) $(2)foo = $(call reverse,a,b)echo $(reverse) 输出：a b origin函数语法：$(origin )origin函数的返回值:undefined: 从来没有定义过，origin函数返回这个值“undefined”。default:是一个默认的定义，比如“CC”这个变量，这种变量我们将在后面讲述。environment:是一个环境变量，并且当Makefile被执行时，“-e”参数没有被打开file:被定义在Makefile中command line:被命令行定义override:被override指示符重新定义automatic:一个命令运行中的自动化变量 shell函数功能：用操作系统命令以及字符串处理命令awk，sed等等命令示例： 123456789contents := $(shell cat foo)files := $(shell echo \\*.c)``` - **控制make的函数**- **include函数**在Makefile使用include关键字可以把别的Makefile包含进来，这很像C语言的#include，被包含的文件会原模原样的放在当前文件的包含位置。include的语法是： includefilename可以是当前操作系统Shell的文件模式（可以保含路径和通配符）12在include前面可以有一些空字符，但是绝不能是[Tab]键开始。include和可以用一个或多个空格隔开。举个例子，你有这样几个Makefile：a.mk、b.mk、c.mk，还有一个文件叫foo.make，以及一个变量$(bar)，其包含了e.mk和f.mk，那么，下面的语句： include foo.make *.mk $(bar)12等价于： include foo.make a.mk b.mk c.mk e.mk f.mk12make命令开始时，会把找寻include所指出的其它Makefile，并把其内容安置在当前的位置。就好像C/C++的#include指令一样。如果文件都没有指定绝对路径或是相对路径的话，make会在当前目录下首先寻找，如果当前目录下没有找到，那么，make还会在下面的几个目录下找： 1.如果make执行时，有“-I”或“–include-dir”参数，那么make就会在这个参数所指定的目录下去寻找。2.如果目录/include（一般是：/usr/local/bin或/usr/include）存在的话，make也会去找。12如果有文件没有找到的话，make会生成一条警告信息，但不会马上出现致命错误。它会继续载入其它的文件，一旦完成makefile的读取，make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。如果你想让make不理那些无法读取的文件，而继续执行，你可以在include前加一个减号“-”。如： -include12345678910其表示，无论include过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和这一个是一样的。- **去空格函数 - strip**语法：`$(strip &lt;string&gt; )`功能：去掉&lt;string&gt;字串中开头和结尾的空字符。返回：返回被去掉空格的字符串值。示例： $(strip a b c )把字串“abc”去到开头和结尾的空格，结果是“abc”1234567- **查找字符串函数 - findstring**语法：`$(findstring &lt;find&gt;,&lt;in&gt; )`功能：在字串&lt;in&gt;中查找&lt;find&gt;字串。返回：如果找到，那么返回&lt;find&gt;，否则返回空字符串。示例： $(findstring a,a b c)$(findstring a,b c)12345678910第一个函数返回“a”字符串，第二个返回“”字符串（空字符串）$(filter &lt;pattern...&gt;,&lt;text&gt; )- **过滤函数 - filter**语法：`$(filter &lt;pattern...&gt;,&lt;text&gt; )`功能：以&lt;pattern&gt;模式过滤&lt;text&gt;字符串中的单词，保留符合模式&lt;pattern&gt;的单词。可以有多个模式。返回：返回符合模式&lt;pattern&gt;的字串。示例： sources := foo.c bar.c baz.s ugh.hfoo: $(sources)cc $(filter %.c %.s,$(sources)) -o foo1234567891011返回的值是“foo.c bar.c baz.s”- **反过滤函数——filter-out**语法：`$(filter-out &lt;pattern...&gt;,&lt;text&gt; )`名称：反过滤函数——filter-out。功能：以&lt;pattern&gt;模式过滤&lt;text&gt;字符串中的单词，去除符合模式&lt;pattern&gt;的单词。可以有多个模式。返回：返回不符合模式&lt;pattern&gt;的字串。示例： objects=main1.o foo.o main2.o bar.omains=main1.o main2.o12345678910111213141516171819202122232425262728293031323334353637$(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”- **排序函数——sort**语法：`$(sort &lt;list&gt; )`功能：给字符串&lt;list&gt;中的单词排序（升序）。返回：返回排序后的字符串。示例：$(sortfoobarlose)返回“barfoolose”。备注：sort函数会去掉&lt;list&gt;中相同的单词。- **取单词函数——word**语法：`$(word &lt;n&gt;,&lt;text&gt; )`功能：取字符串&lt;text&gt;中第&lt;n&gt;个单词。（从一开始）返回：返回字符串&lt;text&gt;中第&lt;n&gt;个单词。如果&lt;n&gt;比&lt;text&gt;中的单词数要大，那么返回空字符串。示例：$(word2,foobarbaz)返回值是“bar”- **取单词串函数——wordlist**功能：从字符串&lt;text&gt;中取从&lt;s&gt;开始到&lt;e&gt;的单词串。&lt;s&gt;和&lt;e&gt;是一个数字。返回：返回字符串&lt;text&gt;中从&lt;s&gt;到&lt;e&gt;的单词字串。如果&lt;s&gt;比&lt;text&gt;中的单词数要大，那么返回空字符串。如果&lt;e&gt;大于&lt;text&gt;的单词数，那么返回从&lt;s&gt;开始，到&lt;text&gt;结束的单词串。示例：$(wordlist2,3,foobarbaz)返回值是“barbaz”3. 功能方面- **在规则中使用通配符**make支持三各通配符：`*，?，[...]`。（1）~波浪号`~`字符在文件名中也有比较特殊的用途。如果是`~/test`，这就表示当前用户的$HOME目录下的test目录。而`~hchen/test`则表示用户hchen的宿主目录下的test目录。（这些都是Unix下的小知识了，make也支持）而在Windows或是MS-DOS下，用户没有宿主目录，那么波浪号所指的目录则根据环境变量“`HOME`”而定。（2）*通配符代替了你一系列的文件，如`*.c`表示所以后缀为c的文件。一个需要我们注意的是，如果我们的文件名中有通配符，如：`*`，那么可以用转义字符`\\`，如`\\*`来表示真实的`*`字符，而不是任意长度的字符串。好吧，还是先来看几个例子吧： clean: rm -f *.o12上面这个例子我不不多说了，这是操作系统Shell所支持的通配符。这是在命令中的通配符。 print: *.c lpr -p $? touch print12 上面这个例子说明了通配符也可以在我们的规则中，目标print依赖于所有的`[.c]`文件。其中的“`$?`”是一个自动化变量。 objects = *.o12上面这个例子，表示了，通符同样可以用在变量中。并不是说`[*.o]`会展开，不！`objects`的值就是`*.o`。Makefile中的变量其实就是C/C++中的宏。如果你要让通配符在变量中展开，也就是让`objects`的值是所有`[.o]`的文件名的集合，那么，你可以这样： objects := $(wildcard *.o)123456- **文件搜寻**在一些大的工程中，有大量的源文件，我们通常的做法是把这许多的源文件分类，并存放在不同的目录中。所以，当make需要去找寻文件的依赖关系时，你可以在文件前加上路径，但最好的方法是把一个路径告诉make，让make在自动去找。Makefile文件中的特殊变量&quot;VPATH&quot;就是完成这个功能的，如果没有指明这个变量，make只会在当前的目录中去找寻依赖文件和目标文件。如果定义了这个变量，那么，make就会在当当前目录找不到的情况下，到所指定的目录中去找寻文件了。 VPATH = src:../headers123456789101112上面的的定义指定两个目录，“src”和“../headers”，make会按照这个顺序进行搜索。目录由“冒号”分隔。（当然，当前目录永远是最高优先搜索的地方）另一个设置文件搜索路径的方法是使用make的“vpath”关键字（注意，它是全小写的），这不是变量，这是一个make的关键字，这和上面提到的那个VPATH变量很类似，但是它更为灵活。它可以指定不同的文件在不同的搜索目录中。这是一个很灵活的功能。它的使用方法有三种：- `vpath &lt; pattern&gt; &lt; directories&gt;` 为符合模式&lt; pattern&gt;的文件指定搜索目录&lt;directories&gt;。- `vpath &lt; pattern&gt; ` 清除符合模式&lt; pattern&gt;的文件的搜索目录。- `vpath ` 清除所有已被设置好了的文件搜索目录。vapth使用方法中的&lt; pattern&gt;需要包含“%”字符。“%”的意思是匹配零或若干字符，例如，“%.h”表示所有以“.h”结尾的文件。&lt; pattern&gt;指定了要搜索的文件集，而&lt; directories&gt;则指定了的文件集的搜索的目录。例如： vpath %.h ../headers1234该语句表示，要求make在“../headers”目录下搜索所有以“.h”结尾的文件。（如果某文件在当前目录没有找到的话）我们可以连续地使用vpath语句，以指定不同搜索策略。如果连续的vpath语句中出现了相同的&lt; pattern&gt;，或是被重复了的&lt; pattern&gt;，那么，make会按照vpath语句的先后顺序来执行搜索。如： vpath %.c foo vpath % blish vpath %.c bar12其表示“.c”结尾的文件，先在“foo”目录，然后是“blish”，最后是“bar”目录。 vpath %.c foo:bar vpath % blish123456而上面的语句则表示“.c”结尾的文件，先在“foo”目录，然后是“bar”目录，最后才是“blish”目录- **伪目标**最早先的一个例子中，我们提到过一个“clean”的目标，这是一个“伪目标”， clean: rm *.o temp 123456正像我们前面例子中的“clean”一样，即然我们生成了许多文件编译文件，我们也应该提供一个清除它们的“目标”以备完整地重编译而用。 （以“make clean”来使用该目标）因为，我们并不生成“clean”这个文件。“伪目标”并不是一个文件，只是一个标签，由于“伪目标”不是文件，所以make无法生成它的依赖关系和决定它是否要执行。我们只有通过显示地指明这个“目标”才能让其生效。当然，“伪目标”的取名不能和文件名重名，不然其就失去了“伪目标”的意义了。当然，为了避免和文件重名的这种情况，我们可以使用一个特殊的标记“.PHONY”来显示地指明一个目标是“伪目标”，向make说明，不管是否有这个文件，这个目标就是“伪目标”。 .PHONY : clean12只要有这个声明，不管是否有“clean”文件，要运行“clean”这个目标，只有“make clean”这样。于是整个过程可以这样写： .PHONY: clean clean: rm *.o temp 12伪目标一般没有依赖的文件。但是，我们也可以为伪目标指定所依赖的文件。伪目标同样可以作为“默认目标”，只要将其放在第一个。一个示例就是，如果你的Makefile需要一口气生成若干个可执行文件，但你只想简单地敲一个make完事，并且，所有的目标文件都写在一个Makefile中，那么你可以使用“伪目标”这个特性： all : prog1 prog2 prog3 .PHONY : all prog1 : prog1.o utils.o cc -o prog1 prog1.o utils.o prog2 : prog2.o cc -o prog2 prog2.o prog3 : prog3.o sort.o utils.o cc -o prog3 prog3.o sort.o utils.o1234我们知道，Makefile中的第一个目标会被作为其默认目标。我们声明了一个“all”的伪目标，其依赖于其它三个目标。由于伪目标的特性是，总是被执行的，所以其依赖的那三个目标就总是不如“all”这个目标新。所以，其它三个目标的规则总是会被决议。也就达到了我们一口气生成多个目标的目的。“.PHONY : all”声明了“all”这个目标为“伪目标”。随便提一句，从上面的例子我们可以看出，目标也可以成为依赖。所以，伪目标同样也可成为依赖。看下面的例子： .PHONY: cleanall cleanobj cleandiff cleanall : cleanobj cleandiff rm program cleanobj : rm .o cleandiff : rm .diff123456“makeclean”将清除所有要被清除的文件。“cleanobj”和“cleandiff”这两个伪目标有点像“子程序”的意思。我们可以输入“makecleanall”和“make cleanobj”和“makecleandiff”命令来达到清除不同种类文件的目的- **多目标**Makefile的规则中的目标可以不止一个，其支持多目标，有可能我们的多个目标同时依赖于一个文件，并且其生成的命令大体类似。于是我们就能把其合并起来。当然，多个目标的生成规则的执行命令是同一个，这可能会可我们带来麻烦，不过好在我们的可以使用一个自动化变量“$@”（关于自动化变量，将在后面讲述），这个变量表示着目前规则中所有的目标的集合，这样说可能很抽象，还是看一个例子吧。 bigoutput littleoutput : text.g generate text.g -$(subst output,,$@) &gt; $@ 12上述规则等价于： bigoutput : text.g generate text.g -big &gt; bigoutput littleoutput : text.g generate text.g -little &gt; littleoutput 123456其中，`-$(subst output,,$@) `中的“$”表示执行一个Makefile的函数，函数名为subst，后面的为参数。关于函数，将在后面讲述。这里的这个函数是截取字符串的意思，“$@”表示目标的集合，就像一个数组，“$@”依次取出目标，并执于命令。- **静态模式**静态模式可以更加容易地定义多目标的规则，可以让我们的规则变得更加的有弹性和灵活。我们还是先来看一下语法： &lt;targets…&gt;: : …123456789101112targets定义了一系列的目标文件，可以有通配符。是目标的一个集合。target-parrtern是指明了targets的模式，也就是的目标集模式。prereq-parrterns是目标的依赖模式，它对target-parrtern形成的模式再进行一次依赖目标的定义。这样描述这三个东西，可能还是没有说清楚，还是举个例子来说明一下吧。如果我们的&lt;target-parrtern&gt;定义成“%.o”，意思是我们的集合中都是以“.o”结尾的，而如果我们的&lt;prereq-parrterns&gt;定义成“%.c”，意思是对&lt;target-parrtern&gt;所形成的目标集进行二次定义，其计算方法是，取&lt;target-parrtern&gt;模式中的“%”（也就是去掉了[.o]这个结尾），并为其加上[.c]这个结尾，形成的新集合。所以，我们的“目标模式”或是“依赖模式”中都应该有“%”这个字符，如果你的文件名中有“%”那么你可以使用反斜杠“\\”进行转义，来标明真实的“%”字符。看一个例子： objects = foo.o bar.o all: $(objects) $(objects): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@123 上面的例子中，指明了我们的目标从$object中获取，“%.o”表明要所有以“.o”结尾的目标，也就是“foo.o bar.o”，也就是变量$object集合的模式，而依赖模式“%.c”则取模式“%.o”的“%”，也就是“foobar”，并为其加下“.c”的后缀，于是，我们的依赖目标就是“foo.cbar.c”。而命令中的“$&lt;”和“$@”则是自动化变量，“$&lt;”表示所有的依赖目标集（也就是“foo.c bar.c”），“$@”表示目标集（也褪恰癴oo.o bar.o”）。于是，上面的规则展开后等价于下面的规则： foo.o : foo.c $(CC) -c $(CFLAGS) foo.c -o foo.o bar.o : bar.c $(CC) -c $(CFLAGS) bar.c -o bar.o 1试想，如果我们的“%.o”有几百个，那种我们只要用这种很简单的“静态模式规则”就可以写完一堆规则，实在是太有效率了。“静态模式规则”的用法很灵活，如果用得好，那会一个很强大的功能。再看一个例子： files = foo.elc bar.o lose.o $(filter %.o,$(files)): %.o: %.c $(CC) -c $(CFLAGS) $&lt; -o $@ $(filter %.elc,$(files)): %.elc: %.el emacs -f batch-byte-compile $&lt;123456$(filter%.o,$(files))表示调用Makefile的filter函数，过滤“$filter”集，只要其中模式为“%.o”的内容。其的它内容，我就不用多说了吧。这个例字展示了Makefile中更大的弹性。- **自动生成依赖性**在Makefile中，我们的依赖关系可能会需要包含一系列的头文件，比如，如果我们的main.c中有一句“#include &quot;defs.h&quot;”，那么我们的依赖关系应该是： main.o : main.c defs.h12但是，如果是一个比较大型的工程，你必需清楚哪些C文件包含了哪些头文件，并且，你在加入或删除头文件时，也需要小心地修改Makefile，这是一个很没有维护性的工作。为了避免这种繁重而又容易出错的事情，我们可以使用C/C++编译的一个功能。大多数的C/C++编译器都支持一个“-M”的选项，即自动找寻源文件中包含的头文件，并生成一个依赖关系。例如，如果我们执行下面的命令： cc -M main.c12其输出是： main.o : main.c defs.h1234于是由编译器自动生成的依赖关系，这样一来，你就不必再手动书写若干文件的依赖关系，而由编译器自动生成了。需要提醒一句的是，如果你使用GNU的C/C++编译器，你得用“-MM”参数，不然，“-M”参数会把一些标准库的头文件也包含进来。gcc-M main.c的输出是： main.o: main.c defs.h /usr/include/stdio.h /usr/include/features.h \\ /usr/include/sys/cdefs.h /usr/include/gnu/stubs.h \\ /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stddef.h \\ /usr/include/bits/types.h /usr/include/bits/pthreadtypes.h \\ /usr/include/bits/sched.h /usr/include/libio.h \\ /usr/include/_G_config.h /usr/include/wchar.h \\ /usr/include/bits/wchar.h /usr/include/gconv.h \\ /usr/lib/gcc-lib/i486-suse-linux/2.95.3/include/stdarg.h \\ /usr/include/bits/stdio_lim.h 123 gcc -MM main.c的输出则是： main.o: main.c defs.h123456那么，编译器的这个功能如何与我们的Makefile联系在一起呢。因为这样一来，我们的Makefile也要根据这些源文件重新生成，让Makefile自已依赖于源文件？这个功能并不现实，不过我们可以有其它手段来迂回地实现这一功能。GNU组织建议把编译器为每一个源文件的自动生成的依赖关系放到一个文件中，为每一个“name.c”的文件都生成一个“name.d”的Makefile文件，[.d]文件中就存放对应[.c]文件的依赖关系。于是，我们可以写出[.c]文件和[.d]文件的依赖关系，并让make自动更新或自成[.d]文件，并把其包含在我们的主Makefile中，这样，我们就可以自动化地生成每个文件的依赖关系了。这里，我们给出了一个模式规则来产生[.d]文件： %.d: %.c @set -e; rm -f $@; \\ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@. ; \\ sed &apos;s,$∗\\.o[ :]*,\\1.o $@ : ,g&apos; &lt; $@. $@; \\ rm -f $@. 12345这个规则的意思是，所有的[.d]文件依赖于[.c]文件，“rm-f $@”的意思是删除所有的目标，也就是[.d]文件，第二行的意思是，为每个依赖文件“$&lt;”，也就是[.c]文件生成依赖文件，“$@”表示模式“%.d”文件，如果有一个C文件是name.c，那么“%”就是“name”，“”意为一个随机编号，第二行生成的文件有可能是“name.d.12345”，第三行使用sed命令做了一个替换，关于sed命令的用法请参看相关的使用文档。第四行就是删除临时文件。总而言之，这个模式要做的事就是在编译器生成的依赖关系中加入[.d]文件的依赖，即把依赖关系： main.o : main.c defs.h12转成： main.o main.d : main.c defs.h1于是，我们的[.d]文件也会自动更新了，并会自动生成了，当然，你还可以在这个[.d]文件中加入的不只是依赖关系，包括生成的命令也可一并加入，让每个[.d]文件都包含一个完赖的规则。一旦我们完成这个工作，接下来，我们就要把这些自动生成的规则放进我们的主Makefile中。我们可以使用Makefile的“include”命令，来引入别的Makefile文件（前面讲过），例如： sources = foo.c bar.c1 include $(sources:.c=.d)123456上述语句中的“$(sources:.c=.d)”中的“.c=.d”的意思是做一个替换，把变量$(sources)所有[.c]的字串都替换成[.d]，关于这个“替换”的内容，在后面我会有更为详细的讲述。当然，你得注意次序，因为include是按次来载入文件，最先载入的[.d]文件中的目标会成为默认目标- **清空目标文件的规则**每个Makefile中都应该写一个清空目标文件（.o和执行文件）的规则，这不仅便于重编译，也很利于保持文件的清洁。这是一个“修养”（呵呵，还记得我的《编程修养》吗）。一般的风格都是： clean: rm edit $(objects) 12更为稳健的做法是： .PHONY : clean clean : -rm edit $(objects) 123456789101112131415161718192021222324252627282930313233343536373839.PHONY意思表示clean是一个“伪目标”，。而在rm命令前面加了一个小减号的意思就是，也许某些文件出现问题，但不要管，继续做后面的事。当然，clean的规则不要放在文件的开头，不然，这就会变成make的默认目标，相信谁也不愿意这样。不成文的规矩是——“clean从来都是放在文件的最后”。### 编译规则- 如果这个工程没有编译过，那么我们的所有C文件都要编译并被链接。- 如果这个工程的某几个C文件被修改，那么我们只编译被修改的C文件，并链接目标程序。- 如果这个工程的头文件被改变了，那么我们需要编译引用了这几个头文件的C文件，并链接目标程序。---## makefile的运行1、make的退出码0 ：表示成功执行。1 ：如果make运行时出现任何错误，其返回1。2 ：如果你使用了make的“-q”选项，并且make使得一些目标不需要更新，那么返回2。2、指定Makefile3、指定目标4、检查规则5、make的参数---## 总结1. 命令行一定要以`tab`进行缩进---## 示例1. 示例一 test:main.o base.o g++ -o test main.o base.o main.o:main.cpp base.hpp gcc -c main.cpp base.o:base.cpp base.hpp gcc -c base.cpp .PHONY:clean clean: rm test main.o base.o 12345678解释：（1）test为生成的可执行文件的名称，即make makefile后生成的test可执行文件（2）如果语言是C++，则要使用g++来进行编译和链接（3）命令行只能使用tab来缩进，不能使用空格等2. 示例二 obj=main.o base.o test:$(obj) g++ -o test $(obj) main.o:base.hpp base.o:base.hpp .PHONY:clean clean: rm test $(obj) ` 参考文章–&gt; 文章1","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"MAKEFILE","slug":"MAKEFILE","permalink":"https://lives.xtcgch.ink/tags/MAKEFILE/"},{"name":"编译","slug":"编译","permalink":"https://lives.xtcgch.ink/tags/编译/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]},{"title":"【专项】 数据结构之排序","slug":"数据结构之排序-20181122","date":"2018-11-22T14:49:27.000Z","updated":"2021-10-10T14:37:35.506Z","comments":true,"path":"2018/11/22/数据结构之排序/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/22/数据结构之排序/","excerpt":"本文主要介绍常见的七大排序方法，并且经过了优化，例子是C++版本，在vs1015中经过测试，全部通过，可以直接使用。","text":"本文主要介绍常见的七大排序方法，并且经过了优化，例子是C++版本，在vs1015中经过测试，全部通过，可以直接使用。 1、冒泡排序12345678910111213141516171819void bubble(vector&lt;int&gt; &amp;v)&#123; int flag = 1; int len = v.size(); for(int i = 0; i &lt; len &amp;&amp; flag == 1; i++) &#123; flag = 0; for(int j = len - 1; j &gt; i; j--) &#123; if(v[j - 1] &gt; v[j]) &#123; int temp = v[j]; v[j] = v[j - 1]; v[j - 1] = temp; flag = 1; &#125; &#125; &#125;&#125; 2、选择排序123456789101112131415161718192021222324252627void select(vector&lt;int&gt; &amp;v)&#123; int len = v.size(); if(len == 0) &#123; return; &#125; register int i, j, min, m; for(i = 0; i &lt; len - 1; i++) &#123; min = i;//²éÕÒ×îÐ¡Öµ for(j = i + 1; j &lt; len; j++) &#123; if(v[min] &gt; v[j]) &#123; min = j; &#125; &#125; if(min != i) &#123; swap(v[min], v[i]); cout &lt;&lt; &quot;第&quot; &lt;&lt; i + 1 &lt;&lt; &quot;次排序结果是：&quot; &lt;&lt; endl; copy(v.begin(), v.end(), ostream_iterator&lt;int, char&gt;(cout, &quot; &quot;)); cout &lt;&lt; endl; &#125; &#125;&#125; 3、简单插入排序12345678910111213void insert(vector&lt;int&gt; &amp;v)&#123; for(int i = 1; i &lt; v.size(); i++) &#123; int j = i - 1; int data = v[i]; for(; j &gt;= 0 &amp;&amp; data &lt; v[j]; j--) &#123; v[j + 1] = v[j]; &#125; v[j + 1] = data; &#125;&#125; 4、希尔排序123456789101112131415161718192021void shell(vector&lt;int&gt; &amp;v)&#123; int h = 1, len = v.size(); while(h &lt; len)//»ñÈ¡ÔöÁ¿ h = 3 * h + 1; while(h &gt; 0) &#123; for(int j = h; j &lt; len; j++) &#123; int key = v[j]; int i = j - h; while(i &gt;= 0 &amp;&amp; v[i] &gt; key) &#123; v[i + h] = v[i]; i = i - h; &#125; v[i + h] = key; &#125; h = h / 3; &#125;&#125; 5、快速排序优化： 尾排 选取合适的关键字 尾递归概念： 如果一个函数中所有递归形式的调用都出现在函数的末尾，当递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分时，这个递归调用就是尾递归。 尾递归函数的特点是在回归过程中不用做任何操作，这个特性很重要，因为大多数现代的编译器会利用这种特点自动生成优化的代码。 尾递归原理： 当编译器检测到一个函数调用是尾递归的时候，它就覆盖当前的活动记录而不是在栈中去创建一个新的。 编译器可以做到这点，因为递归调用是当前活跃期内最后一条待执行的语句，于是当这个调用返回时栈帧中并没有其他事情可做，因此也就没有保存栈帧的必要了。通过覆盖当前的栈帧而不是在其之上重新添加一个，这样所使用的栈空间就大大缩减了，这使得实际的运行效率会变得更高。 12345678910111213141516171819202122232425int partion(vector&lt;int&gt; &amp; v, int low, int high)&#123; int pivot, m; m = low + (high - low) / 2; if(v[low] &gt; v[high]) swap(v[low], v[high]); if(v[m] &gt; v[high]) swap(v[m], v[high]); if(v[m] &gt; v[low]) swap(v[m], v[low]); pivot = v[low]; while(low &lt; high) &#123; while(low &lt; high &amp;&amp; v[high] &gt;= pivot) high--; v[low] = v[high]; while(low &lt; high &amp;&amp; v[low] &lt;= pivot) low++; v[high] = v[low]; &#125; v[low] = pivot; return low;&#125; //尾排12345678910void qsort(vector&lt;int&gt; &amp; v, int low, int high)&#123; int pivot; if(low &lt; high) &#123; pivot = partion(v, low, high); qsort(v, low, pivot - 1); qsort(v, pivot + 1, high); &#125;&#125; //尾排 - 编译器可以优化尾排12345678910111213141516void qsort1(vector&lt;int&gt; &amp; v, int low, int high)&#123; int pivot; while(low &lt; high) &#123; pivot = partion(v, low, high); qsort1(v, low, pivot - 1); low = pivot + 1; &#125;&#125;void quick(vector&lt;int&gt; &amp; v)&#123; qsort1(v, 0, v.size() - 1);&#125; 6、堆排序12345678910111213141516171819202122232425262728293031323334353637void adjustHeap(vector&lt;int&gt; &amp;arrs, int ParentKey, int len)&#123; int ParentValue = arrs[ParentKey]; int ChildKey = 2 * ParentKey + 1; while(ChildKey &lt; len) &#123; if(ChildKey + 1 &lt; len&amp;&amp;arrs[ChildKey] &lt; arrs[ChildKey + 1]) &#123; ChildKey++; //½Ï´óº¢×ÓµÄÏÂ±ê &#125; if(ParentValue &lt; arrs[ChildKey]) &#123; arrs[ParentKey] = arrs[ChildKey]; ParentKey = ChildKey; ChildKey = 2 * ParentKey + 1; &#125; else break; &#125; arrs[ParentKey] = ParentValue;&#125;void heapSort(vector&lt;int&gt; &amp;arrs, int len)&#123; for(int i = arrs.size() / 2 - 1; i &gt;= 0; i--) adjustHeap(arrs, i, arrs.size()); for(int i = arrs.size() - 1; i &gt;= 0; i--) &#123; //Êä³ö¸ù½Úµã int maxEle = arrs[0]; arrs[0] = arrs[i]; arrs[i] = maxEle; adjustHeap(arrs, 0, i); &#125;&#125; 7、归并排序12345678910111213141516171819202122232425262728293031323334//归并排序void Merge(vector&lt;int&gt; &amp;a, int low, int mid, int high, vector&lt;int&gt; &amp;temp)&#123; int i, j, k; i = low; j = mid + 1; k = 0; while(i &lt;= mid &amp;&amp; j &lt;= high) &#123; if(a[i] &lt;= a[j]) temp[k++] = a[i++]; else temp[k++] = a[j++]; &#125; while(i &lt;= mid) temp[k++] = a[i++]; while(j &lt;= high) temp[k++] = a[j++]; for(i = 0; i &lt; k; i++) a[low + i] = temp[i]; &#125;//接口函数void MergeSort(vector&lt;int&gt; &amp;data, int low, int high, vector&lt;int&gt; &amp;result)&#123; if(low &lt; high) &#123; int mid = (low + high) / 2; MergeSort(data, low, mid, result); MergeSort(data, mid + 1, high, result); Merge(data, low, mid, high, result); &#125;&#125;","categories":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://lives.xtcgch.ink/tags/算法/"},{"name":"排序","slug":"排序","permalink":"https://lives.xtcgch.ink/tags/排序/"}],"keywords":[{"name":"专项","slug":"专项","permalink":"https://lives.xtcgch.ink/categories/专项/"}]},{"title":"【原理】 网络通信之HTTP(S)","slug":"网络通信之HTTP(S)-20181122","date":"2018-11-22T05:15:06.000Z","updated":"2021-10-10T15:48:48.818Z","comments":true,"path":"2018/11/22/网络通信之HTTP(S)/","link":"","permalink":"https://lives.xtcgch.ink/2018/11/22/网络通信之HTTP(S)/","excerpt":"http应该是每个做过网络编程的程序员都应该去了解的一个协议，只是根据自身业务和职业方向来决定是否深入专研还是浅尝辄止。对于我来说，只需要初步理解http的原理就可以了。","text":"http应该是每个做过网络编程的程序员都应该去了解的一个协议，只是根据自身业务和职业方向来决定是否深入专研还是浅尝辄止。对于我来说，只需要初步理解http的原理就可以了。 简介 HTTP协议（Hyper Text Transfer Protocol，超文本传输协议）,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。 HTTP基于TCP/IP通信协议来传递数据。 HTTP基于客户端/服务端（C/S）架构模型，通过一个可靠的链接来交换信息，是一个无状态的请求/响应协议。 请求体 请求方法 HEAD: 仅请求响应首部 GET: 完整请求一个资源 （常用 PUT: (webdav) 上传文件（但是浏览器不支持该方法） POST：提交表单 （常用） DELETE：(webdav) 删除 TRACE: 追求一个资源请求中间所经过的代理（该方法不能由浏览器发出） OPTIONS：返回请求的资源所支持的方法的方法 状态码1xx: 信息性状态码,表示服务器已接收了客户端请求，客户端可继续发送请求 1100, 101 2xx: 成功状态码, 1200：OK 3xx: 重定向状态码,表示服务器要求客户端重定向 12345301: 永久重定向, Location响应首部的值仍为当前URL，因此为隐藏重定向;302: 临时重定向，显式重定向, Location响应首部的值为新的URL304：Not Modified 未修改，比如本地缓存的资源文件和服务器上比较时，发现并没有修改，服务器返回一个304状态码，告诉浏览器，你不用请求该资源，直接使用本地的资源即可。 附注： 服务器给浏览器响应一个301永久重定向响应，这样浏览器就会访问http://www.facebook.com/而非http://facebook.com/。 为什么服务器一定要重定向而不是直接发送用户想看的网页内容呢？ 其中一个原因跟搜索引擎排名有关。 如果一个页面有两个地址，就像http://www.igoro.com/和http://igoro.com/，搜索引擎会认为它们是两个网站，结果造成每个搜索链接都减少从而降低排名。 而搜索引擎知道301永久重定向是什么意思，这样就会把访问带www的和不带www的地址归到同一个网站排名下。 还有就是用不同的地址会造成缓存友好性变差，当一个页面有好几个名字时，它可能会在缓存里出现好几次。 4xx: 客户端错误状态码，表示客户端的请求有非法内容 1234567400 Bad Request 表示客户端请求有语法错误，不能被服务器所理解401 Unauthonzed 表示请求未经授权，该状态代码必须与 WWW-Authenticate 报头域一起使用403 Forbidden 表示服务器收到请求，但是拒绝提供服务，通常会在响应正文中给出不提供服务的原因 404: Not Found 请求的URL资源并不存在 5xx: 服务器端错误状态码，表示服务器未能正常处理客户端的请求而出现意外错误 12345500: Internal Server Error 服务器内部错误502: Bad Gateway 前面代理服务器联系不到后端的服务器时出现504：Gateway Timeout 这个是代理能联系到后端的服务器，但是后端的服务器在规定的时间内没有给代理服务器响应 请求过程1、域名解析 2、浏览器与web服务器建立一个 TCP 连接 3、浏览器给Web服务器发送一个http请求 4、服务器的永久重定向响应 考虑代理服务器的重定向 考虑路由器的重定向 5、浏览器跟踪重定向地址 6、服务器“处理”请求 考虑缓存 7、服务器发回一个HTML响应 8、客户端浏览器解析HTML内容 9、浏览器获取嵌入在HTML中的对象","categories":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://lives.xtcgch.ink/tags/网络/"},{"name":"前端","slug":"前端","permalink":"https://lives.xtcgch.ink/tags/前端/"},{"name":"HTTP","slug":"HTTP","permalink":"https://lives.xtcgch.ink/tags/HTTP/"}],"keywords":[{"name":"原理","slug":"原理","permalink":"https://lives.xtcgch.ink/categories/原理/"}]}]}